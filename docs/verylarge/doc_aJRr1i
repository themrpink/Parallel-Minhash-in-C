== Electoral history ==
{{main|Electoral history of John McCain}}

== Bibliography ==

=== Books ===
* ''[[Faith of My Fathers]]'' by John McCain, [[Mark Salter]] (Random House, August 1999) {{ISBN|0-375-50191-6}} (later made into the 2005 television film ''[[Faith of My Fathers (film)|Faith of My Fathers]]'')
* ''[[Worth the Fighting For]]'' by John McCain, Mark Salter (Random House, September 2002) {{ISBN|0-375-50542-3}}
* ''[[Why Courage Matters]]: The Way to a Braver Life'' by John McCain, Mark Salter (Random House, April 2004) {{ISBN|1-4000-6030-3}}
* ''[[Character Is Destiny]]: Inspiring Stories Every Young Person Should Know and Every Adult Should Remember'' by John McCain, Mark Salter (Random House, October 2005) {{ISBN|1-4000-6412-0}}
* ''[[Hard Call]]: Great Decisions and the Extraordinary People Who Made Them'' by John McCain, Mark Salter (Hachette, August 2007) {{ISBN|0-446-58040-6}}
* ''[[Thirteen Soldiers]]: A Personal History of Americans at War'' by John McCain, Mark Salter (Simon &amp; Schuster, November 2014) {{ISBN|1-4767-5965-0}}
* ''[[The Restless Wave (book)|The Restless Wave]]: Good Times, Just Causes, Great Fights, and Other Appreciations'' by John McCain, Mark Salter (Simon &amp; Schuster, May 2018) {{ISBN|978-1501178009}}

=== Articles and forewords ===
* [https://web.archive.org/web/20081013133940/http://www.usnews.com/articles/news/world/2008/01/28/john-mccain-prisoner-of-war-a-first-person-account.html &quot;How the POW's Fought Back&quot;, by John S. McCain III, Lieut. Commander, U.S. Navy], ''[[U.S. News &amp; World Report]]'', May 14, 1973 (reprinted for web under different title in 2008). Reprinted in ''Reporting Vietnam, Part Two: American Journalism 1969–1975'' ([[The Library of America]], 1998) {{ISBN|1-883011-59-0}}
* &quot;[[The Code of Conduct and the Vietnam Prisoners of War]]&quot;, by John S. McCain, Commander USN, [[National War College]], April 8, 1974 ([http://graphics8.nytimes.com/packages/pdf/politics/20080615/McCain.pdf actual paper])
* Foreword by John McCain to ''A Code to Keep: The True Story of America's Longest-Held Civilian POW in Vietnam'' by [[Ernest C. Brace]] (St. Martin's Press, 1988) {{ISBN|0-7090-3560-8}}
* [https://web.archive.org/web/20030219/http://mccain.senate.gov/speechesyr.htm Speeches] of John McCain, 1988–2000
* Foreword by John McCain to ''Glory Denied: The Saga of Jim Thompson, America's Longest-held Prisoner'' by Tom Philpott (W. W. Norton, 2001) {{ISBN|0-393-02012-6}}
* Foreword by John McCain to ''[[The Best and the Brightest]]'' by [[David Halberstam]] (Random House, 2001 edition) {{ISBN|1-58836-098-9}}
* Foreword by John S. McCain to ''Unfinished Business: Afghanistan, the Middle East and Beyond&amp;nbsp;– Defusing the Dangers That Threaten America's Security'' by [[Harlan Ullman]] (Citadel Press, June 2002) {{ISBN|0-8065-2431-6}}
* Foreword by John McCain and [[Max Cleland]] to ''Odysseus in America: Combat Trauma and the Trials of Homecoming'' by Jonathan Shay (Scribner, November 2002) {{ISBN|0-7432-1156-1}}
* [https://web.archive.org/web/20080529155057/http://www.popularmechanics.com/technology/military_law/3491861.html?page=3 Foreword] by John McCain to ''Debunking 9/11 Myths: Why Conspiracy Theories Can't Stand Up to the Facts'' by the Editors of ''[[Popular Mechanics]]'' (Hearst, August 2006) {{ISBN|1-58816-635-X}}
* Introduction by John McCain to ''Pearl Harbor, the Day of Infamy, an Illustrated History'' by [[Dan van der Vat]] (Black Walnut Books, 2007) {{ISBN|1-897330-28-6}}
* [https://web.archive.org/web/20080821034132/http://www.foreignaffairs.org/20071101faessay86602/john-mccain/an-enduring-peace-built-on-freedom.html &quot;An Enduring Peace Built on Freedom: Securing America's Future&quot; by John McCain] ''[[Foreign Affairs]]'', November/December 2007

== See also ==
* [[List of United States Congress members who died in office]]
* [[List of United States Senators born outside the United States]]

== References ==
{{reflist|25em}}

== Bibliography ==
{{refbegin}}
* Alexander, Paul. ''Man of the People: The Life of John McCain'' ([[John Wiley &amp; Sons]], Hoboken, New Jersey 2002). {{ISBN|0-471-22829-X}}.
* [[David Brock|Brock, David]] and Waldman, Paul. ''Free Ride: John McCain and the Media'' ([[Anchor Books]], New York 2008). {{ISBN|0-307-27940-5}}.
* [[Elizabeth Drew|Drew, Elizabeth]]. ''Citizen McCain'' ([[Simon &amp; Schuster]], New York 2002). {{ISBN|0-641-57240-9}}.
* Feinberg, Barbara Silberdick. ''John McCain: Serving His Country'' ([[Millbrook Press]], Brookfield, Connecticut 2000). {{ISBN|0-7613-1974-3}}.
* Hubbell, John G. ''P.O.W.: A Definitive History of the American Prisoner-Of-War Experience in Vietnam, 1964–1973'' ([[Reader's Digest Press]], New York 1976). {{ISBN|0-88349-091-9}}.
* Karaagac, John. ''John McCain: An Essay in Military and Political History'' ([[Lexington Books]], Lanham, Maryland 2000). {{ISBN|0-7391-0171-4}}.
* McCain, John and [[Mark Salter|Salter, Mark]], ''[[Faith of My Fathers]]'' ([[Random House]], New York 1999). {{ISBN|0-375-50191-6}}.
* McCain, John and Salter, Mark. ''[[Worth the Fighting For]]'' ([[Random House]], New York 2002). {{ISBN|0-375-50542-3}}.
* [[Stuart Rochester|Rochester, Stuart I.]] and Kiley, Frederick. ''Honor Bound: American Prisoners of War in Southeast Asia, 1961–1973'' ([[Naval Institute Press]], Annapolis, Maryland 1999). {{ISBN|1-55750-694-9}}.
* Schecter, Cliff. ''The Real McCain: Why Conservatives Don't Trust Him and Why Independents Shouldn't'' ([[PoliPoint Press]], Sausalito, California 2008). {{ISBN|0-9794822-9-1}}.
* [[Robert Timberg|Timberg, Robert]]. ''John McCain: An American Odyssey'' ([[Touchstone Books]], New York 1999). {{ISBN|0-684-86794-X}}. [https://www.amazon.com/dp/product-description/0684826739 Chapter 1] available online.
* Timberg, Robert. ''[[The Nightingale's Song]]'' ([[Simon &amp; Schuster]], New York 1996). {{ISBN|0-684-80301-1}}. [https://www.nytimes.com/books/first/t/timberg-mccain.html Chapter 1] available online.
* Welch, Matt. ''McCain: The Myth of a Maverick'' ([[Palgrave Macmillan]], New York 2007). {{ISBN|0-230-60396-3}}.
{{refend}}

== External links ==
{{Sister project links|s=Author:John McCain|wikt=no|voy=no|m=no|mw=no|species=no|n=Category:John McCain|b=no|v=no|d=Q10390}}
* [https://web.archive.org/web/19990508184631/http://mccain.senate.gov/ Senator John McCain] official U.S. Senate website
* [http://www.johnmccain.com/ John McCain for Senate]
* [[Sean Wilentz]]: [https://www.britannica.com/biography/John-McCain ''John McCain.''] In: ''[[Encyclopædia Britannica]]'', February 15, 2018
* {{Curlie|Regional/North_America/United_States/Arizona/Government/Federal/US_Senate/John_McCain_%5BR%5D}}
* {{C-SPAN|johnmccain}}
* {{CongLinks | congbio=m000303 | votesmart=53270 | fec=S6AZ00019 | congress=john-mccain/754}}
* [https://www.pbs.org/weta/finding-your-roots/blog/john-mccains-interactive-family-tree/ Gates, H.L. John McCain's Interactive Family Tree. PBS. February 11, 2016. Accessed February 17, 2017]

{{s-start}}
{{s-par|us-hs}}
{{US House succession box
|state    = Arizona
|district = 1
|before   = [[John Jacob Rhodes]]
|after    = [[John Jacob Rhodes III]]
|years    = 1983–1987}}
|-
{{s-ppo}}
{{s-bef|before=[[Barry Goldwater]]}}
{{s-ttl|title=[[Republican Party (United States)|Republican]] nominee for [[List of United States Senators from Arizona|U.S. Senator]] from [[Arizona]]&lt;br /&gt;([[Classes of United States Senators|Class 3]])|years=[[1986 United States Senate election in Arizona|1986]], [[1992 United States Senate election in Arizona|1992]], [[1998 United States Senate election in Arizona|1998]], [[2004 United States Senate election in Arizona|2004]], [[2010 United States Senate election in Arizona|2010]], [[2016 United States Senate election in Arizona|2016]]}}
{{s-aft|after=[[Martha McSally]]}}
|-
{{s-bef|before=[[Susan Molinari]]}}
{{s-ttl|title=Keynote Speaker of the [[Republican National Convention]]|years=[[2000 Republican National Convention|2000]]|alongside=[[Colin Powell]]}}
{{s-aft|after=[[Zell Miller]]}}
|-
{{s-bef|before=[[George W. Bush]]}}
{{s-ttl|title=[[Republican Party (United States)|Republican]] nominee for [[President of the United States]]|years=[[2008 United States presidential election|2008]]}}
{{s-aft|after=[[Mitt Romney]]}}
|-
{{s-par|us-sen}}
{{U.S. Senator box
|state     = Arizona
|class     = 3
|before    = [[Barry Goldwater]]
|after     = [[Jon Kyl]]
|years     = 1987–2018
|alongside = [[Dennis DeConcini]], [[Jon Kyl]], [[Jeff Flake]]}}
|-
{{s-bef|before=[[Daniel Inouye]]}}
{{s-ttl|title=Chair of the [[United States Senate Committee on Indian Affairs|Senate Indian Affairs Committee]]|years=1995–1997}}
{{s-aft|after=[[Ben Nighthorse Campbell]]}}
|-
{{s-bef|before=[[Larry Pressler]]}}
{{s-ttl|title=Chair of the [[United States Senate Committee on Commerce, Science and Transportation|Senate Commerce Committee]]|years=1997–2001}}
{{s-aft|rows=4|after=[[Fritz Hollings]]}}
|-
{{s-bef|rows=4|before=Fritz Hollings}}
{{s-ttl|title=Ranking Member of the [[United States Senate Committee on Commerce, Science and Transportation|Senate Commerce Committee]]|years=2001}}
|-
{{s-ttl|title=Chair of the [[United States Senate Committee on Commerce, Science and Transportation|Senate Commerce Committee]]|years=2001}}
|-
{{s-ttl|title=Ranking Member of the [[United States Senate Committee on Commerce, Science and Transportation|Senate Commerce Committee]]|years=2001–2003}}
|-
{{s-ttl|title=Chair of the [[United States Senate Committee on Commerce, Science and Transportation|Senate Commerce Committee]]|years=2003–2005}}
{{s-aft|after=[[Ted Stevens]]}}
|-
{{s-bef|before=[[Ben Nighthorse Campbell]]}}
{{s-ttl|title=Chair of the [[United States Senate Committee on Indian Affairs|Senate Indian Affairs Committee]]|years=2005–2007}}
{{s-aft|after=[[Byron Dorgan]]}}
|-
{{s-bef|rows=2|before=[[Carl Levin]]}}
{{s-ttl|title=Ranking Member of the [[United States Senate Committee on Armed Services|Senate Armed Services Committee]]|years=2007–2013}}
{{s-aft|rows=2|after=[[Jim Inhofe]]}}
|-
{{s-ttl|title=Chair of the [[United States Senate Committee on Armed Services|Senate Armed Services Committee]]|years=2015–2018}}
|-
{{s-hon}}
{{s-bef|before=[[Billy Graham]]}}
{{s-ttl|title=Persons who have [[lying in state|lain in state or honor]]&lt;br&gt;in the [[United States Capitol rotunda]]|years=August 31, 2018}}
{{s-aft|after=[[George H. W. Bush]]}}
{{s-end}}

{{John McCain|state=expanded}}
{{Navboxes
|title= Articles related to John McCain
|list1=
{{ArizonaUSRepresentatives}}
{{United States senators from Arizona}}
{{US Senate Indian Affairs chairs}}
{{US Senate Commerce chairs}}
{{US Senate Armed Services chairs}}
{{Republican Party (United States)}}
{{Unsuccessful major party pres candidates}}
{{2000 United States presidential election}}
{{2008 United States presidential election}}
{{Iraq Intelligence Commission}}
{{USCongRep-start|congresses=98th–115th [[United States Congress]]es |state=[[Arizona]]}}
{{USCongRep/AZ/98}}
{{USCongRep/AZ/99}}
{{USCongRep/AZ/100}}
{{USCongRep/AZ/101}}
{{USCongRep/AZ/102}}
{{USCongRep/AZ/103}}
{{USCongRep/AZ/104}}
{{USCongRep/AZ/105}}
{{USCongRep/AZ/106}}
{{USCongRep/AZ/107}}
{{USCongRep/AZ/108}}
{{USCongRep/AZ/109}}
{{USCongRep/AZ/110}}
{{USCongRep/AZ/111}}
{{USCongRep/AZ/112}}
{{USCongRep/AZ/113}}
{{USCongRep/AZ/114}}
{{USCongRep/AZ/115}}
{{USCongRep-end}}
{{Lain in State (USA)|state=collapsed}}
}}
{{Portal bar|Politics|Conservatism|War|Arizona|United States}}
{{Authority control}}

{{DEFAULTSORT:McCain, John}}
[[Category:John McCain| ]]
[[Category:1936 births]]
[[Category:2018 deaths]]
[[Category:20th-century American politicians]]
[[Category:20th-century American non-fiction writers]]
[[Category:21st-century American politicians]]
[[Category:21st-century American non-fiction writers]]
[[Category:21st-century Baptists]]
[[Category:American male non-fiction writers]]
[[Category:American memoirists]]
[[Category:American Vietnam War pilots]]
[[Category:American naval personnel of the Vietnam War]]
[[Category:American people of English descent]]
[[Category:American people of Scotch-Irish descent]]
[[Category:American politicians with physical disabilities]]
[[Category:American torture victims]]
[[Category:Arizona Republicans]]
[[Category:Articles containing video clips]]
[[Category:Aviators from the Panama Canal Zone]]
[[Category:Baptists from Arizona]]
[[Category:Burials at the United States Naval Academy Cemetery]]
[[Category:Commanders of the Order of Ouissam Alaouite]]
[[Category:Deaths from cancer in Arizona]]
[[Category:Deaths from brain tumor]]
[[Category:Episcopal High School (Alexandria, Virginia) alumni]]
[[Category:International Republican Institute]]
[[Category:McCain family]]
[[Category:Members of the United States House of Representatives from Arizona]]
[[Category:National Heroes of Georgia]]
[[Category:Neurological disease deaths in the United States]]
[[Category:People from Colón, Panama]]
[[Category:Politicians who died in office]]
[[Category:Politicians from Phoenix, Arizona]]
[[Category:Recipients of St. George's Order of Victory]]
[[Category:Recipients of the Air Medal]]
[[Category:Recipients of the Distinguished Flying Cross (United States)]]
[[Category:Recipients of the Legion of Merit]]
[[Category:Recipients of the Meritorious Service Medal (United States)]]
[[Category:Recipients of the Order of the Cross of Terra Mariana, 1st Class]]
[[Category:Recipients of the Silver Star]]
[[Category:Republican Party (United States) presidential nominees]]
[[Category:Republican Party members of the United States House of Representatives]]
[[Category:Republican Party United States senators]]
[[Category:Shot-down aviators]]
[[Category:Skin cancer survivors]]
[[Category:Sons of the American Revolution]]
[[Category:United States Naval Academy alumni]]
[[Category:United States Naval Aviators]]
[[Category:United States Navy captains]]
[[Category:Candidates in the 2000 United States presidential election]]
[[Category:Candidates in the 2008 United States presidential election]]
[[Category:United States senators from Arizona]]
[[Category:Vietnam War prisoners of war]]
[[Category:Writers from Arizona]]
[[Category:Zonians]]</text>
      <sha1>rq7wbszu9rc2kg0el76mfzlv33146hp</sha1>
    </revision>
  </page>
  <page>
    <title>Taliban government</title>
    <ns>0</ns>
    <id>43716</id>
    <redirect title="Islamic Emirate of Afghanistan" />
    <revision>
      <id>431907154</id>
      <parentid>92000324</parentid>
      <timestamp>2011-05-31T22:56:51Z</timestamp>
      <contributor>
        <username>Kavas</username>
        <id>7841173</id>
      </contributor>
      <comment>a better redirect?</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="44" xml:space="preserve">#REDIRECT [[Islamic Emirate of Afghanistan]]</text>
      <sha1>2dqqhp0jy1qjc7rzmbdjdio3l6rv1u8</sha1>
    </revision>
  </page>
  <page>
    <title>Prisoner's dilemma</title>
    <ns>0</ns>
    <id>43717</id>
    <revision>
      <id>989713931</id>
      <parentid>989478605</parentid>
      <timestamp>2020-11-20T16:11:17Z</timestamp>
      <contributor>
        <username>Biogeographist</username>
        <id>18201938</id>
      </contributor>
      <comment>/* Further reading */ added citation template with free access indicator</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="71341" xml:space="preserve">{{other uses}}
{{distinguish|Three Prisoners problem}}
{{short description|Canonical example of a game analyzed in game theory}}
{| class=&quot;wikitable floatright&quot;
|+ Prisoner's dilemma payoff matrix
! {{diagonal split header|A|B}}
! B stays&lt;br /&gt;silent
! B&lt;br /&gt;betrays
|-
! A stays&lt;br /&gt;silent
| {{diagonal split header|-1|-1|transparent}}
| {{diagonal split header|-3|0|transparent}}
|-
! A&lt;br /&gt;betrays
| {{diagonal split header|0|-3|transparent}}
| {{diagonal split header|-2|-2|transparent}}
|}
The '''prisoner's dilemma''' is a standard example of a game analyzed in [[game theory]] that shows why two completely [[Rationality#Economics|rational]] individuals might not cooperate, even if it appears that it is in their best interests to do so. It was originally framed by [[Merrill Flood]] and [[Melvin Dresher]] while working at [[RAND Corporation|RAND]] in 1950. [[Albert W. Tucker]] formalized the game with prison sentence rewards and named it &quot;prisoner's dilemma&quot;,{{sfn|Poundstone|1993|pp=8, 117}} presenting it as follows:

{{quote|Two members of a criminal gang are arrested and imprisoned. Each prisoner is in solitary confinement with no means of communicating with the other. The prosecutors lack sufficient evidence to convict the pair on the principal charge, but they have enough to convict both on a lesser charge. Simultaneously, the prosecutors offer each prisoner a bargain. Each prisoner is given the opportunity either to betray the other by testifying that the other committed the crime, or to cooperate with the other by remaining silent. The possible outcomes are:
* If A and B each betray the other, each of them serves two years in prison
* If A betrays B but B remains silent, A will be set free and B will serve three years in prison
* If A remains silent but B betrays A, A will serve three years in prison and B will be set free
* If A and B both remain silent, both of them will serve only one year in prison (on the lesser charge).}}

It is implied that the prisoners will have no opportunity to reward or punish their partner other than the prison sentences they get and that their decision will not affect their reputation in the future. Because betraying a partner offers a greater reward than cooperating with them, all purely rational self-interested prisoners will betray the other, meaning the only possible outcome for two purely rational prisoners is for them to betray each other.&lt;ref&gt;{{cite web|last=Milovsky|first=Nicholas|title=The Basics of Game Theory and Associated Games|url=https://issuu.com/johnsonnick895/docs/game_theory_paper|accessdate=11 February 2014}}&lt;/ref&gt;  In reality, humans display a [[systemic bias]] towards cooperative behavior in this and similar games despite what is predicted by simple models of &quot;rational&quot; self-interested action.&lt;ref name = Fehr&gt;{{cite journal | last1=Fehr | first1= Ernst | last2=Fischbacher | first2=Urs   | date= Oct 23, 2003 | title=The Nature of human altruism |journal=Nature | volume=425 | pages=785–91 | doi=10.1038/nature02043 | url=http://www.iwp.jku.at/born/mpwfst/04/nature02043_f_born.pdf | accessdate=February 27, 2013 | pmid=14574401 | issue=6960|bibcode = 2003Natur.425..785F | s2cid= 4305295 }}&lt;/ref&gt;&lt;ref name = Amos&gt;{{cite book | title=Preference, belief, and similarity: selected writings. | publisher=Massachusetts Institute of Technology Press | first1= Amos | last1=Tversky | first2=Eldar | last2=Shafir | url=http://cseweb.ucsd.edu/~gary/PAPER-SUGGESTIONS/Preference,%20Belief,%20and%20Similarity%20Selected%20Writings%20(Bradford%20Books).pdf  | year=2004 | isbn=9780262700931 | accessdate=February 27, 2013}}&lt;/ref&gt;&lt;ref name=&quot;Ahn&quot;&gt;{{cite journal |last1 = Toh-Kyeong|first1 = Ahn|last2 = Ostrom|first2 = Elinor|last3 = Walker|first3 = James|date = Sep 5, 2002|title = Incorporating Motivational Heterogeneity into Game-Theoretic Models of Collective Action|journal = Public Choice|volume = 117|issue = 3–4|pages = 295–314|doi =10.1023/b:puch.0000003739.54365.fd |url = http://www.indiana.edu/~workshop/seminars/papers/ahnostromwalker_092402.pdf|accessdate = June 27, 2015|hdl = 10535/4697|s2cid = 153414274}}&lt;/ref&gt;&lt;ref name=&quot;Hessel&quot;&gt;{{cite journal|last1 = Oosterbeek|first1 = Hessel|last2 = Sloof|first2 = Randolph|last3 = Van de Kuilen|first3 = Gus|date = Dec 3, 2003|title = Cultural Differences in Ultimatum Game Experiments: Evidence from a Meta-Analysis|journal = Experimental Economics|volume = 7|issue = 2|pages = 171–88|doi = 10.1023/B:EXEC.0000026978.14316.74|s2cid = 17659329|url = http://www.econ.nagoya-cu.ac.jp/~yhamagu/ultimatum.pdf|accessdate = February 27, 2013|url-status = dead|archiveurl = https://web.archive.org/web/20130512175243/http://www.econ.nagoya-cu.ac.jp/~yhamagu/ultimatum.pdf|archivedate = May 12, 2013}}&lt;/ref&gt; This bias towards cooperation has been known since the test was first conducted at RAND; the secretaries involved trusted each other and worked together for the best common outcome.&lt;ref&gt;{{Cite book | url=https://books.google.com/books?id=WIhZlB86nJwC&amp;q=rand+secretaries+prisoner%27s+dilemma&amp;pg=PT96 |title = Why Most Things Fail|isbn = 9780571266142|last1 = Ormerod|first1 = Paul|date = 2010-12-22}}&lt;/ref&gt; The prisoner's dilemma became the focus of extensive experimental research.&lt;ref&gt;Deutsch, M. (1958). Trust and suspicion. Journal of Conflict Resolution, 2(4), 265–279. https://doi.org/10.1177/002200275800200401&lt;/ref&gt;&lt;ref&gt;Rapoport, A., &amp; Chammah, A. M. (1965). Prisoner’s Dilemma: A study of conflict and cooperation. Ann Arbor, MI: University of Michigan Press.&lt;/ref&gt;

An extended &quot;iterated&quot; version of the game also exists. In this version, the classic game is played repeatedly between the same prisoners, who continuously have the opportunity to penalize the other for previous decisions. If the number of times the game will be played is known to the players, then (by [[backward induction]]) two classically rational players will betray each other repeatedly, for the same reasons as the single-shot variant. In an infinite or unknown length game there is no fixed optimum strategy, and prisoner's dilemma tournaments have been held to compete and test algorithms for such cases.&lt;ref&gt;{{cite journal|url = https://egtheory.wordpress.com/2015/03/02/ipd/|title = Short history of iterated prisoner's dilemma tournaments|date = March 2, 2015|access-date = February 8, 2016|journal = Journal of Conflict Resolution|volume = 24|issue = 3|pages = 379–403|last = Kaznatcheev|first = Artem|doi = 10.1177/002200278002400301|s2cid = 145555261}}&lt;/ref&gt;

The prisoner's dilemma game can be used as a model for many [[#Real-life examples|real world situations]] involving cooperative behavior. In casual usage, the label &quot;prisoner's dilemma&quot; may be applied to situations not strictly matching the formal criteria of the classic or iterative games: for instance, those in which two entities could gain important benefits from cooperating or suffer from the failure to do so, but find it difficult or expensive—not necessarily impossible—to coordinate their activities.

==Strategy for the prisoner's dilemma==

Two prisoners are separated into individual rooms and cannot communicate with each other.
The normal game is shown below:

{| class=&quot;wikitable&quot;
|-
! {{diagonal split header|&lt;br /&gt;Prisoner A|Prisoner B}} !! Prisoner B stays silent&lt;br&gt;(''cooperates'') !! Prisoner B betrays&lt;br&gt;(''defects'')
|-
! Prisoner A stays silent&lt;br&gt;(''cooperates'')
| Each serves 1 year|| Prisoner A: 3 years&lt;br /&gt;Prisoner B: goes free
|-
! Prisoner A betrays&lt;br&gt;(''defects'')
| Prisoner A: goes free&lt;br /&gt;Prisoner B: 3 years || Each serves 2 years
|}

It is assumed that both prisoners understand the nature of the game, have no loyalty to each other, and will have no opportunity for retribution or reward outside the game. Regardless of what the other decides, each prisoner gets a higher reward by betraying the other (&quot;defecting&quot;). The reasoning involves an argument by [[Dilemma#Use in logic|dilemma]]: B will either cooperate or defect. If B cooperates, A should defect, because going free is better than serving 1 year. If B defects, A should also defect, because serving 2 years is better than serving 3. So either way, A should defect. Parallel reasoning will show that B should defect.

Because defection always results in a better payoff than cooperation regardless of the other player's choice, it is a [[dominant strategy]]. Mutual defection is the only strong [[Nash equilibrium]] in the game (i.e. the only outcome from which each player could only do worse by unilaterally changing strategy). The dilemma, then, is that mutual cooperation yields a better outcome than mutual defection but is not the rational outcome because the choice to cooperate, from a self-interested perspective, is irrational.

==Generalized form==
The structure of the traditional prisoner's dilemma can be generalized from its original prisoner setting. Suppose that the two players are represented by the colors red and blue, and that each player chooses to either &quot;cooperate&quot; or &quot;defect&quot;.

If both players cooperate, they both receive the reward ''R'' for cooperating. If both players defect, they both receive the punishment payoff ''P''. If Blue defects while Red cooperates, then Blue receives the temptation payoff ''T'', while Red receives the &quot;sucker's&quot; payoff, ''S''. Similarly, if Blue cooperates while Red defects, then Blue receives the sucker's payoff ''S'', while Red receives the temptation payoff ''T''.

This can be expressed in [[Normal-form game|normal form]]:

{| class=&quot;wikitable&quot; style=&quot;text-align:center&quot;
|+ Canonical PD payoff matrix
! {{diagonal split header|{{color|#009|Blue}}|{{color|#900|Red}}}}
! scope=&quot;col&quot; style=&quot;width:60px;&quot; | {{color|#900|Cooperate}}
! scope=&quot;col&quot; style=&quot;width:60px;&quot; | {{color|#900|Defect}}
|-
! scope=&quot;row&quot; style=&quot;width:60px;&quot; | {{color|#009|Cooperate}}
| {{diagonal split header|{{color|#009|''R''}}|{{color|#900|''R''}}|transparent}}
| {{diagonal split header|{{color|#009|''S''}}|{{color|#900|''T''}}|transparent}}
|-
! scope=&quot;row&quot; | {{color|#009|Defect}}
| {{diagonal split header|{{color|#009|''T''}}|{{color|#900|''S''}}|transparent}}
| {{diagonal split header|{{color|#009|''P''}}|{{color|#900|''P''}}|transparent}}
|}

and to be a prisoner's dilemma game in the strong sense, the following condition must hold for the payoffs:

:{{tmath|T &gt; R &gt; P &gt; S}}

The payoff relationship {{tmath|R &gt; P}} implies that mutual cooperation is superior to mutual defection, while the payoff relationships {{tmath|T &gt; R}} and {{tmath|P &gt; S}} imply that defection is the [[dominant strategy]] for both agents.

===Special case: donation game===
The &quot;donation game&quot;&lt;ref name=Hilbe2013&gt;{{cite journal|last=Hilbe|first=Christian |author2=Martin A. Nowak |author3=Karl Sigmund|title=Evolution of extortion in Iterated Prisoner's Dilemma games|journal=PNAS|date=April 2013|volume=110|issue=17|pages=6913–18|doi=10.1073/pnas.1214834110|pmid=23572576 |pmc=3637695 |bibcode=2013PNAS..110.6913H |arxiv=1212.1067}}&lt;/ref&gt; is a form of prisoner's dilemma in which cooperation corresponds to offering the other player a benefit ''b'' at a personal cost ''c'' with ''b'' &gt; ''c''. Defection means offering nothing. The payoff matrix is thus

{| class=&quot;wikitable&quot; style=&quot;text-align:center&quot;
! {{diagonal split header|{{navy (color)|Blue}}|{{color|#900|Red}}}}
! scope=&quot;col&quot; style=&quot;width:60px;&quot; | {{color|#900|Cooperate}}
! scope=&quot;col&quot; style=&quot;width:60px;&quot; | {{color|#900|Defect}}
|-
! scope=&quot;row&quot; style=&quot;width:60px;&quot; | {{color|#009|Cooperate}}
| {{diagonal split header|{{color|#009|''b''&amp;minus;''c''}}|{{color|#900|''b''&amp;minus;''c''}}|transparent}}
| {{diagonal split header|{{color|#009|&amp;minus;''c''}}|{{color|#900|''b''}}|transparent}}
|-
! scope=&quot;row&quot; | {{color|#009|Defect}}
| {{diagonal split header|{{color|#009|''b''}}|{{color|#900|&amp;minus;''c''}}|transparent}}
| {{diagonal split header|{{color|#009|0}}|{{color|#900|0}}|transparent}}
|}

Note that {{tmath|2R&gt;T+S}} (i.e. {{tmath|2(b-c)&gt;b-c}}) which qualifies the donation game to be an iterated game (see next section).

The donation game may be applied to markets. Suppose X grows oranges, Y grows apples. The [[marginal utility]] of an apple to the orange-grower X is ''b'', which is higher than the marginal utility (''c'') of an orange, since X has a surplus of oranges and no apples. Similarly, for apple-grower Y, the marginal utility of an orange is ''b'' while the marginal utility of an apple is ''c''. If X and Y contract to exchange an apple and an orange, and each fulfills their end of the deal, then each receive a payoff of ''b''-''c''. If one &quot;defects&quot; and does not deliver as promised, the defector will receive a payoff of ''b'', while the cooperator will lose ''c''. If both defect, then neither one gains or loses anything.

==The iterated prisoner's dilemma==
{{more citations needed section|date=November 2012}}
If two players play prisoner's dilemma more than once in succession and they remember previous actions of their opponent and change their strategy accordingly, the game is called iterated prisoner's dilemma.

In addition to the general form above, the iterative version also requires that {{tmath|2R &gt; T + S}}, to prevent alternating cooperation and defection giving a greater reward than mutual cooperation.

The iterated prisoner's dilemma game is fundamental to some theories of human cooperation and trust. On the assumption that the game can model transactions between two people requiring trust, cooperative behaviour in populations may be modeled by a multi-player, iterated, version of the game. It has, consequently, fascinated many scholars over the years. In 1975, Grofman and Pool estimated the count of scholarly articles devoted to it at over 2,000. The iterated prisoner's dilemma has also been referred to as the &quot;[[Peace war game|peace-war game]]&quot;.&lt;ref name = Shy&gt;{{cite book | title= Industrial Organization: Theory and Applications | publisher=Massachusetts Institute of Technology Press | first1= Oz | last1=Shy |url=https://books.google.com/books?id=tr4CjJ5LlRcC&amp;q=industrial+organization+theory+and+applications&amp;pg=PR13  | year=1995 | isbn=978-0262193665 | accessdate=February 27, 2013}}&lt;/ref&gt;

If the game is played exactly ''N'' times and both players know this, then it is optimal to defect in all rounds. The only possible [[Nash equilibrium]] is to always defect. The proof is [[Mathematical induction|inductive]]: one might as well defect on the last turn, since the opponent will not have a chance to later retaliate. Therefore, both will defect on the last turn. Thus, the player might as well defect on the second-to-last turn, since the opponent will defect on the last no matter what is done, and so on.  The same applies if the game length is unknown but has a known upper limit.

Unlike the standard prisoner's dilemma, in the iterated prisoner's dilemma the defection strategy is counter-intuitive and fails badly to predict the behavior of human players. Within standard economic theory, though, this is the only correct answer.  The [[superrational]] strategy in the iterated prisoner's dilemma with fixed ''N'' is to cooperate against a superrational opponent, and in the limit of large ''N'', experimental results on strategies agree with the superrational version, not the game-theoretic rational one.

For [[cooperation]] to emerge between game theoretic rational players, the total number of rounds ''N'' must be unknown to the players. In this case &quot;always defect&quot; may no longer be a strictly dominant strategy, only a Nash equilibrium. Amongst results shown by [[Robert Aumann]] in a 1959 paper, rational players repeatedly interacting for indefinitely long games can sustain the cooperative outcome.

According to a 2019 experimental study in the ''American Economic Review'' which tested what strategies real-life subjects used in iterated prisoners' dilemma situations with perfect monitoring, the majority of chosen strategies were always defect, [[Tit for tat|tit-for-tat]], and [[grim trigger]]. Which strategy the subjects chose depended on the parameters of the game.&lt;ref&gt;{{Cite journal|last1=Dal Bó|first1=Pedro|last2=Fréchette|first2=Guillaume R.|date=2019|title=Strategy Choice in the Infinitely Repeated Prisoner's Dilemma|journal=American Economic Review|language=en|volume=109|issue=11|pages=3929–3952|doi=10.1257/aer.20181480|issn=0002-8282}}&lt;/ref&gt;

===Strategy for the iterated prisoner's dilemma===
Interest in the iterated prisoner's dilemma (IPD) was kindled by [[Robert Axelrod]] in his book ''[[The Evolution of Cooperation]]'' (1984). In it he reports on a tournament he organized of the ''N'' step prisoner's dilemma (with ''N'' fixed) in which participants have to choose their mutual strategy again and again, and have memory of their previous encounters. Axelrod invited academic colleagues all over the world to devise computer strategies to compete in an IPD tournament. The programs that were entered varied widely in algorithmic complexity, initial hostility, capacity for forgiveness, and so forth.

Axelrod discovered that when these encounters were repeated over a long period of time with many players, each with different strategies, greedy strategies tended to do very poorly in the long run while more [[altruism|altruistic]] strategies did better, as judged purely by self-interest. He used this to show a possible mechanism for the evolution of altruistic behaviour from mechanisms that are initially purely selfish, by [[natural selection]].

The winning [[deterministic algorithm|deterministic]] strategy was tit for tat, which [[Anatol Rapoport]] developed and entered into the tournament. It was the simplest of any program entered, containing only four lines of [[BASIC]], and won the contest. The strategy is simply to cooperate on the first iteration of the game; after that, the player does what his or her opponent did on the previous move. Depending on the situation, a slightly better strategy can be &quot;tit for tat with forgiveness&quot;. When the opponent defects, on the next move, the player sometimes cooperates anyway, with a small probability (around 1–5%). This allows for occasional recovery from getting trapped in a cycle of defections. The exact probability depends on the line-up of opponents.

By analysing the top-scoring strategies, Axelrod stated several conditions necessary for a strategy to be successful.

; Nice: The most important condition is that the strategy must be &quot;nice&quot;, that is, it will not defect before its opponent does (this is sometimes referred to as an &quot;optimistic&quot; algorithm). Almost all of the top-scoring strategies were nice; therefore, a purely selfish strategy will not &quot;cheat&quot; on its opponent, for purely self-interested reasons first.
; Retaliating: However, Axelrod contended, the successful strategy must not be a blind optimist. It must sometimes retaliate. An example of a non-retaliating strategy is Always Cooperate. This is a very bad choice, as &quot;nasty&quot; strategies will ruthlessly exploit such players.
; Forgiving: Successful strategies must also be forgiving. Though players will retaliate, they will once again fall back to cooperating if the opponent does not continue to defect. This stops long runs of revenge and counter-revenge, maximizing points.
; Non-envious: The last quality is being non-envious, that is not striving to score more than the opponent.

The optimal (points-maximizing) strategy for the one-time PD game is simply defection; as explained above, this is true whatever the composition of opponents may be. However, in the iterated-PD game the optimal strategy depends upon the strategies of likely opponents, and how they will react to defections and cooperations. For example, consider a population where everyone defects every time, except for a single individual following the tit for tat strategy. That individual is at a slight disadvantage because of the loss on the first turn. In such a population, the optimal strategy for that individual is to defect every time. In a population with a certain percentage of always-defectors and the rest being tit for tat players, the optimal strategy for an individual depends on the percentage, and on the length of the game.

In the strategy called Pavlov, [[win-stay, lose-switch]], faced with a failure to cooperate, the player switches strategy the next turn.&lt;ref&gt;{{cite journal |last1=Wedekind |first1=C. |last2=Milinski |first2=M. |title=Human cooperation in the simultaneous and the alternating Prisoner's Dilemma: Pavlov versus Generous Tit-for-Tat |journal=Proceedings of the National Academy of Sciences |date=2 April 1996 |volume=93 |issue=7 |pages=2686–2689 |doi=10.1073/pnas.93.7.2686 |pmid=11607644 |pmc=39691 }}&lt;/ref&gt; In certain circumstances,{{specify|date=November 2012}} Pavlov beats all other strategies by giving preferential treatment to co-players using a similar strategy.

Deriving the optimal strategy is generally done in two ways:
* [[Bayesian Nash equilibrium]]: If the statistical distribution of opposing strategies can be determined (e.g. 50% tit for tat, 50% always cooperate) an optimal counter-strategy can be derived analytically.{{efn|1=For example see the 2003 study&lt;ref&gt;{{cite web|url= http://econ.hevra.haifa.ac.il/~mbengad/seminars/whole1.pdf|title=Bayesian Nash equilibrium; a statistical test of the hypothesis|url-status=dead|archive-url= https://web.archive.org/web/20051002195142/http://econ.hevra.haifa.ac.il/~mbengad/seminars/whole1.pdf|archive-date=2005-10-02|publisher=[[Tel Aviv University]]}}&lt;/ref&gt; for discussion of the concept and whether it can apply in real [[economic]] or strategic situations.}}
* [[Monte Carlo method|Monte Carlo]] simulations of populations have been made, where individuals with low scores die off, and those with high scores reproduce (a [[genetic algorithm]] for finding an optimal strategy). The mix of algorithms in the final population generally depends on the mix in the initial population. The introduction of mutation (random variation during reproduction) lessens the dependency on the initial population; empirical experiments with such systems tend to produce tit for tat players (see for instance Chess 1988),{{Clarify|date=August 2016}} but no analytic proof exists that this will always occur.&lt;ref&gt;{{Citation|last1=Wu|first1=Jiadong|title=Cooperation on the Monte Carlo Rule: Prisoner's Dilemma Game on the Grid|date=2019|work=Theoretical Computer Science|volume=1069|pages=3–15|editor-last=Sun|editor-first=Xiaoming|publisher=Springer Singapore|language=en|doi=10.1007/978-981-15-0105-0_1|isbn=978-981-15-0104-3|last2=Zhao|first2=Chengye|s2cid=118687103|editor2-last=He|editor2-first=Kun|editor3-last=Chen|editor3-first=Xiaoyun}}&lt;/ref&gt;

Although tit for tat is considered to be the most [[robust]] basic strategy, a team from [[Southampton University]] in England introduced a new strategy at the 20th-anniversary iterated prisoner's dilemma competition, which proved to be more successful than tit for tat. This strategy relied on collusion between programs to achieve the highest number of points for a single program. The university submitted 60 programs to the competition, which were designed to recognize each other through a series of five to ten moves at the start.&lt;ref&gt;{{cite press release|url= http://www.southampton.ac.uk/mediacentre/news/2004/oct/04_151.shtml|publisher=University of Southampton|title=University of Southampton team wins Prisoner's Dilemma competition|date=7 October 2004|url-status=dead|archive-url= https://web.archive.org/web/20140421055745/http://www.southampton.ac.uk/mediacentre/news/2004/oct/04_151.shtml|archive-date=2014-04-21}}&lt;/ref&gt; Once this recognition was made, one program would always cooperate and the other would always defect, assuring the maximum number of points for the defector. If the program realized that it was playing a non-Southampton player, it would continuously defect in an attempt to minimize the score of the competing program. As a result, the 2004 Prisoners' Dilemma Tournament results show [[University of Southampton]]'s strategies in the first three places, despite having fewer wins and many more losses than the GRIM strategy. (In a PD tournament, the aim of the game is not to &quot;win&quot; matches&amp;nbsp;– that can easily be achieved by frequent defection). Also, even without implicit collusion between [[computer program|software strategies]] (exploited by the Southampton team) tit for tat is not always the absolute winner of any given tournament; it would be more precise to say that its long run results over a series of tournaments outperform its rivals. (In any one event a given strategy can be slightly better adjusted to the competition than tit for tat, but tit for tat is more robust). The same applies for the tit for tat with forgiveness variant, and other optimal strategies: on any given day they might not &quot;win&quot; against a specific mix of counter-strategies. An alternative way of putting it is using the Darwinian [[Evolutionarily stable strategy|ESS]] simulation. In such a simulation, tit for tat will almost always come to dominate, though nasty strategies will drift in and out of the population because a tit for tat population is penetrable by non-retaliating nice strategies, which in turn are easy prey for the nasty strategies. [[Richard Dawkins]] showed that here, no static mix of strategies form a stable equilibrium and the system will always oscillate between bounds.}} this strategy ended up taking the top three positions in the competition, as well as a number of positions towards the bottom.

This strategy takes advantage of the fact that multiple entries were allowed in this particular competition and that the performance of a team was measured by that of the highest-scoring player (meaning that the use of self-sacrificing players was a form of [[minmaxing]]). In a competition where one has control of only a single player, tit for tat is certainly a better strategy. Because of this new rule, this competition also has little theoretical significance when analyzing single agent strategies as compared to Axelrod's seminal tournament. However, it provided a basis for analysing how to achieve cooperative strategies in multi-agent frameworks, especially in the presence of noise. In fact, long before this new-rules tournament was played, Dawkins, in his book ''[[The Selfish Gene]]'', pointed out the possibility of such strategies winning if multiple entries were allowed, but he remarked that most probably Axelrod would not have allowed them if they had been submitted. It also relies on circumventing rules about the prisoner's dilemma in that there is no communication allowed between the two players, which the Southampton programs arguably did with their opening &quot;ten move dance&quot; to recognize one another; this only reinforces just how valuable communication can be in shifting the balance of the game.

===Stochastic iterated prisoner's dilemma===

In a stochastic iterated prisoner's dilemma game, strategies are specified by in terms of &quot;cooperation probabilities&quot;.&lt;ref name=Press2012&gt;{{cite journal|last1=Press|first1=WH|last2=Dyson|first2=FJ|title=Iterated Prisoner's Dilemma contains strategies that dominate any evolutionary opponent|journal=[[Proceedings of the National Academy of Sciences of the United States of America]]|date=26 June 2012|volume=109|issue=26|pages=10409–13|doi=10.1073/pnas.1206569109|pmid=22615375|pmc=3387070|bibcode=2012PNAS..10910409P}}&lt;/ref&gt; In an encounter between player ''X'' and player ''Y'', ''X'' 's strategy is specified by a set of probabilities ''P'' of cooperating with ''Y''. ''P'' is a function of the outcomes of their previous encounters or some subset thereof. If ''P'' is a function of only their most recent ''n'' encounters, it is called a &quot;memory-n&quot; strategy. A memory-1 strategy is then specified by four cooperation probabilities:  &lt;math&gt;P=\{P_{cc},P_{cd},P_{dc},P_{dd}\}&lt;/math&gt;, where &lt;math&gt;P_{ab}&lt;/math&gt; is the probability that ''X'' will cooperate in the present encounter given that the previous encounter was characterized by (ab). For example, if the previous encounter was one in which ''X'' cooperated and ''Y'' defected, then &lt;math&gt;P_{cd}&lt;/math&gt; is the probability that ''X'' will cooperate in the present encounter. If each of the probabilities are either 1 or 0, the strategy is called deterministic. An example of a deterministic strategy is the tit for tat strategy written as ''P''={1,0,1,0}, in which ''X'' responds as ''Y'' did in the previous encounter. Another is the [[win–stay, lose–switch]] strategy written as ''P''={1,0,0,1}, in which ''X'' responds as in the previous encounter, if it was a &quot;win&quot; (i.e. cc or dc) but changes strategy if it was a loss (i.e. cd or dd). It has been shown that for any memory-n strategy there is a corresponding memory-1 strategy which gives the same statistical results, so that only memory-1 strategies need be considered.&lt;ref name=&quot;Press2012&quot;/&gt;
