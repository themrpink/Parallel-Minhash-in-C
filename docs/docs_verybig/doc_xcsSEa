{{Authority control}}

[[Category:Digital electronics]]
[[Category:Logic families]]</text>
      <sha1>16qr3vpfzz2ga6rpwx0mtfzgxhlosjw</sha1>
    </revision>
  </page>
  <page>
    <title>TTL</title>
    <ns>0</ns>
    <id>47770</id>
    <revision>
      <id>927462484</id>
      <parentid>897349574</parentid>
      <timestamp>2019-11-22T17:29:31Z</timestamp>
      <contributor>
        <username>Nick Number</username>
        <id>1526960</id>
      </contributor>
      <comment>style fixes per [[MOS:DAB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="917" xml:space="preserve">{{Wiktionary|TTL|Ttl|ttl}}
'''TTL''' may refer to:
{{ToC right}}

==Photography==
* [[Through-the-lens metering]], a camera feature that permits light metering through the taking lens itself, rather than via a separate window
* [[Zenit TTL]], an SLR film camera, named for its introduction of TTL metering to the Zenit camera line

==Technology==
* [[Time to live]], a mechanism that limits the lifespan of data in a computer or network
* [[Transistor–transistor logic]], a family of integrated-circuit digital logic
** [[Differential TTL]], a serial signaling standard based on a transistor–transistor logic interface
* [[Turtle (syntax)]], a computer data format used in semantic web technologies

==Other uses==
* [[Taiwan Tobacco and Liquor]], a state-owned manufacturer of cigarettes and alcohol
* &quot;[[TTL (Time to Love)]]&quot;, a single by South Korean girl group T-ara and boy band Supernova

{{Disambiguation}}</text>
      <sha1>ss1q41sssrj4kpniu9gk1k7w38s7bff</sha1>
    </revision>
  </page>
  <page>
    <title>Roman curia</title>
    <ns>0</ns>
    <id>47771</id>
    <redirect title="Roman Curia" />
    <revision>
      <id>783876580</id>
      <parentid>177480108</parentid>
      <timestamp>2017-06-05T06:07:20Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor />
      <comment>+{{Redirect category shell}} using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="90" xml:space="preserve">#REDIRECT [[Roman Curia]]

{{Redirect category shell|1=
{{R from other capitalisation}}
}}</text>
      <sha1>o0fkfyzgvi2f5z0nbpeztl8euhhe1rs</sha1>
    </revision>
  </page>
  <page>
    <title>Instruction set architecture</title>
    <ns>0</ns>
    <id>47772</id>
    <revision>
      <id>991135711</id>
      <parentid>989363253</parentid>
      <timestamp>2020-11-28T13:08:52Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor />
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 10 templates: del empty params (1×); hyphenate params (5×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="31993" xml:space="preserve">{{short description|Set of abstract symbols which describe a computer program's operations to a processor}}
{{distinguish|Industry Standard Architecture}}
{{Machine code}}

In [[computer science]], an '''instruction set architecture''' ('''ISA''') is an [[abstract model]] of a [[computer]]. It is also referred to as '''architecture''' or '''computer architecture'''. A realization of an ISA, such as a [[central processing unit]] (CPU), is called an ''implementation''. 

In general, an ISA defines the supported [[data type]]s, the [[Register (computer)|registers]], the hardware support for managing [[Random-access memory|main memory]], fundamental features (such as the [[memory consistency]], [[addressing mode]]s, [[virtual memory]]), and the [[input/output]] model of a family of implementations of the ISA.

An ISA specifies the behavior of [[machine code]] running on implementations of that ISA in a fashion that does not depend on the characteristics of that implementation, providing [[binary compatibility]] between implementations. This enables multiple implementations of an ISA that differ in [[Computer performance|performance]], physical size, and monetary cost (among other things), but that are capable of running the same machine code, so that a lower-performance, lower-cost machine can be replaced with a higher-cost, higher-performance machine without having to replace software.  It also enables the evolution of the [[microarchitecture]]s of the implementations of that ISA, so that a newer, higher-performance implementation of an ISA can run software that runs on previous generations of implementations.

If an [[operating system]] maintains a standard and compatible [[application binary interface]] (ABI) for a particular ISA, machine code for that ISA and operating system will run on future implementations of that ISA and newer versions of that operating system.  However, if an ISA supports running multiple operating systems, it does not guarantee that machine code for one operating system will run on another operating system, unless the first operating system supports running machine code built for the other operating system.

An ISA can be extended by adding instructions or other capabilities, or adding support for larger addresses and data values; an implementation of the extended ISA will still be able to execute machine code for versions of the ISA without those extensions.  Machine code using those extensions will only run on implementations that support those extensions.

The binary compatibility that they provide make ISAs one of the most fundamental abstractions in [[computing]].

==Overview==
An instruction set architecture is distinguished from a [[microarchitecture]], which is the set of [[processor design]] techniques used, in a particular processor, to implement the instruction set. Processors with different microarchitectures can share a common instruction set. For example, the [[Intel]] [[P5 (microarchitecture)|Pentium]] and the [[Advanced Micro Devices]] [[Athlon]] implement nearly identical versions of the [[x86 instruction set]], but have radically different internal designs.

The concept of an ''architecture'', distinct from the design of a specific machine, was developed by [[Fred Brooks]] at IBM during the design phase of [[System/360]]. {{quote|Prior to NPL [System/360], the company's computer designers had been free to honor cost objectives not only by selecting technologies but also by fashioning functional and architectural refinements. The SPREAD compatibility objective, in contrast, postulated a single architecture for a series of five processors spanning a wide range of cost and performance. None of the five engineering design teams could count on being able to bring about adjustments in architectural specifications as a way of easing difficulties in achieving cost and performance objectives.&lt;ref name=Pugh&gt;{{cite book|last1=Pugh|first1=Emerson W.|last2=Johnson|first2=Lyle R.|last3=Palmer|first3=John H.|title=IBM's 360 and Early 370 Systems|url=https://archive.org/details/ibms360early370s0000pugh|url-access=registration|year=1991|publisher=MIT Press|isbn=0-262-16123-0}}&lt;/ref&gt;{{rp|p.137}}}}

Some [[virtual machine]]s that support [[bytecode]] as their ISA such as [[Smalltalk]], the [[Java virtual machine]], and [[Microsoft]]'s [[Common Language Runtime]], implement this by translating the bytecode for commonly used code paths into native machine code. In addition, these virtual machines execute less frequently used code paths by interpretation (see: [[Just-in-time compilation]]). [[Transmeta]] implemented the x86 instruction set atop [[VLIW]] processors in this fashion.

==Classification of ISAs==
An ISA may be classified in a number of different ways. A common classification is by architectural ''complexity''. A [[complex instruction set computer]] (CISC) has many specialized instructions, some of which may only be rarely used in practical programs. A [[reduced instruction set computer]] (RISC) simplifies the processor by efficiently implementing only the instructions that are frequently used in programs, while the less common operations are implemented as subroutines, having their resulting additional processor execution time offset by infrequent use.&lt;ref&gt;{{cite web
|url= http://cs.stanford.edu/people/eroberts/courses/soco/projects/risc/risccisc/
|title= RISC Architecture: RISC vs. CISC
|date= December 16, 2006 |access-date= February 21, 2015
|author1= Crystal Chen |author2= Greg Novick |author3= Kirk Shimano
|website= cs.stanford.edu
}}&lt;/ref&gt;

Other types include [[very long instruction word]] (VLIW) architectures, and the closely related ''long instruction word'' (LIW) and ''[[explicitly parallel instruction computing]]'' (EPIC) architectures. These architectures seek to exploit [[instruction-level parallelism]] with less hardware than RISC and CISC by making the [[compiler]] responsible for instruction issue and scheduling.

Architectures with even less complexity have been studied, such as the [[minimal instruction set computer]] (MISC) and [[one instruction set computer]] (OISC). These are theoretically important types, but have not been commercialized.

==&lt;span id=&quot;NATIVE&quot;&gt;&lt;/span&gt;Instructions==
[[Machine_code|Machine language]] is built up from discrete ''statements'' or ''instructions''. On the processing architecture, a given instruction may specify:

*particular [[processor register|registers]] (for arithmetic, addressing, or control functions)
*particular memory locations (or offsets to them)
*particular [[addressing mode]]s (used to interpret the operands)

More complex operations are built up by combining these simple instructions, which are executed sequentially, or as otherwise directed by [[control flow]] instructions.

===Instruction types===
Examples of operations common to many instruction sets include:

====Data handling and memory operations====
*''Set'' a [[Processor register|register]] to a fixed constant value.
*''Copy'' data from a memory location to a register, or vice versa (a machine instruction is often called ''move''; however, the term is misleading). Used to store the contents of a register, the result of a computation, or to retrieve stored data to perform a computation on it later. Often called [[load and store]] operations.
*''Read'' and ''write'' data from hardware devices.

====[[Arithmetic logic unit|Arithmetic and logic]] operations====
*''Add'', ''subtract'', ''multiply'', or ''divide'' the values of two registers, placing the result in a register, possibly setting one or more [[flag (computing)|condition codes]] in a [[status register]].
**''{{vanchor|increment}}'', ''{{vanchor|decrement}}'' in some ISAs, saving operand fetch in trivial cases.
*Perform [[bitwise operation]]s, e.g., taking the ''[[logical conjunction|conjunction]]'' and ''[[logical disjunction|disjunction]]'' of corresponding bits in a pair of registers, taking the ''[[logical negation|negation]]'' of each bit in a register.
*''Compare'' two values in registers (for example, to see if one is less, or if they are equal).
*''{{vanchor|Floating-point instruction}}s'' for arithmetic on floating-point numbers.

====[[Control flow]] operations====
*''[[Branch (computer science)|Branch]]'' to another location in the program and execute instructions there.
*''[[Branch predication|Conditionally branch]]'' to another location if a certain condition holds.
*''[[Indirect branch|Indirectly branch]]'' to another location.
*''[[Subroutine|Call]]'' another block of code, while saving the location of the next instruction as a point to return to.

====[[Coprocessor]] instructions====
*Load/store data to and from a coprocessor or exchanging with CPU registers.
*Perform coprocessor operations.

===Complex instructions===
Processors may include &quot;complex&quot; instructions in their instruction set. A single &quot;complex&quot; instruction does something that may take many instructions on other computers. {{Citation needed|date=October 2012}} Such instructions are [[typified]] by instructions that take multiple steps, control multiple functional units, or otherwise appear on a larger scale than the bulk of simple instructions implemented by the given processor. Some examples of &quot;complex&quot; instructions include:

*transferring multiple registers to or from memory (especially the [[Call stack|stack]]) at once
*moving large blocks of memory (e.g. [[string copy]] or [[DMA transfer]])
*complicated integer and floating-point arithmetic (e.g. [[square root]], or [[transcendental function]]s such as [[logarithm]], [[sine]], [[cosine]], etc.)
*''{{vanchor|[[SIMD]] instruction|SIMD instruction}}s'', a single instruction performing an operation on many homogeneous values in parallel, possibly in dedicated [[SIMD register]]s
*performing an atomic [[test-and-set]] instruction or other [[read-modify-write]] [[atomic instruction]]
*instructions that perform [[arithmetic logic unit|ALU]] operations with an operand from memory rather than a register

Complex instructions are more common in CISC instruction sets than in RISC instruction sets, but RISC instruction sets may include them as well. RISC instruction sets generally do not include ALU operations with memory operands, or instructions to move large blocks of memory, but most RISC instruction sets include [[SIMD]] or [[vector processing|vector]] instructions that perform the same arithmetic operation on multiple pieces of data at the same time. SIMD instructions have the ability of manipulating large vectors and matrices in minimal time. SIMD instructions allow easy [[parallelization]] of algorithms commonly involved in sound, image, and video processing. Various SIMD implementations have been brought to market under trade names such as [[MMX (instruction set)|MMX]], [[3DNow!]], and [[AltiVec]].

{{Anchor|Parts of an instruction}}

===Instruction encoding===
[[File:Mips32 addi.svg|thumb|right|upright=1.7|One instruction may have several fields, which identify the logical operation, and may also include source and destination addresses and constant values. This is the MIPS &quot;Add Immediate&quot; instruction, which allows selection of source and destination registers and inclusion of a small constant.]]

On traditional architectures, an instruction includes an [[opcode]] that specifies the operation to perform, such as ''add contents of memory to register''—and zero or more [[operand]] specifiers, which may specify [[processor register|registers]], memory locations, or literal data. The operand specifiers may have [[addressing mode]]s determining their meaning or may be in fixed fields. In [[very long instruction word]] (VLIW) architectures, which include many [[microcode]] architectures, multiple simultaneous opcodes and operands are specified in a single instruction.

Some exotic instruction sets do not have an opcode field, such as [[transport triggered architecture]]s (TTA), only operand(s).

The [[Forth virtual machine]] and other &quot;[[0-operand instruction set|0-operand]]&quot; instruction sets lack any operand specifier fields, such as some [[stack machine]]s including NOSC.&lt;ref&gt;{{cite web |url=http://strangegizmo.com/forth/NOSC/ |title=Forth Resources: NOSC Mail List Archive |website=strangegizmo.com |access-date=2014-07-25 |archive-url=https://web.archive.org/web/20140520053227/http://www.strangegizmo.com/forth/NOSC/ |archive-date=2014-05-20 |url-status=dead }}&lt;/ref&gt;{{Better source|reason=Not reliable. Just some random mailing list.|date=July 2014}}

&lt;!-- A conditional branch that falls though may still have other effects, e.g., decrementing a count register. --&gt;
Conditional instructions often have a predicate field—a few bits that encode the specific condition to cause an operation to be performed rather than not performed. For example, a conditional branch instruction will transfer control if the condition is true, so that execution proceeds to a different part of the program, and not transfer control if the condition is false, so that execution continues sequentially. Some instruction sets also have conditional moves, so that the move will be executed, and the data stored in the target location, if the condition is true, and not executed, and the target location not modified, if the condition is false. Similarly, IBM [[z/Architecture]] has a conditional store instruction. A few instruction sets include a predicate field in every instruction; this is called [[branch predication]].

====Number of operands====
Instruction sets may be categorized by the maximum number of operands ''explicitly'' specified in instructions.

(In the examples that follow, ''a'', ''b'', and ''c'' are (direct or calculated) addresses referring to memory cells, while ''reg1'' and so on refer to machine registers.)

 C = A+B

*0-operand (''zero-address machines''), so called [[stack machine]]s: All arithmetic operations take place using the top one or two positions on the stack: &lt;code&gt;push a&lt;/code&gt;, &lt;code&gt;push b&lt;/code&gt;, &lt;code&gt;add&lt;/code&gt;, &lt;code&gt;pop c&lt;/code&gt;.
**&lt;code&gt;C = A+B&lt;/code&gt; needs ''four instructions''. For stack machines, the terms &quot;0-operand&quot; and &quot;zero-address&quot; apply to arithmetic instructions, but not to all instructions, as 1-operand push and pop instructions are used to access memory.
*1-operand (''one-address machines''), so called [[accumulator machine]]s, include early computers and many small [[microcontroller]]s: most instructions specify a single right operand (that is, constant, a register, or a memory location), with the implicit [[accumulator (computing)|accumulator]] as the left operand (and the destination if there is one): &lt;code&gt;load a&lt;/code&gt;, &lt;code&gt;add b&lt;/code&gt;, &lt;code&gt;store c&lt;/code&gt;.
**&lt;code&gt;C = A+B&lt;/code&gt; needs ''three instructions''.
*2-operand — many CISC and RISC machines fall under this category:
**CISC — &lt;code&gt;move A&lt;/code&gt; to ''C''; then &lt;code&gt;add B&lt;/code&gt; to ''C''.
***&lt;code&gt;C = A+B&lt;/code&gt; needs ''two instructions''. This effectively 'stores' the result without an explicit ''store'' instruction.
**CISC — Often machines are [https://web.archive.org/web/20131105155703/http://cs.smith.edu/~thiebaut/ArtOfAssembly/CH04/CH04-3.html#HEADING3-79 limited to one memory operand] per instruction: &lt;code&gt;load a,reg1&lt;/code&gt;; &lt;code&gt;add b,reg1&lt;/code&gt;; &lt;code&gt;store reg1,c&lt;/code&gt;; This requires a load/store pair for any memory movement regardless of whether the &lt;code&gt;add&lt;/code&gt; result is an augmentation stored to a different place, as in &lt;code&gt;C = A+B&lt;/code&gt;, or the same memory location: &lt;code&gt;A = A+B&lt;/code&gt;.
***&lt;code&gt;C = A+B&lt;/code&gt; needs ''three instructions''.
**RISC — Requiring explicit memory loads, the instructions would be: &lt;code&gt;load a,reg1&lt;/code&gt;; &lt;code&gt;load b,reg2&lt;/code&gt;; &lt;code&gt;add reg1,reg2&lt;/code&gt;; &lt;code&gt;store reg2,c&lt;/code&gt;.
***&lt;code&gt;C = A+B&lt;/code&gt; needs ''four instructions''.
*3-operand, allowing better reuse of data:&lt;ref name=Cocke &gt;
[http://domino.watson.ibm.com/tchjr/journalindex.nsf/0/22d06c5aa961e78085256bfa0067fa93?OpenDocument The evolution of RISC technology at IBM by John Cocke] &amp;ndash; IBM Journal of R&amp;D, Volume 44, Numbers 1/2, p.48 (2000)
&lt;/ref&gt;
**CISC — It becomes either a single instruction: &lt;code&gt;add a,b,c&lt;/code&gt;
***&lt;code&gt;C = A+B&lt;/code&gt; needs ''one instruction''.
**CISC — Or, on machines limited to two memory operands per instruction, &lt;code&gt;move a,reg1&lt;/code&gt;; &lt;code&gt;add reg1,b,c&lt;/code&gt;;
***&lt;code&gt;C = A+B&lt;/code&gt; needs ''two instructions''.
**RISC — arithmetic instructions use registers only, so explicit 2-operand load/store instructions are needed: &lt;code&gt;load a,reg1&lt;/code&gt;; &lt;code&gt;load b,reg2&lt;/code&gt;; &lt;code&gt;add reg1+reg2-&gt;reg3&lt;/code&gt;; &lt;code&gt;store reg3,c&lt;/code&gt;;
***&lt;code&gt;C = A+B&lt;/code&gt; needs ''four instructions''.
***Unlike 2-operand or 1-operand, this leaves all three values a, b, and c in registers available for further reuse.&lt;ref name=Cocke/&gt;
*more operands—some CISC machines permit a variety of addressing modes that allow more than 3 operands (registers or memory accesses), such as the [[VAX]] &quot;POLY&quot; polynomial evaluation instruction.

Due to the large number of bits needed to encode the three registers of a 3-operand instruction, RISC architectures that have 16-bit instructions are invariably 2-operand designs, such as the Atmel AVR, [[TI MSP430]], and some versions of [[ARM Thumb]]. RISC architectures that have 32-bit instructions are usually 3-operand designs, such as the [[ARM architecture|ARM]], [[AVR32]], [[MIPS architecture|MIPS]], [[Power ISA]], and [[SPARC]] architectures.

Each instruction specifies some number of operands (registers, memory locations, or immediate values) ''explicitly''. Some instructions give one or both operands implicitly, such as by being stored on top of the [[stack (data structure)|stack]] or in an implicit register. If some of the operands are given implicitly, fewer operands need be specified in the instruction. When a &quot;destination operand&quot; explicitly specifies the destination, an additional operand must be supplied. Consequently, the number of operands encoded in an instruction may differ from the mathematically necessary number of arguments for a logical or arithmetic operation (the [[arity]]). Operands are either encoded in the &quot;opcode&quot; representation of the instruction, or else are given as values or addresses following the opcode.

==={{Anchor|REGISTER-PRESSURE}}Register pressure===
''Register pressure'' measures the availability of free registers at any point in time during the program execution. Register pressure is high when a large number of the available registers are in use; thus, the higher the register pressure, the more often the register contents must be [[register spilling|spilled]] into memory. Increasing the number of registers in an architecture decreases register pressure but increases the cost.&lt;ref&gt;{{cite book |last=Page |first=Daniel |title=A Practical Introduction to Computer Architecture |chapter=11. Compilers |year=2009 |publisher=Springer |isbn=978-1-84882-255-9 |page=464|bibcode=2009pica.book.....P }}&lt;/ref&gt;

While embedded instruction sets such as [[ARM Thumb|Thumb]] suffer from extremely high register pressure because they have small register sets, general-purpose RISC ISAs like [[MIPS architecture|MIPS]] and [[DEC Alpha|Alpha]] enjoy low register pressure. CISC ISAs like x86-64 offer low register pressure despite having smaller register sets. This is due to the many addressing modes and optimizations (such as sub-register addressing, memory operands in ALU instructions, absolute addressing, PC-relative addressing, and register-to-register spills) that CISC ISAs offer.&lt;ref&gt;{{cite conference |last1=Venkat |first1=Ashish |last2=Tullsen |first2=Dean M. |title=Harnessing ISA Diversity: Design of a Heterogeneous-ISA Chip Multiprocessor |year=2014 |conference=41st Annual International Symposium on Computer Architecture |url=http://dl.acm.org/citation.cfm?id=2665692}}&lt;/ref&gt;

==={{Anchor|Fixed length|Fixed width|Variable length|Variable width}}Instruction length===
The size or length of an instruction varies widely, from as little as four bits in some [[microcontroller]]s to many hundreds of bits in some VLIW systems. Processors used in [[personal computer]]s, [[mainframe computer|mainframe]]s, and [[supercomputer]]s have instruction sizes between 8 and 64 bits. The longest possible instruction on x86 is 15 bytes (120 bits).&lt;ref&gt;{{cite web|title=Intel® 64 and IA-32 Architectures Software Developer's Manual|url=http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html/|publisher=Intel Corporation|access-date=12 July 2012}}&lt;/ref&gt; Within an instruction set, different instructions may have different lengths. In some architectures, notably most [[reduced instruction set computer]]s (RISC), {{vanchor|instructions are a fixed length|FIXED_LENGTH_INSTRUCTIONS}}, typically corresponding with that architecture's [[word (data type)|word size]]. In other architectures, instructions have variable length, typically integral multiples of a [[byte]] or a [[halfword]]. Some, such as the [[ARMv7|ARM]] with ''Thumb-extension'' have ''mixed'' variable encoding, that is two fixed, usually 32-bit and 16-bit encodings, where instructions cannot be mixed freely but must be switched between on a branch (or exception boundary in ARMv8).

A RISC instruction set normally has a fixed instruction length (often 4 bytes = 32 bits), whereas a typical CISC instruction set may have instructions of widely varying length (1 to 15 bytes for x86). Fixed-length instructions are less complicated to handle than variable-length instructions for several reasons (not having to check whether an instruction straddles a cache line or virtual memory page boundary,&lt;ref name=Cocke/&gt; for instance), and are therefore somewhat easier to optimize for speed.

===Code density===
In early computers, memory was expensive, so minimizing the size of a program to make sure it would fit in the limited memory was often central. Thus the combined size of all the instructions needed to perform a particular task, the ''code density'', was an important characteristic of any instruction set. Computers with high code density often have complex instructions for procedure entry, parameterized returns, loops, etc. (therefore retroactively named ''Complex Instruction Set Computers'', [[complex instruction set computer|CISC]]). However, more typical, or frequent, &quot;CISC&quot; instructions merely combine a basic ALU operation, such as &quot;add&quot;, with the access of one or more operands in memory (using [[addressing mode]]s such as direct, indirect, indexed, etc.). Certain architectures may allow two or three operands (including the result) directly in memory or may be able to perform functions such as automatic pointer increment, etc. Software-implemented instruction sets may have even more complex and powerful instructions.

''Reduced instruction-set computers'', [[reduced instruction set computer|RISC]], were first widely implemented during a period of rapidly growing memory subsystems. They sacrifice code density to simplify implementation circuitry, and try to increase performance via higher clock frequencies and more registers. A single RISC instruction typically performs only a single operation, such as an &quot;add&quot; of registers or a &quot;load&quot; from a memory location into a register. A RISC instruction set normally has a fixed [[#Instruction length|instruction length]], whereas a typical CISC instruction set has instructions of widely varying length. However, as RISC computers normally require more and often longer instructions to implement a given task, they inherently make less optimal use of bus bandwidth and cache memories.

Certain embedded RISC ISAs like [[ARM architecture#Thumb|Thumb]] and [[AVR32]] typically exhibit very high density owing to a technique called code compression. This technique packs two 16-bit instructions into one 32-bit word, which is then unpacked at the decode stage and executed as two instructions.&lt;ref name=weaver&gt;{{cite conference|last1=Weaver|first1=Vincent M.|last2=McKee|first2=Sally A.|title=Code density concerns for new architectures|year=2009|conference=IEEE International Conference on Computer Design|doi=10.1109/ICCD.2009.5413117|citeseerx=10.1.1.398.1967}}&lt;/ref&gt;

[[Minimal instruction set computer]]s (MISC) are a form of [[stack machine]], where there are few separate instructions (16-64), so that multiple instructions can be fit into a single machine word. These types of cores often take little silicon to implement, so they can be easily realized in an [[field-programmable gate array|FPGA]] or in a [[multi-core]] form. The code density of MISC is similar to the code density of RISC; the increased instruction density is offset by requiring more of the primitive instructions to do a task.{{Citation needed|date=January 2010}}
&lt;!-- Need examples here --&gt;
