If we define ''P'' as the above 4-element strategy vector of ''X'' and &lt;math&gt;Q=\{Q_{cc},Q_{cd},Q_{dc},Q_{dd}\}&lt;/math&gt; as the 4-element strategy vector of ''Y'', a transition matrix ''M'' may be defined for ''X'' whose ''ij'' th entry is the probability that the outcome of a particular encounter between ''X'' and ''Y'' will be ''j'' given that the previous encounter was ''i'', where ''i'' and ''j'' are one of the four outcome indices: ''cc'', ''cd'', ''dc'', or ''dd''. For example, from ''X'' 's point of view, the probability that the outcome of the present encounter is ''cd'' given that the previous encounter was ''cd'' is equal to &lt;math&gt;M_{cd,cd}=P_{cd}(1-Q_{dc})&lt;/math&gt;. (The indices for ''Q'' are from ''Y'' 's point of view: a ''cd'' outcome for ''X'' is a ''dc'' outcome for ''Y''.)  Under these definitions, the iterated prisoner's dilemma qualifies as a [[stochastic process]] and ''M'' is a [[stochastic matrix]], allowing all of the theory of stochastic processes to be applied.&lt;ref name=&quot;Press2012&quot;/&gt;

One result of stochastic theory is that there exists a stationary vector ''v'' for the matrix ''M'' such that &lt;math&gt;v\cdot M=v&lt;/math&gt;. Without loss of generality, it may be specified that ''v'' is normalized so that the sum of its four components is unity. The ''ij'' th entry in &lt;math&gt;M^n&lt;/math&gt; will give the probability that the outcome of an encounter between ''X'' and ''Y'' will be ''j'' given that the encounter ''n'' steps previous is ''i''. In the limit as ''n'' approaches infinity, ''M'' will converge to a matrix with fixed values, giving the long-term probabilities of an encounter producing ''j'' which will be independent of ''i''. In other words, the rows of &lt;math&gt;M^\infty&lt;/math&gt; will be identical, giving the long-term equilibrium result probabilities of the iterated prisoners dilemma without the need to explicitly evaluate a large number of interactions. It can be seen that ''v'' is a stationary vector for &lt;math&gt;M^n&lt;/math&gt; and particularly &lt;math&gt;M^\infty&lt;/math&gt;, so that each row of &lt;math&gt;M^\infty&lt;/math&gt; will be equal to ''v''. Thus the stationary vector specifies the equilibrium outcome probabilities for ''X''. Defining &lt;math&gt;S_x=\{R,S,T,P\}&lt;/math&gt; and &lt;math&gt;S_y=\{R,T,S,P\}&lt;/math&gt; as the short-term payoff vectors for the {cc,cd,dc,dd} outcomes (From ''X'' 's point of view), the equilibrium payoffs for ''X'' and ''Y'' can now be specified as &lt;math&gt;s_x=v\cdot S_x&lt;/math&gt; and &lt;math&gt;s_y=v\cdot S_y&lt;/math&gt;, allowing the two strategies ''P'' and ''Q'' to be compared for their long term payoffs.

====Zero-determinant strategies====

[[File:IPD Venn.svg|right|thumb|upright=2.5|The relationship between zero-determinant (ZD), cooperating and defecting strategies in the iterated prisoner's dilemma (IPD) illustrated in a [[Venn diagram]]. Cooperating strategies always cooperate with other cooperating strategies, and defecting strategies always defect against other defecting strategies. Both contain subsets of strategies that are robust under strong selection, meaning no other memory-1 strategy is selected to invade such strategies when they are resident in a population. Only cooperating strategies contain a subset that are always robust, meaning that no other memory-1 strategy is selected to invade and replace such strategies, under both strong and [[weak selection]]. The intersection between ZD and good cooperating strategies is the set of generous ZD strategies. Extortion strategies are the intersection between ZD and non-robust defecting strategies. Tit-for-tat lies at the intersection of cooperating, defecting and ZD strategies.]]

In 2012, [[William H. Press]] and [[Freeman Dyson]] published a new class of strategies for the stochastic iterated prisoner's dilemma called &quot;zero-determinant&quot; (ZD) strategies.&lt;ref name=&quot;Press2012&quot;/&gt; The long term payoffs for encounters between ''X'' and ''Y'' can be expressed as the determinant of a matrix which is a function of the two strategies and the short term payoff vectors: &lt;math&gt;s_x=D(P,Q,S_x)&lt;/math&gt; and &lt;math&gt;s_y=D(P,Q,S_y)&lt;/math&gt;, which do not involve the stationary vector ''v''. Since the determinant function &lt;math&gt;s_y=D(P,Q,f)&lt;/math&gt; is linear in ''f'', it follows that &lt;math&gt;\alpha s_x+\beta s_y+\gamma=D(P,Q,\alpha S_x+\beta S_y+\gamma U)&lt;/math&gt; (where ''U''={1,1,1,1}). Any strategies for which &lt;math&gt;D(P,Q,\alpha S_x+\beta S_y+\gamma U)=0&lt;/math&gt; is by definition a ZD strategy, and the long term payoffs obey the relation  &lt;math&gt;\alpha s_x+\beta s_y+\gamma=0&lt;/math&gt;.

Tit-for-tat is a ZD strategy which is &quot;fair&quot; in the sense of not gaining advantage over the other player. However, the ZD space also contains strategies that, in the case of two players, can allow one player to unilaterally set the other player's score or alternatively, force an evolutionary player to achieve a payoff some percentage lower than his own. The extorted player could defect but would thereby hurt himself by getting a lower payoff. Thus, extortion solutions turn the iterated prisoner's dilemma into a sort of [[ultimatum game]]. Specifically, ''X'' is able to choose a strategy for which &lt;math&gt;D(P,Q,\beta S_y+\gamma U)=0&lt;/math&gt;, unilaterally setting &lt;math&gt;s_y&lt;/math&gt;  to a specific value within a particular range of values, independent of ''Y'' 's strategy, offering an opportunity for ''X'' to &quot;extort&quot; player ''Y'' (and vice versa). (It turns out that if ''X'' tries to set &lt;math&gt;s_x&lt;/math&gt; to a particular value, the range of possibilities is much smaller, only consisting of complete cooperation or complete defection.&lt;ref name=&quot;Press2012&quot;/&gt;)

An extension of the IPD is an evolutionary stochastic IPD, in which the relative abundance of particular strategies is allowed to change, with more successful strategies relatively increasing. This process may be accomplished by having less successful players imitate the more successful strategies, or by eliminating less successful players from the game, while multiplying the more successful ones. It has been shown that unfair ZD strategies are not [[evolutionarily stable strategy|evolutionarily stable]]. The key intuition is that an evolutionarily stable strategy must not only be able to invade another population (which extortionary ZD strategies can do) but must also perform well against other players of the same type (which extortionary ZD players do poorly, because they reduce each other's surplus).&lt;ref&gt;{{cite journal|last=Adami|first=Christoph|author2=Arend Hintze|title=Evolutionary instability of Zero Determinant strategies demonstrates that winning isn't everything|journal=Nature Communications|volume=4|year=2013|page=3|arxiv=1208.2666|doi=10.1038/ncomms3193|pmid=23903782|pmc=3741637|bibcode=2013NatCo...4.2193A}}&lt;/ref&gt;

Theory and simulations confirm that beyond a critical population size, ZD extortion loses out in evolutionary competition against more cooperative strategies, and as a result, the average payoff in the population increases when the population is larger. In addition, there are some cases in which extortioners may even catalyze cooperation by helping to break out of a face-off between uniform defectors and [[win–stay, lose–switch]] agents.&lt;ref name=Hilbe2013 /&gt;

While extortionary ZD strategies are not stable in large populations, another ZD class called &quot;generous&quot; strategies ''is'' both stable and robust.  In fact, when the population is not too small, these strategies can supplant any other ZD strategy and even perform well against a broad array of generic strategies for iterated prisoner's dilemma, including win–stay, lose–switch. This was proven specifically for the [[Prisoner's dilemma#Special case: Donation game|donation game]] by Alexander Stewart and Joshua Plotkin in 2013.&lt;ref name=Stewart2013&gt;{{cite journal|last=Stewart|first=Alexander J.|author2=Joshua B. Plotkin|title=From extortion to generosity, evolution in the Iterated Prisoner's Dilemma|journal=[[Proceedings of the National Academy of Sciences of the United States of America]]|year=2013|doi=10.1073/pnas.1306246110|pmid=24003115|volume=110|issue=38|pages=15348–53|bibcode=2013PNAS..11015348S|pmc=3780848}}&lt;/ref&gt; Generous strategies will cooperate with other cooperative players, and in the face of defection, the generous player loses more utility than its rival. Generous strategies are the intersection of ZD strategies and so-called &quot;good&quot; strategies, which were defined by Akin (2013)&lt;ref name=Akin2013&gt;{{cite arxiv|last=Akin|first=Ethan|title=Stable Cooperative Solutions for the Iterated Prisoner's Dilemma|year=2013|page=9|class=math.DS|eprint=1211.0969}} {{bibcode|2012arXiv1211.0969A}}&lt;/ref&gt; to be those for which the player responds to past mutual cooperation with future cooperation and splits expected payoffs equally if he receives at least the cooperative expected payoff. Among good strategies, the generous (ZD) subset performs well when the population is not too small. If the population is very small, defection strategies tend to dominate.&lt;ref name=Stewart2013 /&gt;

===Continuous iterated prisoner's dilemma===
Most work on the iterated prisoner's dilemma has focused on the discrete case, in which players either cooperate or defect, because this model is relatively simple to analyze. However, some researchers have looked at models of the continuous iterated prisoner's dilemma, in which players are able to make a variable contribution to the other player. Le and Boyd&lt;ref&gt;{{cite journal | last1 = Le | first1 = S. | last2 = Boyd | first2 = R. |name-list-style=vanc| year = 2007 | title = Evolutionary Dynamics of the Continuous Iterated Prisoner's Dilemma | journal = Journal of Theoretical Biology | volume = 245 | issue = 2| pages = 258–67 | doi = 10.1016/j.jtbi.2006.09.016 | pmid = 17125798 }}&lt;/ref&gt; found that in such situations, cooperation is much harder to evolve than in the discrete iterated prisoner's dilemma. The basic intuition for this result is straightforward: in a continuous prisoner's dilemma, if a population starts off in a non-cooperative equilibrium, players who are only marginally more cooperative than non-cooperators get little benefit from [[Assortative mating|assorting]] with one another. By contrast, in a discrete prisoner's dilemma, tit for tat cooperators get a big payoff boost from assorting with one another in a non-cooperative equilibrium, relative to non-cooperators. Since nature arguably offers more opportunities for variable cooperation rather than a strict dichotomy of cooperation or defection, the continuous prisoner's dilemma may help explain why real-life examples of tit for tat-like cooperation are extremely rare in nature (ex. Hammerstein&lt;ref&gt;Hammerstein, P. (2003). Why is reciprocity so rare in social animals? A protestant appeal. In: P. Hammerstein, Editor, Genetic and Cultural Evolution of Cooperation, MIT Press. pp. 83–94.
&lt;/ref&gt;) even though tit for tat seems robust in theoretical models.

===Emergence of stable strategies===
Players cannot seem to coordinate mutual cooperation, thus often get locked into the inferior yet stable strategy of defection.  In this way, iterated rounds facilitate the evolution of stable strategies.&lt;ref&gt;{{cite book|last=Spaniel|first=William|title=Game Theory 101: The Complete Textbook|year=2011}}&lt;/ref&gt; Iterated rounds often produce novel strategies, which have implications to complex social interaction. One such strategy is win-stay lose-shift. This strategy outperforms a simple Tit-For-Tat strategy&amp;nbsp;– that is, if you can get away with cheating, repeat that behavior, however if you get caught, switch.&lt;ref&gt;{{cite journal|last=Nowak|first=Martin|author2=Karl Sigmund|title=A strategy of win-stay, lose-shift that outperforms tit-for-tat in the Prisoner's Dilemma game|journal=Nature|year=1993|volume=364|issue=6432|doi=10.1038/364056a0|pages=56–58|pmid=8316296|bibcode=1993Natur.364...56N|s2cid=4238908}}&lt;/ref&gt;

The only problem of this tit-for-tat strategy is that they are vulnerable to signal error. The problem arises when one individual cheats in retaliation but the other interprets it as cheating. As a result of this, the second individual now cheats and then it starts a see-saw pattern of cheating in a chain reaction.

==Real-life examples==
The prisoner setting may seem contrived, but there are in fact many examples in human interaction as well as interactions in nature that have the same payoff matrix. The prisoner's dilemma is therefore of interest to the [[social science]]s such as [[economics]], [[politics]], and [[sociology]], as well as to the biological sciences such as [[ethology]] and [[evolutionary biology]]. Many natural processes have been abstracted into models in which living beings are engaged in endless games of prisoner's dilemma. This wide applicability of the PD gives the game its substantial importance.

===Environmental studies===
In [[environmental studies]], the PD is evident in crises such as global [[climate change|climate-change]]. It is argued all countries will benefit from a stable climate, but any single country is often hesitant to curb [[Carbon dioxide|{{Co2}}]] emissions. The immediate benefit to any one country from maintaining current behavior is wrongly perceived to be greater than the purported eventual benefit to that country if all countries' behavior was changed, therefore explaining the impasse concerning climate-change in 2007.&lt;ref&gt;{{cite news|newspaper=[[The Economist]]|url=http://www.economist.com/finance/displaystory.cfm?story_id=9867020|title=Markets &amp; Data|date=2007-09-27}}&lt;/ref&gt;

An important difference between climate-change politics and the prisoner's dilemma is uncertainty; the extent and pace at which pollution can change climate is not known. The dilemma faced by government is therefore different from the prisoner's dilemma in that the payoffs of cooperation are unknown. This difference suggests that states will cooperate much less than in a real iterated prisoner's dilemma, so that the probability of avoiding a possible climate catastrophe is much smaller than that suggested by a game-theoretical analysis of the situation using a real iterated prisoner's dilemma.&lt;ref&gt;{{cite web|last=Rehmeyer|first=Julie|title=Game theory suggests current climate negotiations won't avert catastrophe|url=https://www.sciencenews.org/article/game-theory-suggests-current-climate-negotiations-won%E2%80%99t-avert-catastrophe|work=Science News|publisher=Society for Science &amp; the Public|date=2012-10-29}}&lt;/ref&gt;

Osang and Nandy (2003) provide a theoretical explanation with proofs for a regulation-driven win-win situation along the lines of [[Michael Porter]]'s hypothesis, in which government regulation of competing firms is substantial.&lt;ref&gt;{{cite thesis|type=paper|url= http://faculty.smu.edu/tosang/pdf/regln0803.pdf|first1=Thomas|last1=Osang|first2=Arundhati|last2=Nandyyz|date=August 2003|title=Environmental Regulation of Polluting Firms: Porter's Hypothesis Revisited}}&lt;/ref&gt;

===Animals===
Cooperative behavior of many animals can be understood as an example of the prisoner's dilemma. Often animals engage in long term partnerships, which can be more specifically modeled as iterated prisoner's dilemma. For example, [[guppy|guppies]] inspect predators cooperatively in groups, and they are thought to punish non-cooperative inspectors.

[[Vampire bats]] are social animals that engage in reciprocal food exchange. Applying the payoffs from the prisoner's dilemma can help explain this behavior:&lt;ref&gt;{{cite book|last=Dawkins|first=Richard|title=The Selfish Gene|year=1976|publisher=Oxford University Press}}&lt;/ref&gt;
* C/C: &quot;Reward: I get blood on my unlucky nights, which saves me from starving. I have to give blood on my lucky nights, which doesn't cost me too much.&quot;
* D/C: &quot;Temptation: You save my life on my poor night. But then I get the added benefit of not having to pay the slight cost of feeding you on my good night.&quot;
* C/D: &quot;Sucker's Payoff: I pay the cost of saving your life on my good night. But on my bad night you don't feed me and I run a real risk of starving to death.&quot;
* D/D: &quot;Punishment: I don't have to pay the slight costs of feeding you on my good nights. But I run a real risk of starving on my poor nights.&quot;

===Psychology===
In [[addiction]] research / [[behavioral economics]], [[George Ainslie (psychologist)|George Ainslie]] points out&lt;ref&gt;{{cite book |first=George|last=Ainslie |title=Breakdown of Will |year=2001 |isbn=978-0-521-59694-7}}&lt;/ref&gt; that addiction can be cast as an intertemporal PD problem between the present and future selves of the addict.  In this case, ''defecting'' means ''relapsing'', and it is easy to see that not defecting both today and in the future is by far the best outcome. The case where one abstains today but relapses in the future is the worst outcome&amp;nbsp;– in some sense the discipline and self-sacrifice involved in abstaining today have been &quot;wasted&quot; because the future relapse means that the addict is right back where he started and will have to start over (which is quite demoralizing, and makes starting over more difficult).  Relapsing today and tomorrow is a slightly &quot;better&quot; outcome, because while the addict is still addicted, they haven't put the effort in to trying to stop. The final case, where one engages in the addictive behavior today while abstaining &quot;tomorrow&quot; will be familiar to anyone who has struggled with an addiction.  The problem here is that (as in other PDs) there is an obvious benefit to defecting &quot;today&quot;, but tomorrow one will face the same PD, and the same obvious benefit will be present then, ultimately leading to an endless string of defections.

[[John Gottman]] in his research described in &quot;the science of trust&quot; defines good relationships as those where partners know not to enter the (D,D) cell or at least not to get dynamically stuck there in a loop.

===Economics===
The prisoner's dilemma has been called the ''[[Escherichia coli|E. coli]]'' of social psychology, and it has been used widely to research various topics such as [[Oligopoly|oligopolistic]] competition and collective action to produce a collective good.&lt;ref&gt;{{Cite journal|last=Axelrod|first=Robert|date=1980|title=Effective Choice in the Prisoner's Dilemma|journal=The Journal of Conflict Resolution|volume=24|issue=1|pages=3–25|issn=0022-0027|jstor=173932|doi=10.1177/002200278002400101|s2cid=143112198|url=https://semanticscholar.org/paper/fd1ab82470446bfb12c39f0c577644291027cf76}}&lt;/ref&gt; 

Advertising is sometimes cited as a real-example of the prisoner's dilemma.  When [[cigarette advertising]] was legal in the United States, competing cigarette manufacturers had to decide how much money to spend on advertising.  The effectiveness of Firm A's advertising was partially determined by the advertising conducted by Firm B.  Likewise, the profit derived from advertising for Firm B is affected by the advertising conducted by Firm A.  If both Firm A and Firm B chose to advertise during a given period, then the advertisement from each firm negates the other's, receipts remain constant, and expenses increase due to the cost of advertising.  Both firms would benefit from a reduction in advertising.  However, should Firm B choose not to advertise, Firm A could benefit greatly by advertising. Nevertheless, the optimal amount of advertising by one firm depends on how much advertising the other undertakes. As the best strategy is dependent on what the other firm chooses there is no dominant strategy, which makes it slightly different from a prisoner's dilemma. The outcome is similar, though, in that both firms would be better off were they to advertise less than in the equilibrium. Sometimes cooperative behaviors do emerge in business situations.  For instance, cigarette manufacturers endorsed the making of laws banning cigarette advertising, understanding that this would reduce costs and increase profits across the industry.{{Citation needed|reason=This reference doesn't mention or support the claimed historical account.|date=December 2012}}{{efn|1=This argument for the development of cooperation through trust is given in ''[[The Wisdom of Crowds]]'', where it is argued that long-distance [[capitalism]] was able to form around a nucleus of [[Religious Society of Friends|Quakers]], who always dealt honourably with their business partners. (Rather than defecting and reneging on promises&amp;nbsp;– a phenomenon that had discouraged earlier long-term unenforceable overseas contracts). It is argued that dealings with reliable merchants allowed the [[meme]] for cooperation to spread to other traders, who spread it further until a high degree of cooperation became a profitable strategy in general [[commerce]]}} This analysis is likely to be pertinent in many other business situations involving advertising.{{Citation needed|reason=This doesn't sound like cooperation|date=November 2012}}

Without enforceable agreements, members of a [[cartel]] are also involved in a (multi-player) prisoner's dilemma.&lt;ref&gt;{{Cite book|last1=Nicholson|first=Walter|year=2000|title=Intermediate microeconomics and its application|edition=8th|location=Fort Worth, TX|publisher=Dryden Press : Harcourt College Publishers|isbn=978-0-030-25916-6}}&lt;/ref&gt; 'Cooperating' typically means keeping prices at a pre-agreed minimum level. 'Defecting' means selling under this minimum level, instantly taking business (and profits) from other cartel members. [[Anti-trust]] authorities want potential cartel members to mutually defect, ensuring the lowest possible prices for [[consumer]]s.

===Sport===
[[Doping in sport]] has been cited as an example of a prisoner's dilemma.&lt;ref name=&quot;wired&quot;&gt;{{cite journal|last=Schneier |first=Bruce |url=https://www.wired.com/opinion/2012/10/lance-armstrong-and-the-prisoners-dilemma-of-doping-in-professional-sports/ |title=Lance Armstrong and the Prisoners' Dilemma of Doping in Professional Sports &amp;#124; Wired Opinion |journal=Wired |publisher=Wired.com |date=2012-10-26 |accessdate=2012-10-29}}&lt;/ref&gt;

Two competing athletes have the option to use an illegal and/or dangerous drug to boost their performance. If neither athlete takes the drug, then neither gains an advantage. If only one does, then that athlete gains a significant advantage over their competitor, reduced by the legal and/or medical dangers of having taken the drug. If both athletes take the drug, however, the benefits cancel out and only the dangers remain, putting them both in a worse position than if neither had used doping.&lt;ref name=&quot;wired&quot; /&gt;

===International politics===
In [[international politics|international political theory]], the Prisoner's Dilemma is often used to demonstrate the coherence of [[strategic realism]], which holds that in international relations, all states (regardless of their internal policies or professed ideology), will act in their rational self-interest given [[anarchy (international relations)|international anarchy]]. A classic example is an arms race like the [[Cold War]] and similar conflicts.&lt;ref&gt;{{cite journal| title = Arms races as iterated prisoner's dilemma games | author = Stephen J. Majeski | journal = Mathematical and Social Sciences | volume = 7 | issue = 3 | pages = 253–66 | year = 1984 | doi=10.1016/0165-4896(84)90022-2}}&lt;/ref&gt; During the Cold War the opposing alliances of [[NATO]] and the [[Warsaw Pact]] both had the choice to arm or disarm. From each side's point of view, disarming whilst their opponent continued to arm would have led to military inferiority and possible annihilation. Conversely, arming whilst their opponent disarmed would have led to superiority. If both sides chose to arm, neither could afford to attack the other, but both incurred the high cost of developing and maintaining a nuclear arsenal. If both sides chose to disarm, war would be avoided and there would be no costs.

Although the 'best' overall outcome is for both sides to disarm, the rational course for both sides is to arm, and this is indeed what happened. Both sides poured enormous resources into military research and armament in a [[War of attrition (game)|war of attrition]] for the next thirty years until the Soviet Union could not withstand the economic cost.&lt;ref&gt;{{Citation|last=Kuhn|first=Steven|title=Prisoner's Dilemma|date=2019|url=https://plato.stanford.edu/archives/win2019/entries/prisoner-dilemma/|encyclopedia=The Stanford Encyclopedia of Philosophy|editor-last=Zalta|editor-first=Edward N.|edition=Winter 2019|publisher=Metaphysics Research Lab, Stanford University|access-date=2020-04-12}}&lt;/ref&gt; The same logic could be applied in any similar scenario, be it economic or technological competition between sovereign states.

===Multiplayer dilemmas===
Many real-life dilemmas involve multiple players.&lt;ref&gt;Gokhale CS, Traulsen A. Evolutionary games in the multiverse. Proceedings of the National Academy of Sciences. 2010 Mar 23. 107(12):5500–04.&lt;/ref&gt; Although metaphorical, [[Garrett Hardin|Hardin's]] [[tragedy of the commons]] may be viewed as an example of a multi-player generalization of the PD: Each villager makes a choice for personal gain or restraint. The collective reward for unanimous (or even frequent) defection is very low payoffs (representing the destruction of the &quot;commons&quot;). A commons dilemma most people can relate to is washing the dishes in a shared house.  By not washing dishes an individual can gain by saving his time, but if that behavior is adopted by every resident the collective cost is no clean plates for anyone.

The commons are not always exploited: [[William Poundstone]], in a book about the prisoner's dilemma, describes a situation in New Zealand where newspaper boxes are left unlocked. It is possible for people to [[Excludability|take a paper without paying]] (''defecting'') but very few do, feeling that if they do not pay then neither will others, destroying the system.{{sfn|Poundstone|1993|pp=126–127}} Subsequent research by [[Elinor Ostrom]], winner of the 2009 [[Nobel Memorial Prize in Economic Sciences]], hypothesized that the tragedy of the commons is oversimplified, with the negative outcome influenced by outside influences. Without complicating pressures, groups communicate and manage the commons among themselves for their mutual benefit, enforcing social norms to preserve the resource and achieve the maximum good for the group, an example of effecting the best case outcome for PD.&lt;ref&gt;{{cite web|url=http://volokh.com/2009/10/12/elinor-ostrom-and-the-tragedy-of-the-commons/ |title=The Volokh Conspiracy &quot; Elinor Ostrom and the Tragedy of the Commons |publisher=Volokh.com |date=2009-10-12 |accessdate=2011-12-17}}&lt;/ref&gt;&lt;ref&gt;{{cite book |last1=Ostrom |first1=Elinor |title=Governing the Commons: The Evolution of Institutions for Collective Action |date=2015 |orig-year=1990 |publisher=Cambridge University Press |isbn=978-1-107-56978-2 |doi=10.1017/CBO9781316423936}}&lt;/ref&gt;

==Related games==
===Closed-bag exchange===
[[File:Prisoner's Dilemma briefcase exchange (colorized).svg|thumb|The prisoner's dilemma as a briefcase exchange]]
[[Douglas Hofstadter]]&lt;ref name=&quot;dh&quot;&gt;{{cite book | first=Douglas R. | last=Hofstadter| authorlink=Douglas Hofstadter | title= Metamagical Themas: questing for the essence of mind and pattern | publisher= Bantam Dell Pub Group| year=1985 | isbn=978-0-465-04566-2|chapter= Ch.29 ''The Prisoner's Dilemma Computer Tournaments and the Evolution of Cooperation''.| title-link=Metamagical Themas}}&lt;/ref&gt; once suggested that people often find problems such as the PD problem easier to understand when it is illustrated in the form of a simple game, or trade-off. One of several examples he used was &quot;closed bag exchange&quot;:
{{quote|Two people meet and exchange closed bags, with the understanding that one of them contains money, and the other contains a purchase. Either player can choose to honor the deal by putting into his or her bag what he or she agreed, or he or she can defect by handing over an empty bag.}}
Defection always gives a game-theoretically preferable outcome.&lt;ref&gt;{{Cite web|url=https://users.auth.gr/kehagiat/Research/GameTheory/06GamesToPlay/Prisoner%27s_dilemma.htm#Closed_Bag_Exchange|title=Prisoner's dilemma - Wikipedia, the free encyclopedia|website=users.auth.gr|access-date=2020-04-12}}&lt;/ref&gt;

===''Friend or Foe?''===
''[[Friend or Foe? (TV series)|Friend or Foe?]]'' is a game show that aired from 2002 to 2003 on the [[Game Show Network]] in the US.  It is an example of the prisoner's dilemma game tested on real people, but in an artificial setting. On the game show, three pairs of people compete. When a pair is eliminated, they play a game similar to the prisoner's dilemma to determine how the winnings are split. If they both cooperate (Friend), they share the winnings 50–50. If one cooperates and the other defects (Foe), the defector gets all the winnings and the cooperator gets nothing. If both defect, both leave with nothing. Notice that the reward matrix is slightly different from the standard one given above, as the rewards for the &quot;both defect&quot; and the &quot;cooperate while the opponent defects&quot; cases are identical. This makes the &quot;both defect&quot; case a weak equilibrium, compared with being a strict equilibrium in the standard prisoner's dilemma. If a contestant knows that their opponent is going to vote &quot;Foe&quot;, then their own choice does not affect their own winnings. In a specific sense, ''Friend or Foe'' has a rewards model between prisoner's dilemma and the [[Chicken (game)|game of Chicken]].

The rewards matrix is
{| class=&quot;wikitable&quot;
! {{diagonal split header|{{color|#009|Pair 1}}|{{color|#900|Pair 2}}}}
! scope=&quot;col&quot; style=&quot;width:6em;&quot; | {{color|#900|&quot;Friend&quot;&lt;br /&gt;(cooperate)}}
! scope=&quot;col&quot; style=&quot;width:6em;&quot; | {{color|#900|&quot;Foe&quot;&lt;br /&gt;(defect)}}
|-
! scope=&quot;row&quot; style=&quot;width:6em;&quot; | {{color|#009|&quot;Friend&quot;&lt;br /&gt;(cooperate)}}
| {{diagonal split header|{{color|#009|1}}|{{color|#900|1}}|transparent}}
| {{diagonal split header|{{color|#009|0}}|{{color|#900|2}}|transparent}}
|-
! scope=&quot;row&quot; | {{color|#009|&quot;Foe&quot;&lt;br /&gt;(defect)}}
| {{diagonal split header|{{color|#009|2}}|{{color|#900|0}}|transparent}}
| {{diagonal split header|{{color|#009|0}}|{{color|#900|0}}|transparent}}
|}

This payoff matrix has also been used on the [[United Kingdom|British]] [[television]] programmes ''Trust Me'', ''[[Shafted]]'', ''[[The Bank Job (TV series)|The Bank Job]]'' and ''[[Golden Balls]]'', and on the [[United States|American]] game shows ''[[Take It All (game show)|Take It All]]'', as well as for the winning couple on the Reality Show shows ''[[Bachelor Pad]]''. Game data from the ''[[Golden Balls]]'' series has been analyzed by a team of economists, who found that cooperation was &quot;surprisingly high&quot; for amounts of money that would seem consequential in the real world, but were comparatively low in the context of the game.&lt;ref&gt;{{cite journal | ssrn=1592456 | title=Split or Steal? Cooperative Behavior When the Stakes Are Large | author=Van den Assem, Martijn J. | journal=Management Science |date=January 2012 | volume=58 | issue=1 | pages=2–20 | doi=10.1287/mnsc.1110.1413| s2cid=1371739 | url=https://nottingham-repository.worktribe.com/OutputFile/708508 }}&lt;/ref&gt;

===Iterated snowdrift===
{{main|snowdrift game}}

Researchers from the [[University of Lausanne]] and the [[University of Edinburgh]] have suggested that the &quot;Iterated Snowdrift Game&quot; may more closely reflect real-world social situations. Although this model is actually a [[chicken game]], it will be described here. In this model, the risk of being exploited through defection is lower, and individuals always gain from taking the cooperative choice. The snowdrift game imagines two drivers who are stuck on opposite sides of a [[snowdrift]], each of whom is given the option of shoveling snow to clear a path, or remaining in their car. A player's highest payoff comes from leaving the opponent to clear all the snow by themselves, but the opponent is still nominally rewarded for their work.

This may better reflect real world scenarios, the researchers giving the example of two scientists collaborating on a report, both of whom would benefit if the other worked harder. &quot;But when your collaborator doesn’t do any work, it’s probably better for you to do all the work yourself. You’ll still end up with a completed project.&quot;&lt;ref&gt;{{cite web|last=Kümmerli|first=Rolf|title='Snowdrift' game tops 'Prisoner's Dilemma' in explaining cooperation|url=http://phys.org/news111145481.html|accessdate=11 April 2012}}&lt;/ref&gt;

{|
|-
|
{| class=&quot;wikitable&quot; style=&quot;text-align: center;&quot;
|+ Example snowdrift payouts (A, B)
! {{diagonal split header|&amp;nbsp;A|B&amp;nbsp;}} !! Cooperates !! Defects
|-
! Cooperates
| 200, 200 || 100, 300
|-
! Defects
| 300, 100 || 0, 0
|}
||
{| class=&quot;wikitable&quot; style=&quot;text-align: center;margin-left:2em;&quot;
|+ Example PD payouts (A, B)
! {{diagonal split header|&amp;nbsp;A|B&amp;nbsp;}} !! Cooperates !! Defects
|-
! Cooperates
| 200, 200 || -100, 300
|-
! Defects
| 300, -100 || 0, 0
|}

|}

===Coordination games===
{{main|coordination games}}
In coordination games, players must coordinate their strategies for a good outcome. An example is two cars that abruptly meet in a blizzard; each must choose whether to swerve left or right. If both swerve left, or both right, the cars do not collide. The local [[left- and right-hand traffic]] convention helps to co-ordinate their actions.

Symmetrical co-ordination games include [[Stag hunt]] and [[Bach or Stravinsky]].

===Asymmetric prisoner's dilemmas===
A more general set of games are asymmetric. As in the prisoner's dilemma, the best outcome is co-operation, and there are motives for defection. Unlike the symmetric prisoner's dilemma, though, one player has more to lose and/or more to gain than the other. Some such games have been described as a prisoner's dilemma in which one prisoner has an [[alibi]], whence the term &quot;alibi game&quot;.&lt;ref&gt;{{cite conference|last1=Robinson |first1=D.R. |last2=Goforth |first2=D.J. |title=Alibi games: the Asymmetric Prisoner' s Dilemmas |date=May 5, 2004 |url=https://economics.ca/2004/papers/0359.pdf |conference=Meetings of the Canadian Economics Association, Toronto, June 4-6, 2004}}&lt;/ref&gt;

In experiments, players getting unequal payoffs in repeated games may seek to maximize profits, but only under the condition that both players receive equal payoffs; this may lead to a stable equilibrium strategy in which the disadvantaged player defects every X games, while the other always co-operates. Such behaviour may depend on the experiment's social norms around fairness.&lt;ref&gt;{{cite chapter|last1=Beckenkamp |first1=Martin |last2=Hennig-Schmidt |first2=Heike |last3=Maier-Rigaud |first3=Frank P. |chapter=Cooperation in Symmetric and Asymmetric Prisoner's Dilemma Games |date=March 4, 2007 |chapter-url=http://homepage.coll.mpg.de/pdf_dat/2006_25online.pdf |title=[[Max Planck Institute for Research on Collective Goods]]}}&lt;/ref&gt;

==Software==

Several software packages have been created to run prisoner's dilemma simulations and tournaments, some of which have available source code.
* The source code for the [[The Evolution of Cooperation|second tournament]] run by Robert Axelrod (written by Axelrod and many contributors in [[Fortran]]) is available [http://www-personal.umich.edu/~axe/research/Software/CC/CC2.html online]
* [https://web.archive.org/web/19991010053242/http://www.lifl.fr/IPD/ipd.frame.html Prison], a library written in [[Java (programming language)|Java]], last updated in 1998
* [https://github.com/Axelrod-Python/Axelrod Axelrod-Python], written in [[Python (programming language)|Python]]
* [http://selborne.nl/ipd/ play the Iterative Prisoner's Dilemma in the browser], play against strategies or let strategies play against other strategies

==In fiction==
[[Hannu Rajaniemi]] set the opening scene of his ''[[The Quantum Thief]]'' trilogy in a &quot;dilemma prison&quot;. The main theme of the series has been described as the &quot;inadequacy of a binary universe&quot; and the ultimate antagonist is a character called the All-Defector.  Rajaniemi is particularly interesting as an artist treating this subject in that he is a Cambridge-trained mathematician and holds a PhD in [[mathematical physics]]&amp;nbsp;– the interchangeability of matter and information is a major feature of the books, which take place in a &quot;post-singularity&quot; future.  The first book in the series was published in 2010, with the two sequels, ''[[The Fractal Prince]]'' and ''[[The Causal Angel]]'', published in 2012 and 2014, respectively.

A game modeled after the (iterated) prisoner's dilemma is a central focus of the 2012 video game ''[[Zero Escape: Virtue's Last Reward]]'' and a minor part in its 2016 sequel ''[[Zero Escape: Zero Time Dilemma]]''.

In ''The Mysterious Benedict Society and the Prisoner's Dilemma'' by [[Trenton Lee Stewart]], the main characters start by playing a version of the game and escaping from the &quot;prison&quot; altogether. Later they become actual prisoners and escape once again.

In ''[[The Adventure Zone]]: Balance'' during ''The Suffering Game'' subarc, the player characters are twice presented with the prisoner's dilemma during their time in two liches' domain, once cooperating and once defecting.

In the 8th novel from the author James S. A. Corey ''[[Tiamat's Wrath]],'' Winston Duarte explains the prisoners dilemma to his 14-year-old daughter, Teresa, to train her in strategic thinking. {{cn|date=April 2020}}

This is examined literally in the 2019 film ''[[The Platform (film)|The Platform]]'', where inmates in a vertical prison may only eat whatever is left over by those above them. If everyone were to eat their fair share, there would be enough food, but those in the lower levels are shown to starve because of the higher inmates' overconsumption.
