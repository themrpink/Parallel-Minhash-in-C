Stability is crucial in practical applications of Nash equilibria, since the mixed strategy of each player is not perfectly known, but has to be inferred from statistical distribution of their actions in the game. In this case unstable equilibria are very unlikely to arise in practice, since any minute change in the proportions of each strategy seen will lead to a change in strategy and the breakdown of the equilibrium.

The Nash equilibrium defines stability only in terms of unilateral deviations. In cooperative games such a concept is not convincing enough. [[Strong Nash equilibrium]] allows for deviations by every conceivable coalition.&lt;ref name=&quot;CoalitionProof&quot;&gt;{{Citation|doi = 10.1016/0022-0531(87)90099-8|title = Coalition-Proof Equilibria I. Concepts|author1=B. D. Bernheim |author2=B. Peleg |author3=M. D. Whinston |journal = Journal of Economic Theory |volume = 42 |year =1987|issue = 1| pages = 1&amp;ndash;12|postscript = .}}&lt;/ref&gt; Formally, a strong Nash equilibrium is a Nash equilibrium in which no coalition, taking the actions of its complements as given, can cooperatively deviate in a way that benefits all of its members.&lt;ref name=&quot;SNE&quot;&gt;{{Cite book |first=R. |last=Aumann |chapter = Acceptable points in general cooperative n-person games |title=Contributions to the Theory of Games |volume=IV | publisher = Princeton University Press |location=Princeton, N.J. |year=1959 |isbn=978-1-4008-8216-8 }}&lt;/ref&gt; However, the strong Nash concept is sometimes perceived as too &quot;strong&quot; in that the environment allows for unlimited private communication. In fact, strong Nash equilibrium has to be [[Pareto efficient]]. As a result of these requirements, strong Nash is too rare to be useful in many branches of game theory. However, in games such as elections with many more players than possible outcomes, it can be more common than a stable equilibrium.

A refined Nash equilibrium known as [[coalition-proof Nash equilibrium]] (CPNE)&lt;ref name=&quot;CoalitionProof&quot;/&gt; occurs when players cannot do better even if they are allowed to communicate and make &quot;self-enforcing&quot; agreement to deviate. Every correlated strategy supported by [[Dominance (game theory)|iterated strict dominance]] and on the [[Pareto frontier]] is a CPNE.&lt;ref name=&quot;CPNE&quot;&gt;{{Citation|title = Coalition-Proof Equilibrium|author1=D. Moreno |author2=J. Wooders |journal = Games and Economic Behavior|volume = 17|issue = 1|year =1996| pages = 80&amp;ndash;112 | doi = 10.1006/game.1996.0095|postscript = .|url =http://e-archivo.uc3m.es/bitstream/10016/4408/1/Coalition_GEB_1996_ps.PDF|hdl=10016/4408 }}&lt;/ref&gt;  Further, it is possible for a game to have a Nash equilibrium that is resilient against coalitions less than a specified size, k. CPNE is related to the [[Core (economics)|theory of the core]].

Finally in the eighties, building with great depth on such ideas [[Mertens-stable equilibria]] were introduced as a [[solution concept]]. Mertens stable equilibria satisfy both [[forward induction]] and [[backward induction]]. In a [[game theory]] context [[stable equilibria]] now usually refer to Mertens stable equilibria.

== Occurrence ==
If a game has a [[unique (mathematics)|unique]] Nash equilibrium and is played among players under certain conditions, then the NE strategy set will be adopted. Sufficient conditions to guarantee that the Nash equilibrium is played are:
# The players all will do their utmost to maximize their expected payoff as described by the game.
# The players are flawless in execution.
# The players have sufficient intelligence to deduce the solution.
# The players know the planned equilibrium strategy of all of the other players.
# The players believe that a deviation in their own strategy will not cause deviations by any other players.
# There is [[common knowledge (logic)|common knowledge]] that all players meet these conditions, including this one. So, not only must each player know the other players meet the conditions, but also they must know that they all know that they meet them, and know that they know that they know that they meet them, and so on.

=== Where the conditions are not met ===
Examples of [[game theory]] problems in which these conditions are not met:
# The first condition is not met if the game does not correctly describe the quantities a player wishes to maximize. In this case there is no particular reason for that player to adopt an equilibrium strategy. For instance, the prisoner's dilemma is not a dilemma if either player is happy to be jailed indefinitely.
# Intentional or accidental imperfection in execution. For example, a computer capable of flawless logical play facing a second flawless computer will result in equilibrium. Introduction of imperfection will lead to its disruption either through loss to the player who makes the mistake, or through negation of the [[common knowledge (logic)|common knowledge]] criterion leading to possible victory for the player. (An example would be a player suddenly putting the car into reverse in the [[game of chicken]], ensuring a no-loss no-win scenario).
# In many cases, the third condition is not met because, even though the equilibrium must exist, it is unknown due to the complexity of the game, for instance in [[Chinese chess]].&lt;ref&gt;T. L. Turocy, B. Von Stengel, ''[http://www.cdam.lse.ac.uk/Reports/Files/cdam-2001-09.pdf Game Theory]'', copyright 2001, Texas A&amp;M University,  London School of Economics, pages 141-144. {{Citation needed span|text=Nash proved that a perfect NE exists for this type of finite [[extensive form game]]|date=April 2010}} – it can be represented as a strategy complying with his original conditions for a game with a NE. Such games may not have unique NE, but at least one of the many equilibrium strategies would be played by hypothetical players having perfect knowledge of all {{Citation needed span|text=10&lt;sup&gt;150&lt;/sup&gt; [[game-tree complexity|game trees]]|date=April 2010}}.&lt;/ref&gt; Or, if known, it may not be known to all players, as when playing [[tic-tac-toe]] with a small child who desperately wants to win (meeting the other criteria).
# The criterion of common knowledge may not be met even if all players do, in fact, meet all the other criteria. Players wrongly distrusting each other's rationality may adopt counter-strategies to expected irrational play on their opponents’ behalf. This is a major consideration in &quot;[[Game of chicken|chicken]]&quot; or an [[arms race]], for example.

=== Where the conditions are met ===
In his Ph.D. dissertation, John Nash proposed two interpretations of his equilibrium concept, with the objective of showing how equilibrium points

{{quote|(...) can be connected with observable phenomenon. ''One interpretation is rationalistic: if we assume that players are rational, know the full structure of'' the game, the game is played just once, and there is just one Nash equilibrium, then players will play according to that equilibrium. This idea was formalized by Aumann, R. and A. Brandenburger, 1995, ''Epistemic Conditions for Nash Equilibrium'', Econometrica, 63, 1161-1180 who interpreted each player's mixed strategy as a conjecture about the behaviour of other players and have shown that if the game and the rationality of players is mutually known and these conjectures are commonly know, then the conjectures must be a Nash equilibrium (a common prior assumption is needed for this result in general, but not in the case of two players. In this case, the conjectures need only be mutually known).}}

A second interpretation, that Nash referred to by the mass action interpretation, is less demanding on players:

{{quote|[i]t is unnecessary to assume that the participants have full knowledge of the total structure of the game, or the ability and inclination to go through any complex reasoning processes. ''What is assumed is that there is a population of participants for each position in the game, which will be played throughout time by participants drawn at random from the different populations. If there is a stable average frequency with which each pure strategy is employed by the ''average member'' of the appropriate population, then this stable average frequency constitutes a mixed strategy Nash equilibrium.''}}

For a formal result along these lines, see Kuhn, H. and et al., 1996, &quot;The Work of John Nash in Game Theory,&quot; ''Journal of Economic Theory'', 69, 153–185.

Due to the limited conditions in which NE can actually be observed, they are rarely treated as a guide to day-to-day behaviour, or observed in practice in human negotiations. However, as a theoretical concept in [[economics]] and [[evolutionary biology]], the NE has explanatory power. The payoff in economics is utility (or sometimes money), and in evolutionary biology is gene transmission; both are the fundamental bottom line of survival. Researchers who apply games theory in these fields claim that strategies failing to maximize these for whatever reason will be competed out of the market or environment, which are ascribed the ability to test all strategies. This conclusion is drawn from the &quot;[[Nash equilibrium#Stability|stability]]&quot; theory above. In these situations the assumption that the strategy observed is actually a NE has often been borne out by research.&lt;ref&gt;J. C. Cox, M. Walker, ''[http://excen.gsu.edu/jccox/research/learnplay.pdf Learning to Play Cournot Duoploy Strategies] {{Webarchive|url=https://web.archive.org/web/20131211182058/http://excen.gsu.edu/jccox/research/learnplay.pdf |date=2013-12-11 }}'', copyright 1997, Texas A&amp;M University,  University of Arizona, pages 141-144&lt;/ref&gt;

== NE and non-credible threats ==
[[File:SGPNEandPlainNE explainingexample.svg|300px|thumb|Extensive and Normal form illustrations that show the difference between SPNE and other NE. The blue equilibrium is not subgame perfect because player two makes a non-credible threat at 2(2) to be unkind (U).]]
The Nash equilibrium is a superset of the subgame perfect Nash equilibrium. The subgame perfect equilibrium in addition to the Nash equilibrium requires that the strategy also is a Nash equilibrium in every subgame of that game. This eliminates all [[non-credible threats]], that is, strategies that contain non-rational moves in order to make the counter-player change their strategy.

The image to the right shows a simple sequential game that illustrates the issue with subgame imperfect Nash equilibria. In this game player one chooses left(L) or right(R), which is followed by player two being called upon to be kind (K) or unkind (U) to player one, However, player two only stands to gain from being unkind if player one goes left. If player one goes right the rational player two would de facto be kind to her/him in that subgame. However, The non-credible threat of being unkind at 2(2) is still part of the blue (L, (U,U)) Nash equilibrium. Therefore, if rational behavior can be expected by both parties the subgame perfect Nash equilibrium may be a more meaningful solution concept when such [[dynamic inconsistency|dynamic inconsistencies]] arise.

==Proof of existence==

=== Proof using the Kakutani fixed-point theorem ===
Nash's original proof (in his thesis) used Brouwer's fixed-point theorem (e.g., see below for a variant). We give a simpler proof via the Kakutani fixed-point theorem, following Nash's 1950 paper (he credits [[David Gale]] with the observation that such a simplification is possible).

To prove the existence of a Nash equilibrium, let &lt;math&gt;r_i(\sigma_{-i})&lt;/math&gt; be the best response of player i to the strategies of all other players.
:&lt;math&gt; r_i(\sigma_{-i}) = \mathop{\underset{\sigma_i}{\operatorname{arg\,max}}} u_i (\sigma_i,\sigma_{-i}) &lt;/math&gt;

Here, &lt;math&gt;\sigma \in \Sigma&lt;/math&gt;, where &lt;math&gt;\Sigma = \Sigma_i \times \Sigma_{-i}&lt;/math&gt;, is a mixed-strategy profile in the set of all mixed strategies and &lt;math&gt; u_i &lt;/math&gt; is the payoff function for player i. Define a [[Multivalued function|set-valued function]] &lt;math&gt;r\colon \Sigma \rightarrow 2^\Sigma &lt;/math&gt; such that &lt;math&gt;r = r_i(\sigma_{-i})\times r_{-i}(\sigma_{i}) &lt;/math&gt;. The existence of a Nash equilibrium is equivalent to &lt;math&gt;r&lt;/math&gt; having a fixed point.

[[Kakutani fixed-point theorem|Kakutani's fixed point theorem]] guarantees the existence of a fixed point if the following four conditions are satisfied.
# &lt;math&gt; \Sigma&lt;/math&gt; is compact, convex, and nonempty.
# &lt;math&gt;r(\sigma)&lt;/math&gt; is nonempty.
# &lt;math&gt;r(\sigma)&lt;/math&gt; is [[Hemicontinuity|upper hemicontinuous]]
# &lt;math&gt;r(\sigma)&lt;/math&gt; is convex.

Condition 1. is satisfied from the fact that &lt;math&gt;\Sigma&lt;/math&gt; is a simplex and thus compact. Convexity follows from players' ability to mix strategies. &lt;math&gt;\Sigma&lt;/math&gt; is nonempty as long as players have strategies.

Condition 2. and 3. are satisfied by way of Berge's [[maximum theorem]]. Because &lt;math&gt; u_i &lt;/math&gt; is continuous and compact, &lt;math&gt; r(\sigma_i) &lt;/math&gt; is non-empty and [[Hemicontinuity|upper hemicontinuous]].

Condition 4. is satisfied as a result of mixed strategies. Suppose  &lt;math&gt; \sigma_i, \sigma'_i \in r(\sigma_{-i}) &lt;/math&gt;, then  &lt;math&gt; \lambda \sigma_i + (1-\lambda) \sigma'_i \in r(\sigma_{-i}) &lt;/math&gt;. i.e. if two strategies maximize payoffs, then a mix between the two strategies will yield the same payoff.

Therefore, there exists a fixed point in  &lt;math&gt; r &lt;/math&gt; and a Nash equilibrium.&lt;ref&gt;{{cite book |last=Fudenburg |first=Drew |first2=Jean |last2=Tirole |title=Game Theory |publisher=MIT Press |year=1991 |isbn=978-0-262-06141-4 }}&lt;/ref&gt;

When Nash made this point to [[John von Neumann]] in 1949, von Neumann famously dismissed it with the words, &quot;That's trivial, you know. That's just a [[fixed-point theorem]].&quot; (See Nasar, 1998, p.&amp;nbsp;94.)

=== Alternate proof using the [[Brouwer fixed-point theorem]] ===

We have a game &lt;math&gt;G=(N,A,u)&lt;/math&gt; where &lt;math&gt;N&lt;/math&gt; is the number of players and &lt;math&gt;A = A_1 \times \cdots \times A_N&lt;/math&gt; is the action set for the players. All of the action sets &lt;math&gt;A_i&lt;/math&gt; are finite. Let &lt;math&gt;\Delta = \Delta_1 \times \cdots \times \Delta_N&lt;/math&gt; denote the set of mixed strategies for the players. The finiteness of the &lt;math&gt;A_i&lt;/math&gt;s ensures the compactness of &lt;math&gt;\Delta&lt;/math&gt;.

We can now define the gain functions. For a mixed strategy &lt;math&gt;\sigma \in \Delta&lt;/math&gt;, we let the gain for player &lt;math&gt;i&lt;/math&gt; on action &lt;math&gt;a \in A_i&lt;/math&gt; be

:&lt;math&gt;\text{Gain}_i(\sigma,a) = \max \{0, u_i(a, \sigma_{-i}) - u_i(\sigma_{i}, \sigma_{-i})\}.&lt;/math&gt;

The gain function represents the benefit a player gets by unilaterally changing their strategy. We now define &lt;math&gt;g = (g_1,\dotsc,g_N)&lt;/math&gt; where

:&lt;math&gt;g_i(\sigma)(a) = \sigma_i(a) + \text{Gain}_i(\sigma,a)&lt;/math&gt;

for &lt;math&gt;\sigma \in \Delta, a \in A_i&lt;/math&gt;. We see that

:&lt;math&gt;\sum_{a \in A_i} g_i(\sigma)(a) = \sum_{a \in A_i} \sigma_i(a) + \text{Gain}_i(\sigma,a) = 1 + \sum_{a \in A_i} \text{Gain}_i(\sigma,a) &gt; 0.&lt;/math&gt;

Next we define:

:&lt;math&gt;\begin{cases} f = (f_1, \cdots, f_N)  : \Delta \to \Delta \\ f_i(\sigma)(a) = \frac{g_i(\sigma)(a)}{\sum_{b \in A_i} g_i(\sigma)(b)} &amp; a \in A_i \end{cases}&lt;/math&gt;

It is easy to see that each &lt;math&gt;f_i&lt;/math&gt; is a valid mixed strategy in &lt;math&gt;\Delta_i&lt;/math&gt;. It is also easy to check that each &lt;math&gt;f_i&lt;/math&gt; is a continuous function of &lt;math&gt;\sigma&lt;/math&gt;, and hence &lt;math&gt;f&lt;/math&gt; is a continuous function. As the cross product of a finite number of compact convex sets, &lt;math&gt;\Delta&lt;/math&gt; is also compact and convex. Applying the Brouwer fixed point theorem to &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;\Delta&lt;/math&gt; we conclude that &lt;math&gt;f&lt;/math&gt; has a fixed point in &lt;math&gt;\Delta&lt;/math&gt;, call it &lt;math&gt;\sigma^*&lt;/math&gt;. We claim that &lt;math&gt;\sigma^*&lt;/math&gt; is a Nash equilibrium in &lt;math&gt;G&lt;/math&gt;. For this purpose, it suffices to show that

:&lt;math&gt; \forall i \in \{1, \cdots, N\}, \forall a \in A_i: \quad \text{Gain}_i(\sigma^*,a) = 0.&lt;/math&gt;

This simply states that each player gains no benefit by unilaterally changing their strategy, which is exactly the necessary condition for a Nash equilibrium.

Now assume that the gains are not all zero. Therefore, &lt;math&gt;\exists i \in \{1, \cdots, N\},&lt;/math&gt; and &lt;math&gt;a \in A_i&lt;/math&gt; such that &lt;math&gt;\text{Gain}_i(\sigma^*, a) &gt; 0&lt;/math&gt;. Note then that

:&lt;math&gt; \sum_{a \in A_i} g_i(\sigma^*, a) = 1 + \sum_{a \in A_i} \text{Gain}_i(\sigma^*,a) &gt; 1.&lt;/math&gt;

So let

:&lt;math&gt;C = \sum_{a \in A_i} g_i(\sigma^*, a).&lt;/math&gt;

Also we shall denote &lt;math&gt;\text{Gain}(i,\cdot)&lt;/math&gt; as the gain vector indexed by actions in &lt;math&gt;A_i&lt;/math&gt;. Since &lt;math&gt;\sigma^*&lt;/math&gt; is the fixed point we have:

:&lt;math&gt;\begin{align}
\sigma^* = f(\sigma^*)  &amp;\Rightarrow  \sigma^*_i =  f_i(\sigma^*) \\
&amp;\Rightarrow \sigma^*_i = \frac{g_i(\sigma^*)}{\sum_{a \in A_i} g_i(\sigma^*)(a)} \\ [6pt]
&amp;\Rightarrow \sigma^*_i = \frac{1}{C} \left (\sigma^*_i + \text{Gain}_i(\sigma^*,\cdot) \right ) \\ [6pt]
&amp;\Rightarrow C\sigma^*_i = \sigma^*_i + \text{Gain}_i(\sigma^*,\cdot) \\
&amp;\Rightarrow \left(C-1\right)\sigma^*_i = \text{Gain}_i(\sigma^*,\cdot) \\
&amp;\Rightarrow \sigma^*_i = \left(\frac{1}{C-1}\right)\text{Gain}_i(\sigma^*,\cdot).
\end{align}&lt;/math&gt;

Since &lt;math&gt;C &gt; 1&lt;/math&gt; we have that &lt;math&gt;\sigma^*_i&lt;/math&gt; is some positive scaling of the vector &lt;math&gt;\text{Gain}_i(\sigma^*,\cdot)&lt;/math&gt;. Now we claim that

:&lt;math&gt;\forall a \in A_i: \quad  \sigma^*_i(a)(u_i(a_i, \sigma^*_{-i}) - u_i(\sigma^*_i, \sigma^*_{-i})) = \sigma^*_i(a)\text{Gain}_i(\sigma^*, a) &lt;/math&gt;

To see this, we first note that if &lt;math&gt;\text{Gain}_i(\sigma^*, a) &gt; 0&lt;/math&gt; then this is true by definition of the gain function.  Now assume that &lt;math&gt;\text{Gain}_i(\sigma^*, a) = 0&lt;/math&gt;. By our previous statements we have that

:&lt;math&gt;\sigma^*_i(a) = \left(\frac{1}{C-1}\right)\text{Gain}_i(\sigma^*, a) = 0 &lt;/math&gt;

and so the left term is zero, giving us that the entire expression is &lt;math&gt;0&lt;/math&gt; as needed.

So we finally have that

:&lt;math&gt;\begin{align}
0 &amp;= u_i(\sigma^*_i, \sigma^*_{-i}) - u_i(\sigma^*_i, \sigma^*_{-i}) \\
  &amp;=  \left(\sum_{a \in A_i} \sigma^*_i(a)u_i(a_i, \sigma^*_{-i})\right) - u_i(\sigma^*_i, \sigma^*_{-i}) \\
 &amp; =  \sum_{a \in A_i} \sigma^*_i(a) (u_i(a_i, \sigma^*_{-i}) - u_i(\sigma^*_i, \sigma^*_{-i})) \\ 
 &amp; = \sum_{a \in A_i} \sigma^*_i(a) \text{Gain}_i(\sigma^*, a) &amp;&amp; \text{ by the previous statements } \\
  &amp;= \sum_{a \in A_i} \left( C -1 \right) \sigma^*_i(a)^2 &gt; 0
\end{align}&lt;/math&gt;
