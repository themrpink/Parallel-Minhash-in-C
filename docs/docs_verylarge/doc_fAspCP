Reed–Solomon error correction is also used in [[parchive]] files which are commonly posted accompanying multimedia files on [[USENET]]. The Distributed online storage service [[Wuala]] (discontinued in 2015) also used to make use of Reed–Solomon when breaking up files.

===Bar code===
Almost all two-dimensional bar codes such as [[PDF-417]], [[MaxiCode]], [[Datamatrix]], [[QR Code]], and [[Aztec Code]] use Reed–Solomon error correction to allow correct reading even if a portion of the bar code is damaged.  When the bar code scanner cannot recognize a bar code symbol, it will treat it as an erasure.

Reed–Solomon coding is less common in one-dimensional bar codes, but is used by the [[PostBar]] symbology.

===Data transmission===
Specialized forms of Reed–Solomon codes, specifically [[Cauchy matrix|Cauchy]]-RS and [[Vandermonde matrix|Vandermonde]]-RS, can be used to overcome the unreliable nature of data transmission over [[Binary erasure channel|erasure channels]]. The encoding process assumes a code of RS(''N'',&amp;nbsp;''K'') which results in ''N'' codewords of length ''N'' symbols each storing ''K'' symbols of data, being generated, that are then sent over an erasure channel.

Any combination of ''K'' codewords received at the other end is enough to reconstruct all of the ''N'' codewords. The code rate is generally set to 1/2 unless the channel's erasure likelihood can be adequately modelled and is seen to be less. In conclusion, ''N'' is usually 2''K'', meaning that at least half of all the codewords sent must be received in order to reconstruct all of the codewords sent.

Reed–Solomon codes are also used in [[xDSL]] systems and [[CCSDS]]'s [[Space Communications Protocol Specifications]] as a form of [[forward error correction]].

===Space transmission===

[[File:DeepSpaceFEC.png|350px|right|thumb| Deep-space concatenated coding system.&lt;ref&gt;J. Hagenauer, E. Offer, and L. Papke, Reed Solomon Codes and Their Applications. New York IEEE Press, 1994 - p. 433&lt;/ref&gt; Notation: RS(255, 223) + [[convolutional codes|CC]] (&quot;constraint length&quot; = 7, code rate = 1/2).]]

One significant application of Reed–Solomon coding was to encode the digital pictures sent back by the [[Voyager program|Voyager]] space probe.

Voyager introduced Reed–Solomon coding [[concatenated code|concatenated]] with [[convolutional code]]s, a practice that has since become very widespread in deep space and satellite (e.g., direct digital broadcasting) communications.
&lt;!-- Unsourced image removed: [[Image:NASA ECC Codes-imperfection.png|thumb|600px|none|NASA's Deep Space Missions ECC Codes (code imperfectness) {{Deletable image-caption|date=March 2012}}]] --&gt;

[[Viterbi decoder]]s tend to produce errors in short bursts. Correcting these burst errors is a job best done by short or simplified Reed–Solomon codes.

Modern versions of concatenated Reed–Solomon/Viterbi-decoded convolutional coding were and are used on the [[Mars Pathfinder]], [[Galileo probe|Galileo]], [[Mars Exploration Rover]] and [[Cassini probe|Cassini]] missions, where they perform within about 1–1.5 [[decibel|dB]] of the ultimate limit, being the [[Shannon capacity]].

These concatenated codes are now being replaced by more powerful [[turbo code]]s:
{| class=&quot;wikitable&quot;
|+ Channel coding schemes used by NASA missions&lt;ref name=&quot;Andrews, 2007&quot;&gt;Andrews, Kenneth S., et al. &quot;The development of turbo and LDPC codes for deep-space applications.&quot; Proceedings of the IEEE 95.11 (2007): 2142-2156.&lt;/ref&gt;
|-
! Years  !! Code !! Mission(s) 
|-
| 1958-present || Uncoded || Explorer, Mariner, many others 
|-
| 1968-1978 || [[convolutional codes]] (CC) (25, 1/2) || Pioneer, Venus 
|-
| 1969-1975 (32, 6) || [[Reed-Muller code]] || Mariner, Viking 
|-
| 1977-present || [[Binary Golay code]] || Voyager 
|-
| 1977-present || RS(255, 223) + CC(7, 1/2) || Voyager, Galileo, many others
|-
| 1989-2003 || RS(255, 223) + CC(7, 1/3) || Voyager 
|-
| 1958-present || RS(255, 223) + CC(14, 1/4) || Galileo 
|-
| 1996-present || RS + CC (15, 1/6) || Cassini, Mars Pathfinder, others	
|-
| 2004-present || [[Turbo codes]]{{refn|group=nb| Authors in&lt;ref name=&quot;Andrews, 2007&quot;&gt;Andrews, Kenneth S., et al. &quot;The development of turbo and LDPC codes for deep-space applications.&quot; Proceedings of the IEEE 95.11 (2007): 2142-2156.&lt;/ref&gt; provide simulation results which show that for the same code rate (1/6) turbo codes outperform Reed-Solomon concatenated codes up to 2 dB ([[bit error rate]]).}} || Messenger, Stereo, MRO, others 
|-
| est. 2009 || [[LDPC codes]] || Constellation, MSL 
|}

== Constructions ==

The Reed–Solomon code is actually a family of codes, where every code is characterised by three parameters: an [[Block code#The alphabet .CE.A3|alphabet]] size ''q'', a [[Block code#The block length n|block length]] ''n'', and a [[Block code#The message length k|message length]] ''k,'' with ''k &lt; n ≤ q.'' The set of alphabet symbols is interpreted as the [[finite field]] of order ''q'', and thus, ''q'' has to be a [[prime power]]. In the most useful parameterizations of the Reed–Solomon code, the block length is usually some constant multiple of the message length, that is, the [[Block code#The rate R|rate]] {{nowrap|1=''R'' = ''k''/''n''}} is some constant, and furthermore, the block length is equal to or one less than the alphabet size, that is, {{nowrap|1=''n'' = ''q''}} or {{nowrap|1=''n'' = ''q'' − 1}}.{{citation needed|date=March 2017}}

=== Reed &amp; Solomon's original view: The codeword as a sequence of values ===

There are different encoding procedures for the Reed–Solomon code, and thus, there are different ways to describe the set of all codewords.
In the original view of {{Harvtxt|Reed|Solomon|1960}}, every codeword of the Reed–Solomon code is a sequence of function values of a polynomial of degree less than ''k''. In order to obtain a codeword of the Reed–Solomon code, the message is interpreted as the description of a polynomial ''p'' of degree less than ''k'' over the finite field ''F'' with ''q'' elements.
In turn, the polynomial ''p'' is evaluated at ''n'' ≤ ''q'' distinct points &lt;math&gt;a_1,\dots,a_n&lt;/math&gt; of the field ''F'', and the sequence of values is the corresponding codeword. Common choices for a set of evaluation points include {0, 1, 2, ..., ''n'' − 1}, {0, 1, ''α'', ''α''&lt;sup&gt;2&lt;/sup&gt;, ..., ''α''&lt;sup&gt;''n''−2&lt;/sup&gt;}, or for ''n'' &lt; ''q'', {1, ''α'', ''α''&lt;sup&gt;2&lt;/sup&gt;, ..., ''α''&lt;sup&gt;''n''−1&lt;/sup&gt;}, ... , where ''α'' is a [[primitive element (finite field)|primitive element]] of ''F''.

Formally, the set &lt;math&gt;\mathbf{C}&lt;/math&gt; of codewords of the Reed–Solomon code is defined as follows:
: &lt;math&gt;
\mathbf{C}
 = \Big\{\;
     \big( p(a_1), p(a_2), \dots, p(a_n) \big)
     \;\Big|\;
     p \text{ is a polynomial over } F \text{ of degree } &lt;k
   \;\Big\}\,.
&lt;/math&gt;
Since any two ''distinct'' polynomials of degree less than &lt;math&gt;k&lt;/math&gt; agree in at most &lt;math&gt;k-1&lt;/math&gt; points, this means that any two codewords of the Reed–Solomon code disagree in at least &lt;math&gt;n - (k-1) = n-k+1&lt;/math&gt; positions.
Furthermore, there are two polynomials that do agree in &lt;math&gt;k-1&lt;/math&gt; points but are not equal, and thus, the [[Block code#The distance d|distance]] of the Reed–Solomon code is exactly &lt;math&gt;d=n-k+1&lt;/math&gt;.
Then the relative distance is &lt;math&gt;\delta = d/n = 1-k/n + 1/n = 1-R+1/n\sim 1-R&lt;/math&gt;, where &lt;math&gt;R=k/n&lt;/math&gt; is the rate.
This trade-off between the relative distance and the rate is asymptotically optimal since, by the [[Singleton bound]], ''every'' code satisfies &lt;math&gt;\delta+R\leq 1+1/n&lt;/math&gt;.
Being a code that achieves this optimal trade-off, the Reed–Solomon code belongs to the class of [[maximum distance separable code]]s.

While the number of different polynomials of degree less than ''k'' and the number of different messages are both equal to &lt;math&gt;q^k&lt;/math&gt;, and thus every message can be uniquely mapped to such a polynomial, there are different ways of doing this encoding.
The original construction of {{Harvtxt|Reed|Solomon|1960}} interprets the message ''x'' as the ''coefficients'' of the polynomial ''p'', whereas subsequent constructions interpret the message as the ''values'' of the polynomial at the first ''k'' points &lt;math&gt;a_1,\dots,a_k&lt;/math&gt; and obtain the polynomial ''p'' by interpolating these values with a polynomial of degree less than ''k''.
The latter encoding procedure, while being slightly less efficient, has the advantage that it gives rise to a [[systematic code]], that is, the original message is always contained as a subsequence of the codeword.

==== Simple encoding procedure: The message as a sequence of coefficients ====
In the original construction of {{Harvtxt|Reed|Solomon|1960}}, the message &lt;math&gt;x=(x_1,\dots,x_k)\in F^k&lt;/math&gt; is mapped to the polynomial &lt;math&gt;p_x&lt;/math&gt; with
:&lt;math&gt;p_x(a) = \sum_{i=1}^k x_i a^{i-1} \,.&lt;/math&gt;
The codeword of &lt;math&gt;x&lt;/math&gt; is obtained by evaluating &lt;math&gt;p_x&lt;/math&gt; at &lt;math&gt;n&lt;/math&gt; different points &lt;math&gt;a_1,\dots,a_n&lt;/math&gt; of the field &lt;math&gt;F&lt;/math&gt;.
Thus the classical encoding function &lt;math&gt;C:F^k \to F^n&lt;/math&gt; for the Reed–Solomon code is defined as follows: 
:&lt;math&gt;C(x) = \big(p_x(a_1),\dots,p_x(a_n)\big)\,.&lt;/math&gt;
This function &lt;math&gt;C&lt;/math&gt; is a [[linear mapping]], that is, it satisfies &lt;math&gt;C(x) = x \cdot A&lt;/math&gt; for the following &lt;math&gt;(k\times n)&lt;/math&gt;-matrix &lt;math&gt;A&lt;/math&gt; with elements from &lt;math&gt;F&lt;/math&gt;:
:&lt;math&gt;A=\begin{bmatrix}
1         &amp; \dots  &amp; 1         &amp; \dots  &amp; 1     \\
a_1       &amp; \dots  &amp; a_k       &amp; \dots  &amp; a_n   \\
a_1^2     &amp; \dots  &amp; a_k^2     &amp; \dots  &amp; a_n^2 \\
\vdots    &amp;        &amp; \vdots    &amp;        &amp; \vdots \\
a_1^{k-1} &amp; \dots  &amp; a_k^{k-1} &amp; \dots  &amp; a_n^{k-1}
\end{bmatrix}&lt;/math&gt;

This matrix is the transpose of a [[Vandermonde matrix]] over &lt;math&gt;F&lt;/math&gt;. In other words, the Reed–Solomon code is a [[linear code]], and in the classical encoding procedure, its [[Linear code#Properties|generator matrix]] is &lt;math&gt;A&lt;/math&gt;.

==== Systematic encoding procedure: The message as an initial sequence of values ====

There is an alternative encoding procedure that also produces the Reed–Solomon code, but that does so in a [[systematic code|systematic]] way. Here, the mapping from the message &lt;math&gt;x&lt;/math&gt; to the polynomial &lt;math&gt;p_x&lt;/math&gt; works differently: the polynomial &lt;math&gt;p_x&lt;/math&gt; is now defined as the unique polynomial of degree less than &lt;math&gt;k&lt;/math&gt; such that
:&lt;math&gt;p_x(a_i) = x_i&lt;/math&gt; holds for all &lt;math&gt;i\in\{1,\dots,k\}&lt;/math&gt;.
To compute this polynomial &lt;math&gt;p_x&lt;/math&gt; from &lt;math&gt;x&lt;/math&gt;, one can use [[Lagrange interpolation]].
Once it has been found, it is evaluated at the other points &lt;math&gt;a_{k+1},\dots,a_n&lt;/math&gt; of the field.
The alternative encoding function &lt;math&gt;C:F^k \to F^n&lt;/math&gt; for the Reed–Solomon code is then again just the sequence of values: 
:&lt;math&gt;C(x) = \big(p_x(a_1),\dots,p_x(a_n)\big)\,.&lt;/math&gt;
Since the first &lt;math&gt;k&lt;/math&gt; entries of each codeword &lt;math&gt; C(x) &lt;/math&gt; coincide with &lt;math&gt;x&lt;/math&gt;, this encoding procedure is indeed [[systematic code|systematic]].
Since Lagrange interpolation is a linear transformation, &lt;math&gt; C &lt;/math&gt; is a linear mapping. In fact, we have &lt;math&gt; C(x) = x \cdot G &lt;/math&gt;, where
:&lt;math&gt;G=
(A\text{'s left square submatrix})^{-1}\cdot A
=
\begin{bmatrix}
1         &amp; 0      &amp; 0         &amp; \dots  &amp; 0      &amp; g_{1,k+1} &amp; \dots  &amp; g_{1,n} \\
0         &amp; 1      &amp; 0         &amp; \dots  &amp; 0      &amp; g_{2,k+1} &amp; \dots  &amp; g_{2,n} \\
0         &amp; 0      &amp; 1         &amp; \dots  &amp; 0      &amp; g_{3,k+1} &amp; \dots  &amp; g_{3,n} \\
\vdots    &amp; \vdots &amp; \vdots    &amp;        &amp; \vdots &amp; \vdots    &amp;        &amp; \vdots  \\
0         &amp; \dots  &amp; 0         &amp; \dots  &amp; 1      &amp; g_{k,k+1} &amp; \dots  &amp; g_{k,n} 
\end{bmatrix}&lt;/math&gt;

==== Discrete Fourier transform and its inverse ====

A [[discrete Fourier transform (general)|discrete Fourier transform]] is essentially the same as the encoding procedure; it uses the generator polynomial ''p''(x) to map a set of evaluation points into the message values as shown above:

:&lt;math&gt;C(x) = \big(p_x(a_1),\dots,p_x(a_n)\big)\,.&lt;/math&gt;

The inverse Fourier transform could be used to convert an error free set of ''n'' &lt; ''q'' message values back into the encoding polynomial of ''k'' coefficients, with the constraint that in order for this to work, the set of evaluation points used to encode the message must be a set of increasing powers of ''α'':

:&lt;math&gt;a_i = \alpha^{i-1}&lt;/math&gt;
:&lt;math&gt;a_1, \dots, a_n = \{ 1, \alpha, \alpha^2, \dots, \alpha^{n-1} \}&lt;/math&gt;

However, Lagrange interpolation performs the same conversion without the constraint on the set of evaluation points or the requirement of an error free set of message values and is used for systematic encoding, and in one of the steps of the [[#Gao decoder|Gao decoder]].

=== The BCH view: The codeword as a sequence of coefficients ===
In this view, the sender again maps the message &lt;math&gt;x&lt;/math&gt; to a polynomial &lt;math&gt;p_x&lt;/math&gt;, and for this, any of the two mappings just described can be used (where the message is either interpreted as the coefficients of &lt;math&gt;p_x&lt;/math&gt; or as the initial sequence of values of &lt;math&gt;p_x&lt;/math&gt;). Once the sender has constructed the polynomial &lt;math&gt;p_x&lt;/math&gt; in some way, however, instead of sending the ''values'' of &lt;math&gt;p_x&lt;/math&gt; at all points, the sender computes some related polynomial &lt;math&gt;s&lt;/math&gt; of degree at most &lt;math&gt;n-1&lt;/math&gt; for &lt;math&gt;n=q-1&lt;/math&gt; and sends the &lt;math&gt;n&lt;/math&gt; ''coefficients'' of that polynomial. The polynomial &lt;math&gt;s(a)&lt;/math&gt; is constructed by multiplying the message polynomial &lt;math&gt;p_x(a)&lt;/math&gt;, which has degree at most &lt;math&gt;k-1&lt;/math&gt;, with a [[generator polynomial]] &lt;math&gt;g(a)&lt;/math&gt; of degree &lt;math&gt;n-k&lt;/math&gt; that is known to both the sender and the receiver. {{^|comment - as mentioned in remarks below, methods like puncturing may omit transmission of some of the coefficients}} The generator polynomial &lt;math&gt;g(x)&lt;/math&gt; is defined as the polynomial whose roots are exactly &lt;math&gt;\alpha,\alpha^2,\dots,\alpha^{n-k}&lt;/math&gt;, i.e.,

: &lt;math&gt;g(x) = (x-\alpha)(x-\alpha^2)\cdots(x-\alpha^{n-k}) = g_0 + g_1x + \cdots + g_{n-k-1}x^{n-k-1} + x^{n-k}\,.&lt;/math&gt;

The transmitter sends the &lt;math&gt;n=q-1&lt;/math&gt; coefficients of &lt;math&gt;s(a)=p_x(a) \cdot g(a)&lt;/math&gt;. Thus, in the BCH view of Reed–Solomon codes, the set &lt;math&gt;\mathbf{C}&lt;/math&gt; of codewords is defined for &lt;math&gt;n=q-1&lt;/math&gt; as follows:&lt;ref&gt;{{cite book |first1=Rudolf |last1=Lidl |first2=Günter |last2=Pilz |title=Applied Abstract Algebra |edition=2nd |publisher=Wiley |year=1999 |page=226}}&lt;/ref&gt;

:&lt;math&gt;\mathbf{C} =
\left\{
  \left ( s_1, s_2,\dots, s_{n} \right)
  \;\Big|\;
  s(a)=\sum_{i=1}^n s_i a^{i-1}
  \text{ is a polynomial that has at least the roots } \alpha^1,\alpha^2, \dots, \alpha^{n-k}
\right\}\,.&lt;/math&gt;

==== Systematic encoding procedure ====
The encoding procedure for the BCH view of Reed–Solomon codes can be modified to yield a [[systematic code|systematic encoding procedure]], in which each codeword contains the message as a prefix, and simply appends error correcting symbols as a suffix. Here, instead of sending &lt;math&gt;s(x) = p(x) g(x)&lt;/math&gt;, the encoder constructs the transmitted polynomial &lt;math&gt;s(x)&lt;/math&gt; such that the coefficients of the &lt;math&gt;k&lt;/math&gt; largest monomials are equal to the corresponding coefficients of &lt;math&gt;p(x)&lt;/math&gt;, and the lower-order coefficients of &lt;math&gt;s(x)&lt;/math&gt; are chosen exactly in such a way that &lt;math&gt;s(x)&lt;/math&gt; becomes divisible by &lt;math&gt;g(x)&lt;/math&gt;. Then the coefficients of &lt;math&gt;p(x)&lt;/math&gt; are a subsequence (specifically, a prefix) of the coefficients of &lt;math&gt;s(x)&lt;/math&gt;. To get a code that is overall systematic, we construct the message polynomial &lt;math&gt;p(x)&lt;/math&gt; by interpreting the message as the sequence of its coefficients.

Formally, the construction is done by multiplying &lt;math&gt;p(x)&lt;/math&gt; by &lt;math&gt;x^t&lt;/math&gt; to make room for the &lt;math&gt;t=n-k&lt;/math&gt; check symbols, dividing that product by &lt;math&gt;g(x)&lt;/math&gt; to find the remainder, and then compensating for that remainder by subtracting it. The &lt;math&gt;t&lt;/math&gt; check symbols are created by computing the remainder &lt;math&gt;s_r(x)&lt;/math&gt;:

:&lt;math&gt;s_r(x) = p(x)\cdot x^t \ \bmod \  g(x).&lt;/math&gt;

The remainder has degree at most &lt;math&gt;t-1&lt;/math&gt;, whereas the coefficients of &lt;math&gt;x^{t-1},x^{t-2},\dots,x^1,x^0&lt;/math&gt; in the polynomial &lt;math&gt;p(x)\cdot x^t&lt;/math&gt; are zero. Therefore, the following definition of the codeword &lt;math&gt;s(x)&lt;/math&gt; has the property that the first &lt;math&gt;k&lt;/math&gt; coefficients are identical to the coefficients of &lt;math&gt;p(x)&lt;/math&gt;:

:&lt;math&gt;s(x) = p(x)\cdot x^t - s_r(x)\,.&lt;/math&gt;

As a result, the codewords &lt;math&gt;s(x)&lt;/math&gt; are indeed elements of &lt;math&gt;\mathbf{C}&lt;/math&gt;, that is, they are divisible by the generator polynomial &lt;math&gt;g(x)&lt;/math&gt;:&lt;ref&gt;See {{harvtxt|Lin|Costello|1983|p=171}}, for example.&lt;/ref&gt;
:&lt;math&gt;s(x) \equiv p(x)\cdot x^t - s_r(x) \equiv s_r(x) - s_r(x) \equiv 0 \mod g(x)\,.&lt;/math&gt;

==Properties==

The Reed–Solomon code is a [''n'', ''k'', ''n'' &amp;minus; ''k'' + 1] code; in other words, it is a [[linear code|linear block code]] of length ''n'' (over ''F'') with [[Dimension (vector space)|dimension]] ''k'' and minimum [[Hamming distance]] &lt;math display=&quot;inline&quot;&gt;d_{\min}=n-k+1.&lt;/math&gt; The Reed–Solomon code is optimal in the sense that the minimum distance has the maximum value possible for a linear code of size (''n'',&amp;nbsp;''k''); this is known as the [[Singleton bound]]. Such a code is also called a [[MDS code|maximum distance separable (MDS) code]].

The error-correcting ability of a Reed–Solomon code is determined by its minimum distance, or equivalently, by &lt;math&gt;n - k&lt;/math&gt;, the measure of redundancy in the block. If the locations of the error symbols are not known in advance, then a Reed–Solomon code can correct up to &lt;math&gt;(n-k)/2&lt;/math&gt; erroneous symbols, i.e., it can correct half as many errors as there are redundant symbols added to the block. Sometimes error locations are known in advance (e.g., &quot;side information&quot; in [[demodulator]] [[signal-to-noise ratio]]s)—these are called [[Erasure channel|erasures]]. A Reed–Solomon code (like any [[Maximum distance separable code|MDS code]]) is able to correct twice as many erasures as errors, and any combination of errors and erasures can be corrected as long as the relation 2''E''&amp;nbsp;+&amp;nbsp;''S''&amp;nbsp;≤&amp;nbsp;''n''&amp;nbsp;&amp;minus;&amp;nbsp;''k'' is satisfied, where &lt;math&gt;E&lt;/math&gt; is the number of errors and &lt;math&gt;S&lt;/math&gt; is the number of erasures in the block.

[[File:RS BER.png|400px|right|thumb| Theoretical BER performance of the Reed-Solomon code (N=255, K=233, QPSK, AWGN). Step-like characteristic.]]

The theoretical error bound can be described via the following formula for the [[Additive white Gaussian noise|AWGN]] channel for [[Frequency-shift keying|FSK]]:&lt;ref&gt;{{Cite web |url=https://www.mathworks.com/help/comm/ug/bit-error-rate-ber.html#brck0zf |title=Analytical Expressions Used in bercoding and BERTool |access-date=2019-02-01 |archive-date=2019-02-01 |archive-url=https://web.archive.org/web/20190201172027/https://www.mathworks.com/help/comm/ug/bit-error-rate-ber.html#brck0zf |url-status=live }}&lt;/ref&gt;

: &lt;math&gt;P_b \approx \frac{2^{m-1}}{2^m-1}\frac{1}{n}\sum_{\ell=t+1}^n \ell {n\choose \ell}P_s^\ell(1-P_s)^{n-\ell}&lt;/math&gt;

and for other modulation schemes:

: &lt;math&gt;P_b \approx \frac{1}{m}\frac{1}{n}\sum_{\ell=t+1}^n \ell {n\choose \ell} P_s^\ell(1-P_s)^{n-\ell}&lt;/math&gt;

where &lt;math&gt;t = \frac{1}{2}(d_{\min}-1)&lt;/math&gt;, &lt;math&gt;P_s = 1-(1-s)^h&lt;/math&gt;, &lt;math&gt;h = \frac{m}{\log_2M}&lt;/math&gt;, &lt;math&gt;s&lt;/math&gt; is the symbol error rate in uncoded AWGN case and &lt;math&gt;M&lt;/math&gt; is the modulation order.

For practical uses of Reed–Solomon codes, it is common to use a finite field &lt;math&gt;F&lt;/math&gt; with &lt;math&gt;2^m&lt;/math&gt; elements. In this case, each symbol can be represented as an &lt;math&gt;m&lt;/math&gt;-bit value. 
The sender sends the data points as encoded blocks, and the number of symbols in the encoded block is &lt;math&gt;n = 2^m - 1&lt;/math&gt;. Thus a Reed–Solomon code operating on 8-bit symbols has &lt;math&gt;n = 2^8 - 1 = 255&lt;/math&gt; symbols per block. (This is a very popular value because of the prevalence of [[byte-oriented]] computer systems.) The number &lt;math&gt;k&lt;/math&gt;, with &lt;math&gt;k &lt; n&lt;/math&gt;, of ''data'' symbols in the block is a design parameter. A commonly used code encodes &lt;math&gt;k = 223&lt;/math&gt; eight-bit data symbols plus 32 eight-bit parity symbols in an &lt;math&gt;n = 255&lt;/math&gt;-symbol block; this is denoted as a &lt;math&gt;(n, k) = (255,223)&lt;/math&gt; code, and is capable of correcting up to 16 symbol errors per block.

The Reed–Solomon code properties discussed above make them especially well-suited to applications where errors occur in [[burst error|burst]]s.  This is because it does not matter to the code how many bits in a symbol are in error — if multiple bits in a symbol are corrupted it only counts as a single error.  Conversely, if a data stream is not characterized by error bursts or drop-outs but by random single bit errors, a Reed–Solomon code is usually a poor choice compared to a binary code.
