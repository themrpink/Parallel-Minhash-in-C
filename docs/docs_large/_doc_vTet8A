Once the error locators ''X&lt;sub&gt;k&lt;/sub&gt;'' are known, the error values can be determined. This can be done by direct solution for ''Y&lt;sub&gt;k&lt;/sub&gt;'' in the [[#Error locators and error values|error equations]] matrix given above, or using the [[Forney algorithm]].

====Calculate the error locations====

Calculate ''i&lt;sub&gt;k&lt;/sub&gt;'' by taking the log base &lt;math&gt;\alpha&lt;/math&gt; of ''X&lt;sub&gt;k&lt;/sub&gt;''. This is generally done using a precomputed lookup table.

====Fix the errors====

Finally, e(x) is generated from ''i&lt;sub&gt;k&lt;/sub&gt;'' and ''e&lt;sub&gt;i&lt;sub&gt;k&lt;/sub&gt;&lt;/sub&gt;'' and then is subtracted from r(x) to get the originally sent message s(x), with errors corrected.

==== Example ====

Consider the Reed&amp;ndash;Solomon code defined in {{math|''GF''(929)}} with {{math|''α'' {{=}} 3}} and {{math|''t'' {{=}} 4}} (this is used in [[PDF417]] barcodes) for a RS(7,3) code. The generator polynomial is
:&lt;math&gt;g(x) = (x-3)(x-3^2)(x-3^3)(x-3^4) = x^4+809 x^3+723 x^2+568 x+522&lt;/math&gt;
If the message polynomial is {{math|''p''(''x'') {{=}} 3 ''x''&lt;sup&gt;2&lt;/sup&gt; + 2 ''x'' + 1}}, then a systematic codeword is encoded as follows.
:&lt;math&gt;s_r(x) = p(x) \, x^t \mod g(x) = 547 x^3 + 738 x^2 + 442 x + 455&lt;/math&gt;
:&lt;math&gt;s(x) = p(x) \, x^t - s_r(x) = 3 x^6 + 2 x^5 + 1 x^4 + 382 x^3 + 191 x^2 + 487 x + 474&lt;/math&gt;
Errors in transmission might cause this to be received instead.
:&lt;math&gt;r(x) = s(x) + e(x) = 3 x^6 + 2 x^5 + 123 x^4 + 456 x^3 + 191 x^2 + 487 x + 474&lt;/math&gt;
The syndromes are calculated by evaluating ''r'' at powers of ''α''.
:&lt;math&gt;S_1 = r(3^1) = 3\cdot 3^6 + 2\cdot 3^5 + 123\cdot 3^4 + 456\cdot 3^3 + 191\cdot 3^2 + 487\cdot 3 + 474 = 732&lt;/math&gt;
:&lt;math&gt;S_2 = r(3^2) = 637,\;S_3 = r(3^3) = 762,\;S_4 = r(3^4) = 925&lt;/math&gt;

:&lt;math&gt;\begin{bmatrix}
732 &amp; 637 \\
637 &amp; 762
\end{bmatrix}
\begin{bmatrix}
\Lambda_2 \\
\Lambda_1
\end{bmatrix}
= 
\begin{bmatrix}
-762 \\ -925 
\end{bmatrix}
= 
\begin{bmatrix}
167 \\ 004 
\end{bmatrix}
&lt;/math&gt;

Using [[Gaussian elimination]]:

:&lt;math&gt;\begin{bmatrix}
001 &amp; 000 \\
000 &amp; 001
\end{bmatrix}
\begin{bmatrix}
\Lambda_2 \\
\Lambda_1
\end{bmatrix}
= 
\begin{bmatrix}
329 \\ 821 
\end{bmatrix}
&lt;/math&gt;

:Λ(x) = 329 x&lt;sup&gt;2&lt;/sup&gt; + 821 x + 001, with roots x&lt;sub&gt;1&lt;/sub&gt; = 757 = 3&lt;sup&gt;&amp;minus;3&lt;/sup&gt; and x&lt;sub&gt;2&lt;/sub&gt; = 562 = 3&lt;sup&gt;&amp;minus;4&lt;/sup&gt;
The coefficients can be reversed to produce roots with positive exponents, but typically this isn't used:
:R(x) = 001 x&lt;sup&gt;2&lt;/sup&gt; + 821 x + 329, with roots 27 = 3&lt;sup&gt;3&lt;/sup&gt; and 81 = 3&lt;sup&gt;4&lt;/sup&gt;
with the log of the roots corresponding to the error locations (right to left, location 0 is the last term in the codeword).

To calculate the error values, apply the [[Forney algorithm]].

:Ω(x) = S(x) Λ(x) mod x&lt;sup&gt;4&lt;/sup&gt; = 546 x + 732
:Λ'(x) = 658 x + 821
:e&lt;sub&gt;1&lt;/sub&gt; = −Ω(x&lt;sub&gt;1&lt;/sub&gt;)/Λ'(x&lt;sub&gt;1&lt;/sub&gt;) = 074
:e&lt;sub&gt;2&lt;/sub&gt; = −Ω(x&lt;sub&gt;2&lt;/sub&gt;)/Λ'(x&lt;sub&gt;2&lt;/sub&gt;) = 122

Subtracting ''e''&lt;sub&gt;1&lt;/sub&gt; ''x''&lt;sup&gt;3&lt;/sup&gt; and ''e''&lt;sub&gt;2&lt;/sub&gt; ''x''&lt;sup&gt;4&lt;/sup&gt; from the received polynomial ''r'' reproduces the original codeword ''s''.

=== Berlekamp&amp;ndash;Massey decoder ===
The [[Berlekamp&amp;ndash;Massey algorithm]] is an alternate iterative procedure for finding the error locator polynomial. During each iteration, it calculates a discrepancy based on a current instance of Λ(x) with an assumed number of errors ''e'':

:&lt;math&gt; \Delta  = S_{i} + \Lambda_1 \  S_{i-1} + \cdots + \Lambda_e \  S_{i-e}&lt;/math&gt;

and then adjusts Λ(''x'') and ''e'' so that a recalculated Δ would be zero. The article [[Berlekamp&amp;ndash;Massey algorithm]] has a detailed description of the procedure. In the following example, ''C''(''x'') is used to represent Λ(''x'').

==== Example ====

Using the same data as the Peterson Gorenstein Zierler example above:
{| class=&quot;wikitable&quot;
|-
! ''n''
! ''S''&lt;sub&gt;''n''+1&lt;/sub&gt;
! ''d''
! ''C''
! ''B''
! ''b''
! ''m''
|-
| 0 || 732 || 732 || 197 ''x'' + 1 || 1 || 732 || 1
|-
| 1 || 637 || 846 || 173 ''x'' + 1 || 1 || 732 || 2
|-
| 2 || 762 || 412 || 634 ''x''&lt;sup&gt;2&lt;/sup&gt; + 173 ''x'' + 1 || 173 ''x'' + 1 || 412 || 1
|-
| 3 || 925 || 576 || 329 ''x''&lt;sup&gt;2&lt;/sup&gt; + 821 ''x'' + 1 || 173 ''x'' + 1 || 412 || 2
|}
The final value of ''C'' is the error locator polynomial, Λ(''x'').

=== Euclidean decoder ===

Another iterative method for calculating both the error locator polynomial and the error value polynomial is based on Sugiyama's adaptation of the [[extended Euclidean algorithm]] .

Define S(x), Λ(x), and Ω(x) for ''t'' syndromes and ''e'' errors:

:&lt;math&gt; S(x) = S_{t} x^{t-1} + S_{t-1} x^{t-2} + \cdots + S_2 x + S_1 &lt;/math&gt;

:&lt;math&gt; \Lambda(x) = \Lambda_{e} x^{e} + \Lambda_{e-1} x^{e-1} + \cdots + \Lambda_{1} x + 1&lt;/math&gt;

:&lt;math&gt; \Omega(x) = \Omega_{e} x^{e} + \Omega_{e-1} x^{e-1} + \cdots + \Omega_{1} x + \Omega_{0}&lt;/math&gt;

The key equation is:

:&lt;math&gt; \Lambda(x) S(x) = Q(x) x^{t} + \Omega(x) &lt;/math&gt;

For ''t'' = 6 and ''e'' = 3:

:&lt;math&gt;\begin{bmatrix}
\Lambda_3 S_6 &amp; x^8 \\
\Lambda_2 S_6 + \Lambda_3 S_5 &amp; x^7  \\
\Lambda_1 S_6 + \Lambda_2 S_5 + \Lambda_3 S_4 &amp; x^6 \\
          S_6 + \Lambda_1 S_5 + \Lambda_2 S_4 + \Lambda_3 S_3 &amp; x^5 \\
          S_5 + \Lambda_1 S_4 + \Lambda_2 S_3 + \Lambda_3 S_2 &amp; x^4 \\
          S_4 + \Lambda_1 S_3 + \Lambda_2 S_2 + \Lambda_3 S_1 &amp; x^3 \\
          S_3 + \Lambda_1 S_2 + \Lambda_2 S_1 &amp; x^2 \\
          S_2 + \Lambda_1 S_1 &amp; x \\
          S_1
\end{bmatrix}
=
\begin{bmatrix}
Q_2 x^8 \\
Q_1 x^7 \\
Q_0 x^6 \\
0 \\
0 \\
0 \\
\Omega_2 x^2 \\
\Omega_1 x \\
\Omega_0
\end{bmatrix}
&lt;/math&gt;

The middle terms are zero due to the relationship between Λ and syndromes.

The extended Euclidean algorithm can find a series of polynomials of the form

: ''A''&lt;sub&gt;''i''&lt;/sub&gt;(''x'') ''S''(''x'') + ''B''&lt;sub&gt;''i''&lt;/sub&gt;(''x'') ''x''&lt;sup&gt;''t''&lt;/sup&gt; = ''R''&lt;sub&gt;''i''&lt;/sub&gt;(''x'')

where the degree of ''R'' decreases as ''i'' increases. Once the degree of ''R''&lt;sub&gt;''i''&lt;/sub&gt;(''x'') &lt; ''t''/2, then

A&lt;sub&gt;i&lt;/sub&gt;(x) = Λ(x)

B&lt;sub&gt;i&lt;/sub&gt;(x) = −Q(x)

R&lt;sub&gt;i&lt;/sub&gt;(x) = Ω(x).

B(x) and Q(x) don't need to be saved, so the algorithm becomes:

:R&lt;sub&gt;−1&lt;/sub&gt; = x&lt;sup&gt;t&lt;/sup&gt;
:R&lt;sub&gt;0&lt;/sub&gt; = S(x)
:A&lt;sub&gt;−1&lt;/sub&gt; = 0
:A&lt;sub&gt;0&lt;/sub&gt; = 1
:i = 0
:while degree of R&lt;sub&gt;i&lt;/sub&gt; ≥ t/2
::i = i + 1
::Q = R&lt;sub&gt;i-2&lt;/sub&gt; / R&lt;sub&gt;i-1&lt;/sub&gt;
::R&lt;sub&gt;i&lt;/sub&gt; = R&lt;sub&gt;i-2&lt;/sub&gt; - Q R&lt;sub&gt;i-1&lt;/sub&gt;
::A&lt;sub&gt;i&lt;/sub&gt; = A&lt;sub&gt;i-2&lt;/sub&gt; - Q A&lt;sub&gt;i-1&lt;/sub&gt; 
to set low order term of Λ(x) to 1, divide Λ(x) and Ω(x) by A&lt;sub&gt;i&lt;/sub&gt;(0):
:Λ(x) = A&lt;sub&gt;i&lt;/sub&gt; / A&lt;sub&gt;i&lt;/sub&gt;(0)
:Ω(x) = R&lt;sub&gt;i&lt;/sub&gt; / A&lt;sub&gt;i&lt;/sub&gt;(0)

A&lt;sub&gt;i&lt;/sub&gt;(0) is the constant (low order) term of A&lt;sub&gt;i&lt;/sub&gt;.

==== Example ====

Using the same data as the Peterson–Gorenstein–Zierler example above:

{| class=&quot;wikitable&quot;
|-
! ''i''
! R&lt;sub&gt;''i''&lt;/sub&gt;
! A&lt;sub&gt;''i''&lt;/sub&gt;
|-
| −1
| 001 x&lt;sup&gt;4&lt;/sup&gt; + 000 x&lt;sup&gt;3&lt;/sup&gt; + 000 x&lt;sup&gt;2&lt;/sup&gt; + 000 x + 000
| 000
|-
| 0
| 925 x&lt;sup&gt;3&lt;/sup&gt; + 762 x&lt;sup&gt;2&lt;/sup&gt; + 637 x + 732
| 001
|-
| 1
| 683 x&lt;sup&gt;2&lt;/sup&gt; + 676 x + 024
| 697 x + 396 
|-
| 2
| 673 x + 596
| 608 x&lt;sup&gt;2&lt;/sup&gt; + 704 x + 544 
|-
|}

:Λ(x) = A&lt;sub&gt;2&lt;/sub&gt; / 544 = 329 x&lt;sup&gt;2&lt;/sup&gt; + 821 x + 001 
:Ω(x) =  R&lt;sub&gt;2&lt;/sub&gt; / 544 = 546 x + 732

=== Decoder using discrete Fourier transform ===

A discrete Fourier transform can be used for decoding.&lt;ref&gt;Shu Lin and Daniel J. Costello Jr, &quot;Error Control Coding&quot; second edition, pp. 255–262, 1982, 2004&lt;/ref&gt;  To avoid conflict with syndrome names, let ''c''(''x'') = ''s''(''x'') the encoded codeword. ''r''(''x'') and ''e''(''x'') are the same as above. Define ''C''(''x''), ''E''(''x''), and ''R''(''x'') as the discrete Fourier transforms of ''c''(''x''), ''e''(''x''), and ''r''(''x''). Since ''r''(''x'') = ''c''(''x'') + ''e''(''x''), and since a discrete Fourier transform is a linear operator, ''R''(''x'') = ''C''(''x'') + ''E''(''x'').

Transform ''r''(''x'') to ''R''(''x'') using discrete Fourier transform. Since the calculation for a discrete Fourier transform is the same as the calculation for syndromes, ''t'' coefficients of ''R''(''x'') and ''E''(''x'') are the same as the syndromes:

:&lt;math&gt;R_j = E_j = S_j = r(\alpha^j)&lt;/math&gt;
:&lt;math&gt;\text{for } 1 \le j \le t&lt;/math&gt;

Use &lt;math&gt;R_1&lt;/math&gt; through &lt;math&gt;R_t&lt;/math&gt; as syndromes (they're the same) and generate the error locator polynomial using the methods from any of the above decoders.

Let v = number of errors. Generate E(x) using the known coefficients &lt;math&gt;E_1&lt;/math&gt; to &lt;math&gt;E_t&lt;/math&gt;, the error locator polynomial, and these formulas

:&lt;math&gt;E_0 = - \frac{1}{\Lambda_v}(E_{v} + \Lambda_1 E_{v-1} + \cdots + \Lambda_{v-1} E_{1})&lt;/math&gt;
:&lt;math&gt;E_j = -(\Lambda_1 E_{j-1} + \Lambda_2 E_{j-2} + \cdots + \Lambda_v E_{j-v})&lt;/math&gt;
:&lt;math&gt;\text{for } t &lt; j &lt; n&lt;/math&gt;
