Then calculate ''C''(''x'') = ''R''(''x'') − ''E''(''x'') and take the inverse transform (polynomial interpolation) of ''C''(''x'') to produce ''c''(''x'').

===Decoding beyond the error-correction bound===

The [[Singleton bound]] states that the minimum distance ''d'' of a linear block code of size (''n'',''k'') is upper-bounded by ''n''&amp;nbsp;&amp;minus;&amp;nbsp;''k''&amp;nbsp;+&amp;nbsp;1. The distance ''d'' was usually understood to limit the error-correction capability to ⌊''d''/2⌋. The Reed–Solomon code achieves this bound with equality, and can thus correct up to ⌊(''n''&amp;nbsp;&amp;minus;&amp;nbsp;''k''&amp;nbsp;+&amp;nbsp;1)/2⌋ errors. However, this error-correction bound is not exact.

In 1999, [[Madhu Sudan]] and [[Venkatesan Guruswami]] at MIT published &quot;Improved Decoding of Reed–Solomon and Algebraic-Geometry Codes&quot; introducing an algorithm that allowed for the correction of errors beyond half the minimum distance of the code.&lt;ref&gt;{{Citation |first=V. |last=Guruswami |first2=M. |last2=Sudan |title=Improved decoding of Reed–Solomon codes and algebraic geometry codes |journal=[[IEEE Transactions on Information Theory]] |volume=45 |issue=6 |pages=1757&amp;ndash;1767 |date=September 1999 |doi=10.1109/18.782097 |citeseerx=10.1.1.115.292 }}&lt;/ref&gt; It applies to Reed–Solomon codes and more generally to [[algebraic geometric code]]s. This algorithm produces a list of codewords (it is a [[list-decoding]] algorithm) and is based on interpolation and factorization of polynomials over &lt;math&gt;GF(2^m)&lt;/math&gt; and its extensions.

===Soft-decoding===

The algebraic decoding methods described above are hard-decision methods, which means that for every symbol a hard decision is made about its value.  For example, a decoder could associate with each symbol an additional value corresponding to the channel [[demodulator]]'s confidence in the correctness of the symbol. The advent of [[low-density parity-check code|LDPC]] and [[turbo code]]s, which employ iterated [[soft-decision decoding|soft-decision]] belief propagation decoding methods to achieve error-correction performance close to the [[Shannon limit|theoretical limit]], has spurred interest in applying soft-decision decoding to conventional algebraic codes. In 2003, Ralf Koetter and [[Alexander Vardy]] presented a polynomial-time soft-decision algebraic list-decoding algorithm for Reed–Solomon codes, which was based upon the work by Sudan and Guruswami.&lt;ref&gt;{{cite journal | first1=Ralf | last1=Koetter | first2=Alexander | last2=Vardy | title=Algebraic soft-decision decoding of Reed–Solomon codes | journal=[[IEEE Transactions on Information Theory]] | volume=49 | issue=11 | year=2003 | pages=2809–2825 | doi=10.1109/TIT.2003.819332| citeseerx=10.1.1.13.2021 }}&lt;/ref&gt;
In 2016,  Steven J. Franke and Joseph H. Taylor published a novel soft-decision decoder.&lt;ref&gt;{{cite journal | first1=Steven J. | last1=Franke | first2=Joseph H. | last2=Taylor | title=Open Source Soft-Decision Decoder for the JT65 (63,12) Reed–Solomon Code | journal=QEX | issue=May/June | year=2016 | pages=8–17 | url=http://physics.princeton.edu/pulsar/K1JT/FrankeTaylor_QEX_2016.pdf | access-date=2017-06-07 | archive-date=2017-03-09 | archive-url=https://web.archive.org/web/20170309134627/http://www.physics.princeton.edu/pulsar/k1jt/FrankeTaylor_QEX_2016.pdf | url-status=live }}&lt;/ref&gt;

=== Matlab example ===

==== Encoder ====
Here we present a simple Matlab implementation for an encoder.
&lt;syntaxhighlight lang=&quot;matlab&quot;&gt;
function [encoded] = rsEncoder(msg, m, prim_poly, n, k)
    % RSENCODER Encode message with the Reed-Solomon algorithm
    % m is the number of bits per symbol
    % prim_poly: Primitive polynomial p(x). Ie for DM is 301
    % k is the size of the message
    % n is the total size (k+redundant)
    % Example: msg = uint8('Test')
    % enc_msg = rsEncoder(msg, 8, 301, 12, numel(msg));
 
    % Get the alpha
    alpha = gf(2, m, prim_poly);
 
    % Get the Reed-Solomon generating polynomial g(x)
    g_x = genpoly(k, n, alpha);
 
    % Multiply the information by X^(n-k), or just pad with zeros at the end to
    % get space to add the redundant information
    msg_padded = gf([msg zeros(1, n - k)], m, prim_poly);
 
    % Get the remainder of the division of the extended message by the
    % Reed-Solomon generating polynomial g(x)
    [~, remainder] = deconv(msg_padded, g_x);
 
    % Now return the message with the redundant information
    encoded = msg_padded - remainder;
 
end

% Find the Reed-Solomon generating polynomial g(x), by the way this is the
% same as the rsgenpoly function on matlab
function g = genpoly(k, n, alpha)
    g = 1;
    % A multiplication on the galois field is just a convolution
    for k = mod(1 : n - k, n)
        g = conv(g, [1 alpha .^ (k)]);
    end
end
&lt;/syntaxhighlight&gt;

==== Decoder ====
Now the decoding part:
&lt;syntaxhighlight lang=&quot;matlab&quot;&gt;
function [decoded, error_pos, error_mag, g, S] = rsDecoder(encoded, m, prim_poly, n, k)
    % RSDECODER Decode a Reed-Solomon encoded message
    %   Example:
    % [dec, ~, ~, ~, ~] = rsDecoder(enc_msg, 8, 301, 12, numel(msg))
    max_errors = floor((n - k) / 2);
    orig_vals = encoded.x;
    % Initialize the error vector
    errors = zeros(1, n);
    g = [];
    S = [];
 
    % Get the alpha
    alpha = gf(2, m, prim_poly);
 
    % Find the syndromes (Check if dividing the message by the generator
    % polynomial the result is zero)
    Synd = polyval(encoded, alpha .^ (1:n - k));
    Syndromes = trim(Synd);
 
    % If all syndromes are zeros (perfectly divisible) there are no errors
    if isempty(Syndromes.x)
        decoded = orig_vals(1:k);
        error_pos = [];
        error_mag = [];
        g = [];
        S = Synd;
        return;
    end
 
    % Prepare for the euclidean algorithm (Used to find the error locating
    % polynomials)
    r0 = [1, zeros(1, 2 * max_errors)]; r0 = gf(r0, m, prim_poly); r0 = trim(r0);
    size_r0 = length(r0);
    r1 = Syndromes;
    f0 = gf([zeros(1, size_r0 - 1) 1], m, prim_poly);
    f1 = gf(zeros(1, size_r0), m, prim_poly);
    g0 = f1; g1 = f0;
 
    % Do the euclidean algorithm on the polynomials r0(x) and Syndromes(x) in
    % order to find the error locating polynomial
    while true
        % Do a long division
        [quotient, remainder] = deconv(r0, r1);
        % Add some zeros
        quotient = pad(quotient, length(g1));
     
        % Find quotient*g1 and pad
        c = conv(quotient, g1);
        c = trim(c);
        c = pad(c, length(g0));
     
        % Update g as g0-quotient*g1
        g = g0 - c;
     
        % Check if the degree of remainder(x) is less than max_errors
        if all(remainder(1:end - max_errors) == 0)
            break;
        end
     
        % Update r0, r1, g0, g1 and remove leading zeros
        r0 = trim(r1); r1 = trim(remainder);
        g0 = g1; g1 = g;
    end
 
    % Remove leading zeros
    g = trim(g);
 
    % Find the zeros of the error polynomial on this galois field
    evalPoly = polyval(g, alpha .^ (n - 1 : - 1 : 0));
    error_pos = gf(find(evalPoly == 0), m);
 
    % If no error position is found we return the received work, because
    % basically is nothing that we could do and we return the received message
    if isempty(error_pos)
        decoded = orig_vals(1:k);
        error_mag = [];
        return;
    end
 
    % Prepare a linear system to solve the error polynomial and find the error
    % magnitudes
    size_error = length(error_pos);
    Syndrome_Vals = Syndromes.x;
    b(:, 1) = Syndrome_Vals(1:size_error);
    for idx = 1 : size_error
        e = alpha .^ (idx * (n - error_pos.x));
        err = e.x;
        er(idx, :) = err;
    end
 
    % Solve the linear system
    error_mag = (gf(er, m, prim_poly) \ gf(b, m, prim_poly))';
    % Put the error magnitude on the error vector
    errors(error_pos.x) = error_mag.x;
    % Bring this vector to the galois field
    errors_gf = gf(errors, m, prim_poly);
 
    % Now to fix the errors just add with the encoded code
    decoded_gf = encoded(1:k) + errors_gf(1:k);
    decoded = decoded_gf.x;
 
end

% Remove leading zeros from Galois array
function gt = trim(g)
    gx = g.x;
    gt = gf(gx(find(gx, 1) : end), g.m, g.prim_poly);
end

% Add leading zeros
function xpad = pad(x, k)
    len = length(x);
    if (len &lt; k)
        xpad = [zeros(1, k - len) x];
    end
end
&lt;/syntaxhighlight&gt;

== Reed Solomon original view decoders ==

The decoders described in this section use the Reed Solomon original view of a codeword as a sequence of polynomial values where the polynomial is based on the message to be encoded. The same set of fixed values are used by the encoder and decoder, and the decoder recovers the encoding polynomial (and optionally an error locating polynomial) from the received message.

=== Theoretical decoder ===

{{Harvtxt|Reed|Solomon|1960}} described a theoretical decoder that corrected errors by finding the most popular message polynomial. The decoder only knows the set of values &lt;math&gt;a_1&lt;/math&gt; to &lt;math&gt;a_n&lt;/math&gt; and which encoding method was used to generate the codeword's sequence of values. The original message, the polynomial, and any errors are unknown. A decoding procedure could use a method like Lagrange interpolation on various subsets of n codeword values taken k at a time to repeatedly produce potential polynomials, until a sufficient number of matching polynomials are produced to reasonably eliminate any errors in the received codeword. Once a polynomial is determined, then any errors in the codeword can be corrected, by recalculating the corresponding codeword values. Unfortunately, in all but the simplest of cases, there are too many subsets, so the algorithm is impractical.  The number of subsets is the [[binomial coefficient]], &lt;math&gt;\textstyle \binom{n}{k} = {n! \over (n-k)! k!}&lt;/math&gt;, and the number of subsets is infeasible for even modest codes. For a &lt;math&gt;(255,249)&lt;/math&gt; code that can correct 3 errors, the naive theoretical decoder would examine 359 billion subsets. &lt;!-- = 255 * 254 * 253 * 252 * 251 * 250 / 720 rounded down; could say 360B --&gt;

=== Berlekamp Welch decoder ===

In 1986, a decoder known as the [[Berlekamp–Welch algorithm]] was developed as a decoder that is able to recover the original message polynomial as well as an error &quot;locator&quot; polynomial that produces zeroes for the input values that correspond to errors, with time complexity O(n^3), where n is the number of values in a message. The recovered polynomial is then used to recover (recalculate as needed) the original message.

==== Example ====

Using RS(7,3), GF(929), and the set of evaluation points ''a''&lt;sub&gt;''i''&lt;/sub&gt; = ''i'' − 1

:{{math| ''a'' {{=}} {0, 1, 2, 3, 4, 5, 6} }}

If the message polynomial is
:{{math| ''p''(''x'') {{=}} 003 ''x''&lt;sup&gt;2&lt;/sup&gt; + 002 ''x'' + 001}}

The codeword is
:{{math| ''c'' {{=}} {001, 006, 017, 034, 057, 086, 121} }}

Errors in transmission might cause this to be received instead.
:{{math| ''b'' {{=}} ''c'' + ''e'' {{=}} {001, 006, 123, 456, 057, 086, 121} }}

The key equations are:

:&lt;math&gt;b_i E(a_i) - Q(a_i) = 0 &lt;/math&gt;

Assume maximum number of errors: ''e'' = 2. The key equations become:

:&lt;math&gt;b_i(e_0 + e_1 a_i) - (q_0 + q_1 a_i + q_2 a_i^2 + q_3 a_i^3 + q_4 a_i^4) = - b_i a_i^2&lt;/math&gt;

:&lt;math&gt;\begin{bmatrix}
001 &amp; 000 &amp; 928 &amp; 000 &amp; 000 &amp; 000 &amp; 000 \\
006 &amp; 006 &amp; 928 &amp; 928 &amp; 928 &amp; 928 &amp; 928 \\
123 &amp; 246 &amp; 928 &amp; 927 &amp; 925 &amp; 921 &amp; 913 \\
456 &amp; 439 &amp; 928 &amp; 926 &amp; 920 &amp; 902 &amp; 848 \\
057 &amp; 228 &amp; 928 &amp; 925 &amp; 913 &amp; 865 &amp; 673 \\
086 &amp; 430 &amp; 928 &amp; 924 &amp; 904 &amp; 804 &amp; 304 \\
121 &amp; 726 &amp; 928 &amp; 923 &amp; 893 &amp; 713 &amp; 562
\end{bmatrix}
\begin{bmatrix}
e_0 \\
e_1 \\
q_0 \\
q_1 \\
q_2 \\
q_3 \\
q_4
\end{bmatrix}
=
\begin{bmatrix}
000 \\
923 \\
437 \\
541 \\
017 \\
637 \\
289
\end{bmatrix}
&lt;/math&gt;

Using [[Gaussian elimination]]:

:&lt;math&gt;
\begin{bmatrix}
001 &amp; 000 &amp; 000 &amp; 000 &amp; 000 &amp; 000 &amp; 000 \\
000 &amp; 001 &amp; 000 &amp; 000 &amp; 000 &amp; 000 &amp; 000 \\
000 &amp; 000 &amp; 001 &amp; 000 &amp; 000 &amp; 000 &amp; 000 \\
000 &amp; 000 &amp; 000 &amp; 001 &amp; 000 &amp; 000 &amp; 000 \\
000 &amp; 000 &amp; 000 &amp; 000 &amp; 001 &amp; 000 &amp; 000 \\
000 &amp; 000 &amp; 000 &amp; 000 &amp; 000 &amp; 001 &amp; 000 \\
000 &amp; 000 &amp; 000 &amp; 000 &amp; 000 &amp; 000 &amp; 001 
\end{bmatrix}
\begin{bmatrix}
e_0 \\
e_1 \\
q_0 \\
q_1 \\
q_2 \\
q_3 \\
q_4
\end{bmatrix}
=
\begin{bmatrix}
006 \\
924 \\
006 \\
007 \\
009 \\
916 \\
003
\end{bmatrix}
&lt;/math&gt;

:{{math| ''Q''(''x'') {{=}} 003 ''x''&lt;sup&gt;4&lt;/sup&gt; + 916 ''x''&lt;sup&gt;3&lt;/sup&gt; + 009 ''x''&lt;sup&gt;2&lt;/sup&gt; + 007 ''x'' + 006}}

:{{math| ''E''(''x'') {{=}} 001 ''x''&lt;sup&gt;2&lt;/sup&gt; + 924 ''x'' + 006}}

:{{math| ''Q''(''x'') / ''E''(''x'') {{=}} ''P''(''x'') {{=}} 003 ''x''&lt;sup&gt;2&lt;/sup&gt; + 002 ''x'' + 001}}

Recalculate {{math| P(x) }} where {{math| E(x) {{=}} 0 : {2, 3} }} to correct {{math| ''b''}} resulting in the corrected codeword:

:{{math| ''c'' {{=}} {001, 006, 017, 034, 057, 086, 121} }}

=== Gao decoder ===

In 2002, an improved decoder was developed by Shuhong Gao, based on the extended Euclid algorithm [http://www.math.clemson.edu/~sgao/papers/RS.pdf Gao_RS.pdf] .

==== Example ====

Using the same data as the Berlekamp Welch example above:

:&lt;math&gt;R_{-1} = \prod_{i=1}^n (x - a_i)&lt;/math&gt;
:&lt;math&gt;R_0 = &lt;/math&gt; Lagrange interpolation of &lt;math&gt;\{a_i, b(a_i)\}&lt;/math&gt; for ''i'' = 1 to ''n''
:&lt;math&gt;A_{-1} = 0&lt;/math&gt;
:&lt;math&gt;A_0 = 1&lt;/math&gt;

{| class=&quot;wikitable&quot;
|-
! ''i''
! R&lt;sub&gt;''i''&lt;/sub&gt;
! A&lt;sub&gt;''i''&lt;/sub&gt;
|-
| −1
| 001 x&lt;sup&gt;7&lt;/sup&gt; + 908 x&lt;sup&gt;6&lt;/sup&gt; + 175 x&lt;sup&gt;5&lt;/sup&gt; + 194 x&lt;sup&gt;4&lt;/sup&gt; + 695 x&lt;sup&gt;3&lt;/sup&gt; + 094 x&lt;sup&gt;2&lt;/sup&gt; + 720 x + 000
| 000
|-
| 0
| 055 x&lt;sup&gt;6&lt;/sup&gt; + 440 x&lt;sup&gt;5&lt;/sup&gt; + 497 x&lt;sup&gt;4&lt;/sup&gt; + 904 x&lt;sup&gt;3&lt;/sup&gt; + 424 x&lt;sup&gt;2&lt;/sup&gt; + 472 x + 001
| 001
|-
| 1
| 702 x&lt;sup&gt;5&lt;/sup&gt; + 845 x&lt;sup&gt;4&lt;/sup&gt; + 691 x&lt;sup&gt;3&lt;/sup&gt; + 461 x&lt;sup&gt;2&lt;/sup&gt; + 327 x + 237
| 152 x + 237
|-
| 2
| 266 x&lt;sup&gt;4&lt;/sup&gt; + 086 x&lt;sup&gt;3&lt;/sup&gt; + 798 x&lt;sup&gt;2&lt;/sup&gt; + 311 x + 532
| 708 x&lt;sup&gt;2&lt;/sup&gt; + 176 x + 532
|-
|}

:{{math| ''Q''(''x'') {{=}} ''R''&lt;sub&gt;2&lt;/sub&gt; {{=}} 266 ''x''&lt;sup&gt;4&lt;/sup&gt; + 086 ''x''&lt;sup&gt;3&lt;/sup&gt; + 798 ''x''&lt;sup&gt;2&lt;/sup&gt; + 311 ''x'' + 532}}

:{{math| ''E''(''x'') {{=}} ''A''&lt;sub&gt;2&lt;/sub&gt; {{=}} 708 ''x''&lt;sup&gt;2&lt;/sup&gt; + 176 ''x'' + 532}}

divide ''Q''(x) and ''E''(x) by most significant coefficient of ''E''(x) = 708. (Optional)

:{{math| ''Q''(''x'') {{=}} 003 ''x''&lt;sup&gt;4&lt;/sup&gt; + 916 ''x''&lt;sup&gt;3&lt;/sup&gt; + 009 ''x''&lt;sup&gt;2&lt;/sup&gt; + 007 ''x'' + 006}}

:{{math| ''E''(''x'') {{=}} 001 ''x''&lt;sup&gt;2&lt;/sup&gt; + 924 ''x'' + 006}}

:{{math| ''Q''(''x'') / ''E''(''x'') {{=}} ''P''(''x'') {{=}} 003 ''x''&lt;sup&gt;2&lt;/sup&gt; + 002 ''x'' + 001}}

Recalculate {{math| ''P''(''x'') }} where {{math| ''E''(''x'') {{=}} 0 : {2, 3} }} to correct {{math| ''b''}} resulting in the corrected codeword:

:{{math| ''c'' {{=}} {001, 006, 017, 034, 057, 086, 121} }}
