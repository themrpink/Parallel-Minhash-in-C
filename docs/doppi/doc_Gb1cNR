=== General properties ===

* The [[probability-generating function]]s of ''X'' and ''Y'' are, respectively,
::&lt;math&gt;
\begin{align}
G_X(s) &amp; = \frac{s\,p}{1-s\,(1-p)}, \\[10pt]
G_Y(s) &amp; = \frac{p}{1-s\,(1-p)}, \quad |s| &lt; (1-p)^{-1}.
\end{align}
&lt;/math&gt;

* Like its continuous analogue (the [[exponential distribution]]), the geometric distribution is [[memorylessness|memoryless]].  That means that if you intend to repeat an experiment until the first success, then, given that the first success has not yet occurred, the conditional probability distribution of the number of additional trials does not depend on how many failures have been observed.  The die one throws or the coin one tosses does not have a &quot;memory&quot; of these failures.  The geometric distribution is the only memoryless discrete distribution.

&lt;math&gt;Pr\{X&gt;m+n|X&gt;n\}=Pr\{X&gt;m\}&lt;/math&gt;&lt;ref&gt;{{Cite web|url=https://www.stat.berkeley.edu/~aditya/resources/AllLectures2018Fall201A.pdf|title=Fall 2018 Statistics 201A (Introduction to Probability at an advanced level) - All Lecture Notes|last=Guntuboyina|first=Aditya|date=|website=|url-status=live|archive-url=|archive-date=|access-date=}}&lt;/ref&gt;

* Among all discrete probability distributions supported on {1,&amp;nbsp;2,&amp;nbsp;3,&amp;nbsp;...&amp;nbsp;} with given expected value&amp;nbsp;''μ'', the geometric distribution ''X'' with parameter ''p''&amp;nbsp;=&amp;nbsp;1/''μ'' is the one with the [[maximum entropy probability distribution|largest entropy]].&lt;ref&gt;{{Cite journal|last=Park|first=Sung Y.|last2=Bera|first2=Anil K.|date=June 2009|title=Maximum entropy autoregressive conditional heteroskedasticity model|journal=Journal of Econometrics|volume=150|issue=2|pages=219–230|doi=10.1016/j.jeconom.2008.12.014}}&lt;/ref&gt;
* The geometric distribution of the number ''Y'' of failures before the first success  is [[infinite divisibility (probability)|infinitely divisible]], i.e., for any positive integer ''n'', there exist independent identically distributed random variables ''Y''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''Y''&lt;sub&gt;''n''&lt;/sub&gt; whose sum has the same distribution that ''Y'' has.  These will not be geometrically distributed unless ''n''&amp;nbsp;=&amp;nbsp;1; they follow a [[negative binomial distribution]].
* The decimal digits of the geometrically distributed random variable ''Y'' are a sequence of [[statistical independence|independent]] (and ''not'' identically distributed) random variables.{{citation needed|date=May 2012}}  For example, the &lt;!-- &quot;hundreds&quot; is correct; &quot;hundredth&quot; is wrong --&gt;hundreds&lt;!-- &quot;hundreds&quot; is correct; &quot;hundredth&quot; is wrong --&gt; digit ''D'' has this probability distribution:

::&lt;math&gt;\Pr(D=d) = {q^{100d} \over 1 + q^{100} + q^{200} + \cdots + q^{900}},&lt;/math&gt;
:where ''q''&amp;nbsp;=&amp;nbsp;1&amp;nbsp;&amp;minus;&amp;nbsp;''p'', and similarly for the other digits, and, more generally, similarly for [[numeral system]]s with other bases than 10.  When the base is 2, this shows that a geometrically distributed random variable can be written as a sum of independent random variables whose probability distributions are [[indecomposable distribution|indecomposable]].

* [[Golomb coding]] is the optimal [[prefix code]]{{clarify|date=May 2012}} for the geometric discrete distribution.&lt;ref&gt;{{Cite journal|last=Gallager|first=R.|last2=van Voorhis|first2=D.|date=March 1975|title=Optimal source codes for geometrically distributed integer alphabets (Corresp.)|journal=IEEE Transactions on Information Theory|volume=21|issue=2|pages=228–230|doi=10.1109/TIT.1975.1055357|issn=0018-9448}}&lt;/ref&gt;
*The sum of two independent ''Geo''(p) distributed random variables is not a geometric distribution. &lt;ref name=&quot;:0&quot; /&gt;

==Related distributions==

* The geometric distribution ''Y'' is a special case of the [[negative binomial distribution]], with ''r''&amp;nbsp;=&amp;nbsp;1. More generally, if ''Y''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''Y''&lt;sub&gt;''r''&lt;/sub&gt; are [[statistical independence|independent]] geometrically distributed variables with parameter&amp;nbsp;''p'', then the sum

::&lt;math&gt;Z = \sum_{m=1}^r Y_m&lt;/math&gt;

:follows a negative binomial distribution with parameters ''r''&amp;nbsp;and&amp;nbsp;''p''.&lt;ref&gt;Pitman, Jim. Probability (1993 edition). Springer Publishers. pp 372.&lt;/ref&gt;

*The geometric distribution is a special case of discrete [[compound Poisson distribution]].
* If ''Y''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''Y''&lt;sub&gt;''r''&lt;/sub&gt; are independent geometrically distributed variables (with possibly different success parameters ''p''&lt;sub&gt;''m''&lt;/sub&gt;), then their [[minimum]]

::&lt;math&gt;W = \min_{m \in 1, \ldots, r} Y_m\,&lt;/math&gt;
::
::is also geometrically distributed, with parameter &lt;math&gt;p = 1-\prod_m(1-p_{m}).&lt;/math&gt;{{citation needed|date=May 2012}}

* Suppose 0&amp;nbsp;&lt;&amp;nbsp;''r''&amp;nbsp;&lt;&amp;nbsp;1, and for ''k''&amp;nbsp;=&amp;nbsp;1,&amp;nbsp;2,&amp;nbsp;3,&amp;nbsp;... the random variable ''X''&lt;sub&gt;''k''&lt;/sub&gt; has a [[Poisson distribution]] with expected value ''r''&lt;sup&gt;&amp;nbsp;''k''&lt;/sup&gt;/''k''.  Then

::&lt;math&gt;\sum_{k=1}^\infty k\,X_k&lt;/math&gt;

:has a geometric distribution taking values in the set {0,&amp;nbsp;1,&amp;nbsp;2,&amp;nbsp;...}, with expected value ''r''/(1&amp;nbsp;&amp;minus;&amp;nbsp;''r'').{{citation needed|date=May 2012}}

* The [[exponential distribution]] is the continuous analogue of the geometric distribution.  If ''X'' is an exponentially distributed random variable with parameter&amp;nbsp;λ, then

::&lt;math&gt;Y = \lfloor X \rfloor,&lt;/math&gt;

: where &lt;math&gt;\lfloor \quad \rfloor&lt;/math&gt; is the [[Floor and ceiling functions|floor]] (or greatest integer) function, is a geometrically distributed random variable with parameter ''p''&amp;nbsp;=&amp;nbsp;1&amp;nbsp;&amp;minus;&amp;nbsp;''e''&lt;sup&gt;&amp;minus;''&amp;lambda;''&lt;/sup&gt; (thus ''&amp;lambda;''&amp;nbsp;=&amp;nbsp;&amp;minus;ln(1&amp;nbsp;&amp;minus;&amp;nbsp;''p'')&lt;ref&gt;{{cite web|url=http://www.wolframalpha.com/input/?i=inverse+p+=+1+-+e%5E-l|title=Wolfram-Alpha: Computational Knowledge Engine|website=www.wolframalpha.com}}&lt;/ref&gt;) and taking values in the set&amp;nbsp;{0,&amp;nbsp;1,&amp;nbsp;2,&amp;nbsp;...}.  This can be used to generate geometrically distributed pseudorandom numbers by first [[Exponential distribution#Generating exponential variates|generating exponentially distributed]] pseudorandom numbers from a uniform [[pseudorandom number generator]]: then &lt;math&gt;\lfloor \ln(U) / \ln(1-p)\rfloor&lt;/math&gt; is geometrically distributed with parameter &lt;math&gt;p&lt;/math&gt;, if &lt;math&gt;U&lt;/math&gt; is uniformly distributed in [0,1].

* If ''p'' = 1/''n'' and ''X'' is geometrically distributed with parameter ''p'', then the distribution of ''X''/''n'' approaches an [[exponential distribution]] with expected value 1 as ''n''&amp;nbsp;&amp;rarr;&amp;nbsp;&amp;infin;, since

::&lt;math&gt;
\begin{align}
P(X/n&gt;a)=P(X&gt;na) &amp; = (1-p)^{na} = \left(1-\frac 1 n \right)^{na} = \left[ \left( 1-\frac 1 n \right)^n \right]^{a} \\
&amp; \to [e^{-1}]^{a} = e^{-a} \text{ as } n\to\infty.
\end{align}
&lt;/math&gt;  More generally, if p=λx/n, where λ is a parameter, then as n&amp;rarr;&amp;nbsp;&amp;infin; the distribution approaches an exponential distribution with expected value λ which gives the general definition of the exponential distribution
:&lt;math&gt;P(X&gt;x)=\lim_{n \to \infty}(1-\lambda x /n)^n=\lambda e^{-\lambda x}&lt;/math&gt; 
:therefore the distribution function of x equals &lt;math&gt;1-e^{-\lambda x}&lt;/math&gt; and differentiating the probability density function of the exponential function is obtained 
:&lt;math&gt;f_X(x)=\lambda e^{-\lambda x} &lt;/math&gt; for x ≥ 0. &lt;ref name=&quot;:0&quot; /&gt;

==Statistical inference==

===Parameter estimation===

For both variants of the geometric distribution, the parameter ''p'' can be estimated by equating the expected value with the [[sample mean]]. This is the [[method of moments (statistics)|method of moments]], which in this case happens to yield [[maximum likelihood]] estimates of ''p''.&lt;ref&gt;{{cite book |last1=casella |first1=george |last2=berger |first2=roger l |title=statistical inference |isbn=0-534-24312-6 |pages=312–315 |edition= 2nd|year=2002 }}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.projectrhea.org/rhea/index.php/MLE_Examples:_Exponential_and_Geometric_Distributions_Old_Kiwi|title=MLE Examples: Exponential and Geometric Distributions Old Kiwi - Rhea|website=www.projectrhea.org|access-date=2019-11-17}}&lt;/ref&gt;

Specifically, for the first variant let ''k''&amp;nbsp;=&amp;nbsp;''k''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''k''&lt;sub&gt;''n''&lt;/sub&gt; be a [[sample (statistics)|sample]] where ''k''&lt;sub&gt;''i''&lt;/sub&gt;&amp;nbsp;≥&amp;nbsp;1 for ''i''&amp;nbsp;=&amp;nbsp;1,&amp;nbsp;...,&amp;nbsp;''n''.  Then ''p'' can be estimated as

:&lt;math&gt;\widehat{p} = \left(\frac1n \sum_{i=1}^n k_i\right)^{-1} = \frac{n}{\sum_{i=1}^n k_i }. \!&lt;/math&gt;

In [[Bayesian inference]], the [[Beta distribution]] is the [[conjugate prior]] distribution for the parameter ''p''.  If this parameter is given a Beta(''α'',&amp;nbsp;''β'') [[prior distribution|prior]], then the [[posterior distribution]] is

:&lt;math&gt;p \sim \mathrm{Beta}\left(\alpha+n,\ \beta+\sum_{i=1}^n (k_i-1)\right). \!&lt;/math&gt;

The posterior mean E[''p''] approaches the maximum likelihood estimate &lt;math&gt;\widehat{p}&lt;/math&gt; as ''α'' and ''β'' approach zero.

In the alternative case, let ''k''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''k''&lt;sub&gt;''n''&lt;/sub&gt; be a sample where ''k''&lt;sub&gt;''i''&lt;/sub&gt;&amp;nbsp;≥&amp;nbsp;0 for ''i''&amp;nbsp;=&amp;nbsp;1,&amp;nbsp;...,&amp;nbsp;''n''.  Then ''p'' can be estimated as

:&lt;math&gt;\widehat{p} = \left(1 + \frac1n \sum_{i=1}^n k_i\right)^{-1} = \frac{n}{\sum_{i=1}^n k_i + n}. \!&lt;/math&gt;

The posterior distribution of ''p'' given a Beta(''α'',&amp;nbsp;''β'') prior is&lt;ref&gt;{{Cite web|url=http://halweb.uc3m.es/esp/Personal/personas/mwiper/docencia/English/PhD_Bayesian_Statistics/ch3_2009.pdf|title=3. Conjugate families of distributions|last=|first=|date=|website=|url-status=live|archive-url=|archive-date=|access-date=}}&lt;/ref&gt;&lt;ref&gt;{{Citation|title=Conjugate prior|date=2019-10-03|url=https://en.wikipedia.org/w/index.php?title=Conjugate_prior&amp;oldid=919465574|work=Wikipedia|access-date=2019-11-17}}&lt;/ref&gt;

:&lt;math&gt;p \sim \mathrm{Beta}\left(\alpha+n,\ \beta+\sum_{i=1}^n k_i\right). \!&lt;/math&gt;

Again the posterior mean E[''p''] approaches the maximum likelihood estimate &lt;math&gt;\widehat{p}&lt;/math&gt; as ''α'' and ''β'' approach zero.

For either estimate of &lt;math&gt;\widehat{p}&lt;/math&gt; using Maximum Likelihood, the bias is equal to 
: &lt;math&gt;
    b \equiv \operatorname{E}\bigg[\;(\hat p_\mathrm{mle} - p)\;\bigg]
        = \frac{p\,(1-p)}{n} 
  &lt;/math&gt;

which yields the '''[[Maximum likelihood estimation#Higher-order properties|bias-corrected maximum likelihood estimator]]'''

: &lt;math&gt;
    \hat{p\,}^*_\text{mle} = \hat{p\,}_\text{mle} - \hat{b\,}
  &lt;/math&gt;

==Computational methods==

===Geometric distribution using R===

The [[R (programming language)|R]] function &lt;code&gt; dgeom(k, prob)&lt;/code&gt; calculates the probability that there are k failures before the first success, where the argument &quot;prob&quot; is the probability of success on each trial.

For example,

&lt;code&gt;dgeom(0,0.6) = 0.6&lt;/code&gt;

&lt;code&gt;dgeom(1,0.6) = 0.24&lt;/code&gt;

R uses the convention that k is the number of failures, so that the number of trials up to and including the first success is ''k'' + 1.

The following R code creates a graph of the geometric distribution from ''Y'' = 0 to 10, with ''p'' = 0.6.

&lt;code&gt;
Y=0:10

plot(Y, dgeom(Y,0.6), type=&quot;h&quot;, ylim=c(0,1), main=&quot;Geometric distribution for p=0.6&quot;, ylab=&quot;P(Y=Y)&quot;, xlab=&quot;Y=Number of failures before first success&quot;)
&lt;/code&gt;

===Geometric distribution using Excel===

The geometric distribution, for the number of failures before the first success, is a special case of the [[negative binomial distribution]], for the number of failures before s successes.

The Excel function &lt;code&gt; NEGBINOMDIST(number_f, number_s, probability_s)&lt;/code&gt; calculates the probability of k = number_f failures before s = number_s successes where p = probability_s is the probability of success on each trial. For the geometric distribution, let number_s = 1 success.
