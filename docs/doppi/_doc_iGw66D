where each &lt;math&gt;f&lt;/math&gt; is a density function.

If ''X'' is discrete and ''Y'' is continuous,

:&lt;math&gt; P(X{=}x| Y{=}y) = \frac{f_{Y | X{=}x}(y) P(X{=}x)}{f_Y(y)}.&lt;/math&gt;

If both ''X'' and ''Y'' are continuous,

:&lt;math&gt; f_{X| Y{=}y}(x) = \frac{f_{Y | X{=}x}(y) f_X(x)}{f_Y(y)}.&lt;/math&gt;

====Extended form====
[[File:Continuous event space specification.svg|thumb|Figure 6: A way to conceptualize event spaces generated by continuous random variables X and Y.]]

A continuous event space is often conceptualized in terms of the numerator terms. It is then useful to eliminate the denominator using the [[law of total probability]]. For ''f&lt;sub&gt;Y&lt;/sub&gt;''(''y''), this becomes an integral:

:&lt;math&gt; f_Y(y) = \int_{-\infty}^\infty f_{Y| X = \xi}(y) f_X(\xi)\,d\xi .&lt;/math&gt;

=== Bayes' rule ===
Bayes' theorem in [[odds|odds form]] is:

:&lt;math&gt;O(A_1:A_2| B) = O(A_1:A_2) \cdot \Lambda(A_1:A_2| B) &lt;/math&gt;

where

:&lt;math&gt;\Lambda(A_1:A_2| B) = \frac{P(B| A_1)}{P(B| A_2)}&lt;/math&gt;

is called the [[Bayes factor]] or [[likelihood ratio]].  The odds between two events is simply the ratio of the probabilities of the two events. Thus

:&lt;math&gt;O(A_1:A_2) = \frac{P(A_1)}{P(A_2)},&lt;/math&gt;

:&lt;math&gt;O(A_1:A_2| B) = \frac{P(A_1| B)}{P(A_2| B)},&lt;/math&gt;

Thus,  the rule says that the posterior odds are the prior odds times the [[Bayes factor]], or in other words,  the posterior is proportional to the prior times the likelihood.

In the special case that &lt;math&gt;A_1 = A&lt;/math&gt; and &lt;math&gt;A_2 = \neg A&lt;/math&gt;, one writes &lt;math&gt;O(A)=O(A:\neg A) =P(A)/(1-P(A))&lt;/math&gt;, and uses a similar abbreviation for the Bayes factor and for the conditional odds. The odds on &lt;math&gt;A&lt;/math&gt; is by definition the odds for and against &lt;math&gt;A&lt;/math&gt;. Bayes' rule can then be written in the abbreviated form

:&lt;math&gt;O(A|B) = O(A)  \cdot \Lambda(A|B) ,&lt;/math&gt;

or, in word, the posterior odds on &lt;math&gt;A&lt;/math&gt; equals the prior odds  on &lt;math&gt;A&lt;/math&gt; times the likelihood ratio for &lt;math&gt;A&lt;/math&gt; given information &lt;math&gt;B&lt;/math&gt;. In short,  '''posterior odds equals prior odds times likelihood ratio'''.

==Derivation==

===For events===
Bayes' theorem may be derived from the definition of [[conditional probability]]:

:&lt;math&gt;P(A\mid B)=\frac{P(A \cap B)}{P(B)}, \text{ if } P(B) \neq 0, &lt;/math&gt;
:&lt;math&gt;P(B\mid A) = \frac{P(B \cap A)}{P(A)}, \text{ if } P(A) \neq 0, &lt;/math&gt;

where &lt;math&gt;P(A \cap B)&lt;/math&gt; is the [[joint probability]] of both A and B being true. Because

:&lt;math&gt;P(B \cap A)=P(A \cap B)&lt;/math&gt;,
:&lt;math&gt;\Rightarrow P(A \cap B) = P(A\mid B) P(B) = P(B\mid A) P(A) &lt;/math&gt;
:&lt;math&gt;\Rightarrow P(A\mid B) = \frac{P(B\mid A) P(A)}{P(B)}, \text{ if } P(B) \neq 0.&lt;/math&gt;

===For random variables===
For two continuous [[random variable]]s ''X'' and ''Y'', Bayes' theorem may be analogously derived from the definition of [[conditional density]]:

:&lt;math&gt;f_{X \mid  Y=y} (x) = \frac{f_{X,Y}(x,y)}{f_Y(y)} &lt;/math&gt;
:&lt;math&gt;f_{Y \mid  X=x}(y) = \frac{f_{X,Y}(x,y)}{f_X(x)} &lt;/math&gt;

Therefore,

:&lt;math&gt;f_{X \mid Y=y}(x) = \frac{f_{Y \mid  X=x}(y) f_X(x)}{f_Y(y)}.&lt;/math&gt;

==Correspondence to other mathematical frameworks==

===Propositional logic===
Bayes' theorem represents a generalisation of [[contraposition]] which in [[Propositional calculus|propositional logic]] can be expressed as:

:&lt;math&gt;(\lnot A \to \lnot B) \to (B \to A). &lt;/math&gt;

The corresponding formula in terms of probability calculus is Bayes' theorem which in its expanded form is expressed as: 
:&lt;math&gt;P(A \mid B) = \frac{P(B \mid A) a(A)}{P(B\mid A) a(A)+P(B \mid \lnot A) a(\lnot A)}.&lt;/math&gt;

In the equation above the [[conditional probability]] &lt;math&gt;P(B \mid A)&lt;/math&gt; generalizes the logical statement &lt;math&gt;(A \to B)&lt;/math&gt;, i.e. in addition to assigning TRUE or FALSE we can also assign any probability to the statement. The term &lt;math&gt;a(A)&lt;/math&gt; denotes the [[prior probability]] (aka. the [[base rate]]) of &lt;math&gt;A&lt;/math&gt;. Assume that &lt;math&gt;P(A \mid B) = 1&lt;/math&gt; is equivalent to &lt;math&gt;(B \to A)&lt;/math&gt; being TRUE, and that &lt;math&gt;P(A \mid B) = 0&lt;/math&gt; is equivalent to &lt;math&gt;(B \to A)&lt;/math&gt; being FALSE.  It is then easy to see that &lt;math&gt;P(A \mid B) = 1&lt;/math&gt; when &lt;math&gt;P(\lnot B\mid \lnot A) = 1&lt;/math&gt; i.e. when &lt;math&gt;(\lnot A \to \lnot B)&lt;/math&gt; is TRUE. This is because &lt;math&gt;P(B\mid \lnot A) = 1 - P(\lnot B \mid \lnot A) = 0&lt;/math&gt; so that the fraction on the right-hand side of the equation above is equal to 1, and hence &lt;math&gt;P(A \mid B) = 1&lt;/math&gt; which is equivalent to  &lt;math&gt;(B \to A)&lt;/math&gt; being TRUE. Hence, Bayes' theorem represents a generalization of [[contraposition]].&lt;ref&gt;Audun Jøsang, 2016, ''Subjective Logic; A formalism for Reasoning Under Uncertainty.'' Springer, Cham, {{ISBN|978-3-319-42337-1}}&lt;/ref&gt;

===Subjective logic===
Bayes' theorem represents a special case of conditional inversion in [[subjective logic]] expressed as:

:&lt;math&gt;(\omega^S_{A\tilde{|}B},\omega^S_{A\tilde{|}\lnot B}) = (\omega^S_{B\mid A}, \omega^S_{B\mid\lnot A}) \widetilde{\phi} a_A,&lt;/math&gt;

where &lt;math&gt;\widetilde{\phi}&lt;/math&gt; denotes the operator for conditional inversion. The argument &lt;math&gt;(\omega^S_{B\mid A},\omega^S_{B\mid\lnot A})&lt;/math&gt; denotes a pair of binomial conditional opinions given by source &lt;math&gt;S&lt;/math&gt;, and the argument &lt;math&gt;a_{A}&lt;/math&gt; denotes the [[prior probability]] (aka. the [[base rate]]) of &lt;math&gt;A&lt;/math&gt;. The pair of inverted conditional opinions is denoted &lt;math&gt;(\omega^S_{A\tilde{|}B},\omega^{S}_{A\tilde{|}\lnot B})&lt;/math&gt;. The conditional opinion &lt;math&gt;\omega^S_{A\mid B}&lt;/math&gt; generalizes the probabilistic conditional &lt;math&gt;P(A \mid B)&lt;/math&gt;, i.e. in addition to assigning a probability the source &lt;math&gt;S&lt;/math&gt; can assign any subjective opinion to the conditional statement &lt;math&gt;(A\mid B)&lt;/math&gt;. A binomial subjective opinion &lt;math&gt;\omega^{S}_{A}&lt;/math&gt; is the belief in the truth of statement &lt;math&gt;A&lt;/math&gt; with degrees of epistemic uncertainty, as expressed by source &lt;math&gt;S&lt;/math&gt;. Every subjective opinion has a corresponding projected probability &lt;math&gt;P(\omega^{S}_{A})&lt;/math&gt;. The application of Bayes' theorem to projected probabilities of opinions is a [[homomorphism]], meaning that Bayes' theorem can be expressed in terms of projected probabilities of opinions:

:&lt;math&gt;P(\omega^S_{A \tilde{|} B}) = \frac{P(\omega^S_{B \mid A}) a(A)}{P(\omega^S_{B\mid A})  a(A) + P(\omega^S_{B \mid \lnot A}) a(\lnot A)}. &lt;/math&gt;

Hence, the subjective Bayes' theorem represents a generalization of Bayes' theorem.&lt;ref&gt;Audun Jøsang, 2016, ''[http://folk.uio.no/josang/papers/Josang2016-MFI.pdf Generalising Bayes' Theorem in Subjective Logic].'' IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2016), Baden-Baden, September 2016&lt;/ref&gt;

==Generalizations==

===Conditioned version===

A conditioned version of the Bayes' theorem&lt;ref name=koller09&gt;{{cite book
 |author=Koller, D.
 |author2=Friedman, N.
 |title=Probabilistic Graphical Models
 |url=http://pgm.stanford.edu/
 |publisher=MIT Press
 |location=Massachusetts
 |year=2009
 |pages=1208
 |isbn=978-0-262-01319-2
 |archive-url=https://web.archive.org/web/20140427083249/http://pgm.stanford.edu/
 |archive-date=2014-04-27
 |url-status=dead
 |author2-link=Nir Friedman
 |author-link=Daphne Koller
 }}&lt;/ref&gt; results from the addition of a third event &lt;math&gt;C&lt;/math&gt; on which all probabilities are conditioned:

:&lt;math&gt;P(A \mid B \cap C) = \frac{P(B \mid A \cap C) \, P(A \mid C)}{P(B \mid C)} &lt;/math&gt;

====Derivation====

Using the [[Chain rule (probability)|chain rule]]
:&lt;math&gt;P(A \cap B \cap C) = P(A \mid B \cap C) \, P(B \mid C) \, P(C)&lt;/math&gt;

And, on the other hand
:&lt;math&gt;P(A \cap B \cap C) = P(B \cap A \cap C) = P(B \mid A \cap C) \, P(A \mid C) \, P(C) &lt;/math&gt;

The desired result is obtained by identifying both expressions and solving for &lt;math&gt;P(A \mid B \cap C)&lt;/math&gt;.

===Bayes' rule with 3 events===

In the case of 3 events - A, B, and C - it can be shown that:

&lt;math&gt;P(A \mid B,C) = \frac{P(B \mid A,C) \; P(A \mid C)}{P(B \mid C)} &lt;/math&gt;

{{hidden begin|style=width:60%|ta1=center|border=1px #aaa solid|title=[Proof]&lt;ref&gt;Graham Kemp (https://math.stackexchange.com/users/135106/graham-kemp), Bayes' rule with 3 variables, URL (version: 2015-05-14): https://math.stackexchange.com/q/1281558&lt;/ref&gt;}}
&lt;math&gt;
\begin{align}
\mathsf P(A\mid B, C) &amp; = \frac{\mathsf P(A,B,C)}{\mathsf P(B, C)}
\\[1ex] &amp; =\frac{\mathsf P(B\mid A,C)\,\mathsf P(A, C)}{\mathsf P(B, C)}
\\[1ex] &amp; =\frac{\mathsf P(B\mid A,C)\,\mathsf P(A\mid C)\,\mathsf P(C)}{\mathsf P(B, C)}
\\[1ex] &amp; =\frac{\mathsf P(B\mid A,C)\,\mathsf P(A\mid C) \mathsf P(C)}{\mathsf P(B\mid C) \mathsf P(C)}
\\[1ex] &amp; =\frac{\mathsf P(B\mid A,C)\;\mathsf P(A\mid C)}{\mathsf P(B\mid C)}
\end{align}
&lt;/math&gt;
{{hidden end}}
